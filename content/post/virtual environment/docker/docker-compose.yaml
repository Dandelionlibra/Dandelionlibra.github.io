name: dandelion

networks:
  ollama_net:
    driver: bridge
    
services:
  jupyter:
    image: pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel
    tty: true
      #entrypoint: [/bin/bash]
      #command: jupyter lab --ip=0.0.0.0 --port=8888 --allow-root --no-browser
    ports:
      - "8888:8888"
    volumes:
      - ~/yuchen:/workspace/yuchen
    networks:
      - ollama_net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: /usr/local/bin/docker-healthcheck.sh
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
  ollama:
    tty: true
    image: ollama/ollama
                #  # container_name: ${APP_OLLAMA_CONTAINER_NAME}
                #  # restart: always
    networks:
      - ollama_net
    volumes:
      - ~/yuchen/ollama:/root/.ollama
    ports:
      - "11435:11434"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: /usr/local/bin/docker-healthcheck.sh
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
      
  lightrag:
    container_name: lightrag # http://lightrag:9621
    image: ghcr.io/hkuds/lightrag:latest
    ports:
      - "9621:9621"
    volumes:
      - ./LightRAG/data/rag_storage:/app/data/rag_storage
      - ./LightRAG/data/inputs:/app/data/inputs
      - ./LightRAG/config.ini:/app/config.ini
      - ./LightRAG/.env:/app/.env
    env_file:
      - ./LightRAG/.env
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - ollama_net


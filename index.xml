<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>YuChen</title><link>https://Dandelionlibra.github.io/</link><description>Recent content on YuChen</description><generator>Hugo -- gohugo.io</generator><language>zh-Hant-TW</language><lastBuildDate>Tue, 22 Jul 2025 05:27:00 +0800</lastBuildDate><atom:link href="https://Dandelionlibra.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>LightRAG 論文導讀 — Simple and Fast Retrieval-Augmented Generation 筆記</title><link>https://Dandelionlibra.github.io/post/note/lightrag-paper-review/</link><pubDate>Tue, 22 Jul 2025 05:27:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/note/lightrag-paper-review/</guid><description>&lt;blockquote>
&lt;p>本文整理自：&lt;a class="link" href="https://arxiv.org/abs/2410.05779" target="_blank" rel="noopener"
>LightRAG: Simple and Fast Retrieval-Augmented Generation&lt;/a>&lt;br>
作者：Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, Chao Huang&lt;br>
發佈於 arXiv，2024年10月&lt;/p>&lt;/blockquote>
&lt;h1 id="摘要">摘要
&lt;/h1>&lt;p>RAG 透過整合外部知識來源，提升 LLMs 回應的準確性與上下文相關性，但面臨&lt;strong>過度依賴平面資料表示&lt;/strong> (flat data representations)、&lt;strong>上下文感知能力不足&lt;/strong> (inadequate contextual awareness)、&lt;strong>導致生成碎片化答案&lt;/strong> (fragmented answers)，無法捕捉複雜的相互依賴關係 (inter-dependencies)。&lt;br>
LightRAG，提出透過將圖結構 (graph structures) 引入文本的索引 (text indexing) 和檢索 (retrieval) 過程來解決上述問題。&lt;/p>
&lt;hr>
&lt;h1 id="引言">引言
&lt;/h1>&lt;h2 id="現有-rag-系統的局限性">現有 RAG 系統的局限性
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>&lt;strong>依賴平面資料表示：&lt;/strong> 許多方法依賴於平面資料表示（flat data representations），限制了它們根據實體之間複雜關係來理解和檢索資訊的能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>缺乏上下文感知：&lt;/strong> 這些系統通常缺乏維持不同實體及其相互關係之間連貫性所需的上下文感知能力，導致回應可能無法完全解決用戶查詢。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>例：考慮用戶提問「電動車的興起如何影響城市空氣品質和大眾運輸基礎設施？」現有 RAG 方法可能檢索到關於電動車、空氣污染和公共交通挑戰的獨立文檔，但難以將這些信息綜合為一個連貫的回應。它們可能無法解釋電動車的普及如何改善空氣品質，進而可能影響公共交通規劃，用戶可能收到一個碎片化的答案，未能充分捕捉這些主題之間複雜的相互依賴關係。&lt;/p>&lt;/blockquote>
&lt;h2 id="lightrag-的提出與核心挑戰">LightRAG 的提出與核心挑戰
&lt;/h2>&lt;hr>
&lt;hr>
&lt;hr>
&lt;hr></description></item><item><title>Re2G 論文導讀 — Retrieve, Rerank, Generate 框架解析與應用</title><link>https://Dandelionlibra.github.io/post/note/re2g-paper-review/</link><pubDate>Tue, 22 Jul 2025 01:31:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/note/re2g-paper-review/</guid><description>&lt;blockquote>
&lt;p>本文整理自：&lt;a class="link" href="https://arxiv.org/abs/2207.06300" target="_blank" rel="noopener"
>Re2G: Retrieve, Rerank, Generate&lt;/a>&lt;br>
作者：Michael Glass, Gaetano Rossiello, Md Faisal Mahbub Chowdhury, Ankita Rajaram Naik, Pengshan Cai, Alfio Gliozzo&lt;br>
發佈於 arXiv，2022年7月&lt;/p>&lt;/blockquote>
&lt;h1 id="摘要">摘要
&lt;/h1>&lt;p>大型 Transformer 模型在處理複雜任務時雖然表現強大，但在應對知識密集型任務時，仍會面臨顯著的計算成本與記憶體限制。此研究指出，非參數記憶和檢索技術能有效解決這些挑戰。&lt;br>
基於此，Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 模型應運而生，它創新地整合了神經初始檢索與重新排序機制，並以 BART 框架為基礎進行序列到序列的生成。Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 的核心創新之處在於其獨特的重新排序功能。這使得模型能夠智慧地整合來自不同檢索源的結果，即使這些源的分數不可比較，例如同時融合傳統的 BM25 算法與神經檢索（如密集段落檢索，DPR）。透過引入重排序 (Reranker) 組件，模型得以統一處理並最大化初始候選池的質量。此外，Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 還引入了&lt;strong>線上知識蒸餾方法&lt;/strong>，實現了整個檢索與生成管道的端到端訓練。這種訓練方式將系統的所有組件串接成一個整體模型，直接以最終目標作為損失函數進行優化，從而無需分階段訓練，有效提升了系統的整體性能。&lt;/p>
&lt;p>※ 在機器學習領域，「端到端訓練」（End-to-End Training）指的是將整個系統的所有組件（如檢索、重排序、生成）串接為一個整體模型，直接以最終目標（如生成正確答案）作為損失函數，反向傳播優化所有參數。這種方式不需分階段分別訓練各模組，而是讓模型自動協調各部分，最大化整體性能。&lt;/p>
&lt;hr>
&lt;h1 id="基本架構介紹">基本架構介紹
&lt;/h1>&lt;p>RAG（Retrieval-Augmented Generation）與 Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G（Retrieve, Rerank, Generate）架構模組如下圖所示：&lt;br>
&lt;img src="https://ar5iv.labs.arxiv.org/html/2207.06300/assets/x1.png"
loading="lazy"
alt="RAG 基本架構圖"
>&lt;br>
圖 1. RAG 基本架構圖：RAG 基礎流程包含檢索器與生成器，將查詢與檢索到的外部知識片段一同輸入生成模型，產生最終回答。&lt;/p>
&lt;p>&lt;img src="https://ar5iv.labs.arxiv.org/html/2207.06300/assets/x2.png"
loading="lazy"
alt="RAG 重排序架構圖"
>&lt;br>
圖 2. Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G (Retrieve, Rerank, Generate) 架構圖：進階版本在檢索後加入重排序（Rerank）模組，對候選片段進行排序優化，提升檢索結果品質與生成相關性。&lt;/p>
&lt;p>&lt;strong>RAG 架構&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>檢索器（Retriever）：從語料庫中檢索相關段落&lt;/li>
&lt;li>生成器（Generator）：基於檢索結果生成回答&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 架構&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>初始檢索層（Initial Retrieval Layer）：神經檢索 + 關鍵字檢索&lt;/li>
&lt;li>重排序層（Reranker Layer）：融合多種檢索結果並重排序&lt;/li>
&lt;li>生成層（Generation Layer）：基於重排序結果生成最終輸出&lt;/li>
&lt;/ol>
&lt;p>這種分層設計使 Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 能靈活結合多種檢索技術，並透過重排序提升候選質量，最終增強生成效果。&lt;/p>
&lt;h1 id="re2g-核心概念與創新突破">Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 核心概念與創新突破
&lt;/h1>&lt;p>Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 的兩大創新突破，分別體現在多源檢索結果的融合能力與創新的端到端訓練策略。
首先，Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 的重排序方法打破了傳統檢索分數不可比的限制，能夠有效融合來自不同檢索機制的候選結果。其次，作者提出一種改良的知識蒸餾策略，使得整個系統能僅依賴目標序列輸出進行訓練，實現從初始檢索、重排序到序列生成端到端改善。這項設計解決了當重排序器主導運算後，查詢編碼器將無法從生成損失中獲得有效梯度的問題。透過在線知識蒸餾，Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 讓重排序器成為查詢編碼器的指導，重新建立了梯度流通路，深化多模組系統間的互動訓練。&lt;/p>
&lt;p>主要流程是從大型語料庫中&lt;strong>檢索相關段落&lt;/strong>，隨後對這些初步檢索到的段落&lt;strong>進行精確的重排序&lt;/strong>，最後基於重排序後的結果&lt;strong>生成最終的輸出序列&lt;/strong>。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>檢索相關段落&lt;/strong>&lt;br>
從大型語料庫中，透過高效的初始檢索模型（如 DPR 或 BM25）篩選出與查詢相關的候選段落。&lt;br>
&lt;img src="https://ar5iv.labs.arxiv.org/html/2207.06300/assets/x4.png"
loading="lazy"
alt="雙編碼器表示模型 — 初始檢索器（DPR）"
>&lt;br>
&lt;em>圖 3：表示模型（Bi-Encoder）運作方式：查詢（Query）與段落（Passage）分別透過獨立的 BERT 編碼器轉換為向量表示（r&lt;!-- raw HTML omitted -->q&lt;!-- raw HTML omitted --> 與 r&lt;!-- raw HTML omitted -->p&lt;!-- raw HTML omitted -->），之後透過 向量內積（Inner Product） 計算相似度，作為檢索排序的依據。&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>精確的重排序&lt;/strong>&lt;br>
對初步檢索到的候選段落，使用互動模型（Reranker）進行相關性重排序。&lt;br>
此階段的關鍵創新在於能夠&lt;strong>整合多種來源的檢索結果&lt;/strong>，例如：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>BM25&lt;/strong>：基於關鍵字的傳統檢索，分數反映字詞匹配頻率&lt;/li>
&lt;li>&lt;strong>DPR&lt;/strong>：基於語意向量的神經檢索，分數來自內積相似度&lt;/li>
&lt;/ul>
&lt;p>然而，這些檢索分數性質不同，直接比對會產生偏誤。&lt;br>
為此，Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 引入 &lt;strong>獨立的 Reranker 模組&lt;/strong>，將不同檢索來源的候選進行&lt;strong>統一評分&lt;/strong>，重排序後產出可比較的結果。&lt;br>
&lt;img src="https://ar5iv.labs.arxiv.org/html/2207.06300/assets/x3.png"
loading="lazy"
alt="互動模型 — 重排序器（Reranker）"
>&lt;br>
&lt;em>圖 4：互動模型（Interaction Model）運作方式 — 查詢與段落聯合輸入 BERT，透過交叉注意力捕捉語義關聯，最終由 [CLS] 預測相關性分數。&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>基於重排序結果的生成&lt;/strong>&lt;br>
最終，將排序靠前的 Top-K 段落，與查詢共同輸入到序列生成模型（如 BART）中，生成目標回答或回應。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="re2g-模型架構詳解">Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 模型架構詳解
&lt;/h2>&lt;h3 id="初始檢索層dpr與bm25的協同作用">初始檢索層：DPR與BM25的協同作用
&lt;/h3>&lt;p>目的是建立一個包含潛在相關段落的候選池，在此階段結合了兩種互補的檢索方法：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>DPR (Dense Passage Retrieval) 密集段落檢索：DPR 採用雙編碼器表示模型，其中查詢編碼器和段落編碼器（兩者均基於 BERT）獨立生成查詢和段落的表示向量。這種獨立編碼的設計允許在檢索前預先計算語料庫中所有段落的向量，並使用近似最近鄰 (ANN) 索引。在推斷時，輸入查詢會使用 DPR 查詢編碼器進行編碼，並從 HNSW 索引中快速檢索出最相關的 Top-12 段落。  &lt;/p>
&lt;/li>
&lt;li>
&lt;p>BM25：作為一種傳統的基於關鍵字的檢索方法，BM25 擅長捕捉精確的詞彙匹配。在推斷時，查詢也會傳遞給 BM25 搜索（具體使用 Anserini 庫），並收集 Top-12 的 BM25 結果。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 在此層結合使用了 DPR (一種神經「表示模型」) 和 BM25 (一種詞彙匹配方法)。這兩種方法互補，共同產生一個初步的候選段落池，這兩種方法檢索到的段落隨後會被合併，為後續的重排序階段提供一個更全面且多樣化的候選集。&lt;/p>
&lt;blockquote>
&lt;p>舉例：&lt;br>
&lt;strong>DPR 的檢索結果：&lt;/strong>
DPR 模型會將文檔庫中的所有段落預先編碼成向量，並儲存在一個向量資料庫中，當有一個查詢進來時，DPR 會將這個查詢也編碼成一個向量，然後，它會在向量資料庫中進行「最近鄰搜索」，找出與查詢向量最相似的 K 個段落向量，這些被找出來的 K 個段落，就是 DPR 的「檢索結果」，它們是實際的文本段落。&lt;br>
例如：「尼加拉瀑布位於加拿大和美國的邊界。」&lt;/p>
&lt;p>&lt;strong>BM25 的檢索結果：&lt;/strong>
BM25 演算法會根據查詢中的關鍵字，在文檔庫中計算每個段落與查詢的相關性分數，它會根據這些分數，找出相關性最高的 K 個段落，這些被找出來的 K 個段落，就是 BM25 的「檢索結果」，它們也是實際的文本段落。&lt;br>
例如：「尼加拉瀑布是世界著名的瀑布。」&lt;/p>
&lt;p>合併指的是將這兩個獨立檢索器（DPR 和 BM25）各自找出來的候選段落列表結合起來，形成一個更大的、包含更多潛在相關段落的集合。&lt;/p>
&lt;p>例如：&lt;br>
DPR 可能檢索到段落 A, B, C, D, E。&lt;br>
BM25 可能檢索到段落 C, F, G, H, I。&lt;br>
合併後，初始候選集就可能包含 A, B, C, D, E, F, G, H, I。&lt;/p>&lt;/blockquote>
&lt;h3 id="重排序層互動模型的強大能力">重排序層：互動模型的強大能力
&lt;/h3>&lt;p>重排序層的核心目的是精煉初始檢索結果的排名，並實現來自不同檢索方法結果的合併。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>模型類型&lt;/strong>：Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 使用基於 Nogueira 和 Cho 序列對分類方法的「互動模型」進行重排序。&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;hr>
&lt;!-- raw HTML omitted -->
&lt;hr>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>機制&lt;/strong>： 在互動模型中，查詢和段落會作為一個整體輸入到 BERT 變換器中，模型會在兩個序列的所有詞元上共同應用交叉注意力機制，從而捕捉查詢和段落之間更深層次的交互關係。  &lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>優勢&lt;/strong>：透過使用互動模型對來自表示模型的 Top-N 段落進行重排序，Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 能夠同時獲得兩種模型類型的優勢：互動模型帶來的更高準確性（因其能進行更細緻的交叉注意力計算），以及表示模型帶來的可擴展性（因其允許高效的初始檢索）。這種設計模式在許多大規模資訊檢索系統中非常有效，平衡了對大型語料庫的快速初始檢索與對較小候選集的精細排名。  &lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>初始化與推斷&lt;/strong>： 重排序器從 NBoost 在 MS MARCO 數據集上訓練的 BERT 模型初始化。在推斷時，從初始檢索層合併後的段落集會傳遞給重排序器進行評分，並選出 Top-5 的段落供生成器使用。  &lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="生成層基於bart的序列生成">生成層：基於BART的序列生成
&lt;/h3>&lt;p>生成層負責根據重排序後的段落和查詢生成最終的目標輸出序列。  &lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>基礎模型&lt;/strong>：Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 使用基於 BART 的序列到序列生成模型，具體是 $BART_{LARGE}$。BART 結合了雙向編碼器（如 BERT）和自回歸解碼器（如 GPT）的優勢，使其非常適合序列到序列任務，並能有效地整合檢索到的資訊。這種選擇利用了現有的穩健生成模型，並透過外部知識增強了它們的能力。  &lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>生成器輸入與輸出&lt;/strong>：來自重排序器的 Top-5 段落會與原始查詢結合，作為 $BART_{LARGE}$ 的輸入以生成輸出。BART 生成的五個輸出序列隨後會根據重排序器分數的 softmax 進行加權，以產生最終的輸出。這個過程在 RAG 中稱為邊緣化 (marginalization)，它確保了檢索到的相關性信息能夠有效指導最終的生成。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="四階段訓練方法與線上知識蒸餾">四階段訓練方法與線上知識蒸餾
&lt;/h2>&lt;h3 id="第一階段dpr-訓練">第一階段：DPR 訓練
&lt;/h3>&lt;p>訓練數據由查詢、正向段落（來自真實標籤的來源資訊）以及「硬負向」段落（從 BM25 檢索但非真實標籤的段落）的三元組組成，這些實例會被批次處理，並且批次中其他實例的正向和硬負向段落會被用作當前實例的「批次負向」，DPR 雙編碼器模型隨後會為每個查詢提供其對正向、硬負向和批次負向段落的概率分佈。此階段的損失函數是正向段落的負對數似然，完成此階段訓練後，語料庫中的所有段落都會使用分層可導航小世界圖 (HNSW) 結合 FAISS 庫進行索引，以便後續高效檢索。&lt;/p>
&lt;h3 id="第二階段生成訓練">第二階段：生成訓練
&lt;/h3>&lt;p>此階段的訓練目標是擴展查詢編碼器的訓練，並訓練 BART&lt;!-- raw HTML omitted -->LARGE&lt;!-- raw HTML omitted --> 序列到序列模型以生成最終的目標序列輸出。這個訓練過程與 Lewis 等人描述的 RAG 模型生成訓練方法一致。&lt;/p>
&lt;h3 id="第三階段重排序訓練">第三階段：重排序訓練
&lt;/h3>&lt;p>重排序器的獨立訓練始於收集訓練集上來自 DPR 和 BM25 的初始檢索結果，這些結果隨後會被合併，並作為重排序器的訓練數據。由於某些數據集可能存在多個正向段落，因此此階段採用的損失函數是這些正向段落負對數似然之和。&lt;/p>
&lt;h3 id="第四階段端到端訓練">第四階段：端到端訓練
&lt;/h3>&lt;p>端到端訓練帶來了一個特殊挑戰：在 Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 中，重排序器的分數而非初始檢索分數用於加權每個序列在生成中的影響。這意味著重排序器可以直接透過目標輸出的真實標籤進行訓練，但查詢編碼器的梯度將為零，因為邊緣化過程不再直接依賴於查詢和段落表示向量的內積。  &lt;/p>
&lt;p>為了解決這個問題，Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 引入了一種新穎的線上知識蒸餾應用。在這種方法中，重排序器作為「教師模型」，為 DPR「學生模型」提供軟標籤。這種知識蒸餾是「線上」發生的，即在重排序器訓練的同時進行，實現了知識從一種架構（互動模型）到另一種架構（表示模型）的轉移。初始檢索（DPR）的損失函數是其在檢索到的段落上給出的概率分佈與重排序器在相同段落上給出的概率分佈之間的 KL 散度。為了平滑這些分佈、防止過度損失並穩定訓練，模型使用了溫度超參數 (T)。這種方法不僅提供了正向和負向實例的信號，還提供了「負向程度」的信號，並且能夠利用更多段落進行訓練（DPR 檢索 12 個段落，而生成只使用 Top-5），從而提供了比二元標籤更豐富的訓練信號。&lt;/p>
&lt;hr>
&lt;h2 id="實驗結果與性能分析">實驗結果與性能分析
&lt;/h2>&lt;p>此部分尚未撰寫。&lt;/p>
&lt;hr>
&lt;h2 id="結論">結論
&lt;/h2>&lt;p>Re&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted -->G 在槽填充、問答、事實核查和對話等任務中，無論是檢索還是端到端性能都得到了實質性提升。&lt;/p>
&lt;p>本研究的關鍵成果包括：&lt;/p>
&lt;ul>
&lt;li>重排序器的有效性。  &lt;/li>
&lt;li>線上知識蒸餾的成功。  &lt;/li>
&lt;li>多源檢索的益處。&lt;/li>
&lt;/ul>
&lt;h2 id="reference">Reference
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://ar5iv.labs.arxiv.org/html/2207.06300#:~:text=The%20third%20solution%20is%20our,excessive%20loss%20and%20stabilize%20training" target="_blank" rel="noopener"
>Re2G: Retrieve, Rerank, Generate-ar5iv 可視化版本&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>三種 RAG 架構比較與應用解析 — Naive、Advanced、Modular RAG 差異整理</title><link>https://Dandelionlibra.github.io/post/note/rag-type-compare-note/</link><pubDate>Mon, 21 Jul 2025 09:16:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/note/rag-type-compare-note/</guid><description>&lt;h1 id="三種-rag-技術架構比較naive-ragadvanced-rag-與-modular-rag">三種 RAG 技術架構比較：Naive RAG、Advanced RAG 與 Modular RAG
&lt;/h1>&lt;p>本文比較《Retrieval-Augmented Generation for Large Language Models: A Survey》中提出的三種檢索增強生成（RAG）技術架構：Naive RAG、Advanced RAG 和 Modular RAG。RAG 旨在結合大型語言模型（LLM）的內部知識與外部資料檢索，以提升事實正確性與時效性。這三種架構代表了 RAG 技術的演進路徑，各自引入不同模組與策略來克服先前架構的侷限。本文將從架構組成、實作方式、技術細節、應用場景與優劣比較等面向，深入剖析三類架構的差異與適用性。&lt;/p>
&lt;hr>
&lt;h2 id="架構組成與流程差異">架構組成與流程差異
&lt;/h2>&lt;h3 id="naive-rag">Naive RAG
&lt;/h3>&lt;p>最早期且基礎的 RAG 架構，僅包含索引（Indexing）、檢索（Retrieval）與生成（Generation）三個串連模組。流程為：資料向量化 → 檢索前 $K$ 個相關片段 → 查詢與檢索結果一併餵給 LLM 產生回答。此架構流程簡單、模組單一，缺乏查詢優化或反饋機制，適合快速原型開發。&lt;/p>
&lt;p>&lt;img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/e0/d6/naive-rag.png"
loading="lazy"
alt="Naive RAG 架構圖"
>&lt;/p>
&lt;h3 id="advanced-rag">Advanced RAG
&lt;/h3>&lt;p>在 Naive 基礎上增加前處理與後處理模組，如查詢優化、重排序、內容過濾/壓縮等。流程仍為索引→檢索→生成，但在檢索前後插入優化步驟，提升檢索品質與生成相關性。組件包含查詢改寫、混合檢索、重排序等，能針對性強化檢索與生成階段。&lt;/p>
&lt;p>&lt;img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/8f/cb/advances-rag.png"
loading="lazy"
alt="Advanced RAG 架構圖"
>&lt;/p>
&lt;h3 id="modular-rag">Modular RAG
&lt;/h3>&lt;p>最新階段，強調積木式模組化設計。除繼承前述流程外，允許多輪檢索-生成、平行資訊融合、自適應流程等。可靈活增減如網路搜尋、長程記憶、路由決策等模組，流程可重組、迭代或分支，適應複雜多變的任務需求。&lt;/p>
&lt;p>&lt;img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/a7/e6/modular-rag.component.crop-16by9-m.ts=1740501066286.png/content/adobe-cms/us/en/think/topics/rag-techniques/jcr:content/root/table_of_contents/body-article-8/image_1228195012"
loading="lazy"
alt="Modular RAG 架構圖"
>&lt;/p>
&lt;hr>
&lt;h2 id="實作方式與系統特性">實作方式與系統特性
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>Naive RAG&lt;/strong>：實作最直接，僅需嵌入模型、向量資料庫與 LLM。模組線性串接，無需微調，部署維護成本低，適合簡單應用。&lt;/li>
&lt;li>&lt;strong>Advanced RAG&lt;/strong>：需引入查詢優化、重排序等模組，常用 LlamaIndex、LangChain 等框架。系統複雜度提升，需調校多個子系統，適合中等複雜度任務。&lt;/li>
&lt;li>&lt;strong>Modular RAG&lt;/strong>：高度模組化，常用流水線編排框架。每個功能獨立封裝，系統可為有向圖結構，便於擴充與維護，但開發協調成本高。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="核心技術細節">核心技術細節
&lt;/h2>&lt;h3 id="資料預處理與嵌入">資料預處理與嵌入
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Naive RAG&lt;/strong>：文本清洗、切分、嵌入，建立向量索引，重點在語義表示。&lt;/li>
&lt;li>&lt;strong>Advanced RAG&lt;/strong>：細粒度切分、滑動視窗、metadata 標註、混合嵌入（密集+稀疏），提升檢索覆蓋率與精確性。&lt;/li>
&lt;li>&lt;strong>Modular RAG&lt;/strong>：動態資料處理，可即時抓取新資料、多模態資料、記憶模組自我增強，嵌入策略多元且可演化。&lt;/li>
&lt;/ul>
&lt;h3 id="檢索策略與查詢優化">檢索策略與查詢優化
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Naive RAG&lt;/strong>：單輪語義相似度檢索，無查詢優化或多輪交互。&lt;/li>
&lt;li>&lt;strong>Advanced RAG&lt;/strong>：查詢重寫/擴展、多次/混合檢索、重排序與過濾，提升檢索準確率與覆蓋率。&lt;/li>
&lt;li>&lt;strong>Modular RAG&lt;/strong>：自適應多階段檢索、路由決策、平行多查詢、遞歸式檢索，根據任務動態調度檢索策略。&lt;/li>
&lt;/ul>
&lt;h3 id="上下文融合與資訊增強">上下文融合與資訊增強
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Naive RAG&lt;/strong>：直接拼接查詢與檢索內容，無額外處理，易受雜訊干擾。&lt;/li>
&lt;li>&lt;strong>Advanced RAG&lt;/strong>：重排序、壓縮、過濾、明確引導模型引用檢索內容，提升訊息品質。&lt;/li>
&lt;li>&lt;strong>Modular RAG&lt;/strong>：多步融合、示範-搜索-預測、動態記憶、事後校驗，深度整合外部知識與模型推理。&lt;/li>
&lt;/ul>
&lt;h3 id="回答生成與控制">回答生成與控制
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Naive RAG&lt;/strong>：LLM 直接生成，控制力弱，易出現幻覺或拼貼。&lt;/li>
&lt;li>&lt;strong>Advanced RAG&lt;/strong>：提示工程、微調、反饋迴路、生成後過濾，強化可靠性與安全性。&lt;/li>
&lt;li>&lt;strong>Modular RAG&lt;/strong>：示範模組、迭代生成、後處理校驗、用戶反饋迴路，實現嚴謹的生成管控。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="適用場景與限制">適用場景與限制
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>Naive RAG&lt;/strong>：適合原型、FAQ、內部知識庫等低複雜度場景，開發快但不適合高精度或多步推理任務。&lt;/li>
&lt;li>&lt;strong>Advanced RAG&lt;/strong>：適用於醫療、法律、教育等知識密集型問答，能處理較大規模知識庫，但資源需求與維護成本較高。&lt;/li>
&lt;li>&lt;strong>Modular RAG&lt;/strong>：適合大型企業、跨領域系統、需多階段推理或多源資訊整合的場景，擴展性與維護性最佳，但開發複雜度與初始成本高。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="優劣比較">優劣比較
&lt;/h2>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>架構&lt;/th>
&lt;th>實用性&lt;/th>
&lt;th>可擴展性&lt;/th>
&lt;th>維護成本&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Naive RAG&lt;/td>
&lt;td>高（易用）&lt;/td>
&lt;td>低～中&lt;/td>
&lt;td>低&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Advanced RAG&lt;/td>
&lt;td>中（需專業）&lt;/td>
&lt;td>中～高&lt;/td>
&lt;td>中&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Modular RAG&lt;/td>
&lt;td>低（複雜）&lt;/td>
&lt;td>極高&lt;/td>
&lt;td>高（初始），低（局部維護）&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>&lt;strong>Naive RAG&lt;/strong>：簡單易用、成本低，但遇到複雜任務易達天花板。&lt;/li>
&lt;li>&lt;strong>Advanced RAG&lt;/strong>：性能與複雜度平衡，適合多數專業應用，維護需專業投入。&lt;/li>
&lt;li>&lt;strong>Modular RAG&lt;/strong>：彈性與擴展性最強，適合高端需求，但開發與協調成本高。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="結論">結論
&lt;/h2>&lt;p>三種 RAG 架構各有適用場景與優劣。Naive RAG 適合快速原型與簡單應用，Advanced RAG 適合專業領域與中大型知識庫，Modular RAG 則為高複雜度、需長期演化的系統提供最佳解決方案。選擇何種架構，應根據實際需求、資源與長期維護考量權衡取捨。&lt;/p>
&lt;h2 id="reference">Reference
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://arxiv.org/abs/2312.10997" target="_blank" rel="noopener"
>Retrieval-Augmented Generation for Large Language Models: A Survey&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.thecloudgirl.dev/blog/three-paradigms-of-retrieval-augmented-generation-rag-for-llms#:~:text=,on%20embeddings%20from%20language%20models" target="_blank" rel="noopener"
>Three Paradigms of Retrieval-Augmented Generation (RAG) for LLMs&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.ibm.com/think/topics/rag-techniques#:~:" target="_blank" rel="noopener"
>RAG Techniques | IBM Think&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>檢索增強大型語言模型綜述 — RA-LLMs 系統性回顧與應用解析</title><link>https://Dandelionlibra.github.io/post/note/rag-llms-survey-note/</link><pubDate>Sun, 20 Jul 2025 08:50:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/note/rag-llms-survey-note/</guid><description>&lt;blockquote>
&lt;p>本文整理自：&lt;a class="link" href="https://arxiv.org/abs/2405.06211" target="_blank" rel="noopener"
>A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models&lt;/a>&lt;br>
作者：Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, Qing Li&lt;br>
發佈於 arXiv，2024年5月&lt;/p>&lt;/blockquote>
&lt;h1 id="摘要">摘要
&lt;/h1>&lt;p>大型語言模型（LLMs）雖展現強大生成能力，但受限於內部知識與幻覺問題。檢索增強生成（Retrieval-Augmented Generation;RAG）透過即時檢索外部資訊，提升回應的可靠性與時效性。本文整理 RA-LLMs 的架構、訓練策略與應用，並探討其面臨的挑戰與未來發展，展現檢索對提升 LLM 實用性的關鍵價值。&lt;/p>
&lt;h1 id="前言">前言
&lt;/h1>&lt;p>檢索增強生成（RAG）技術透過結合資訊檢索與大型語言模型（LLMs），補足模型知識不足與幻覺問題，近年受到廣泛關注。LLMs 雖具強大生成能力，卻常受限於知識時效與專領域應用，而 RA-LLMs 則透過檢索外部資料提升生成品質。&lt;/p>
&lt;h1 id="背景">背景
&lt;/h1>&lt;h2 id="大型語言模型">大型語言模型
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>應用&lt;/p>
&lt;ul>
&lt;li>在特定資料集上進行微調，LLM 可以適應各種下游任務，使其能夠專注於特定領域或應用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>架構:&lt;/p>
&lt;ul>
&lt;li>Encoder-only 模型，雙向編碼，可同時考慮單詞左右語境。&lt;br>
ex. BERT&lt;/li>
&lt;li>Decoder-only 模型，單向生成（左至右），根據前文預測下個字元。&lt;br>
ex. GPT&lt;/li>
&lt;li>Encoder-Decoder 模型，將輸入編碼後，再由解碼器生成對應輸出。&lt;br>
ex. T5&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="提示學習">提示學習
&lt;/h2>&lt;h3 id="提示工程prompt-engineering">提示工程（Prompt Engineering）
&lt;/h3>&lt;p>因為 LLM 的參數量通常非常龐大，因此提示學習的發展可使 LLM 不需為了特定任務進行大量微調，就可以實現各項任務。&lt;br>
缺點：當缺乏專業領域知識時，生成結果可能不夠精確。&lt;/p>
&lt;h3 id="上下文學習in-context-learning-icl">上下文學習（In-Context Learning, ICL）
&lt;/h3>&lt;p>為提示學習的一種形式，透過在提示中提供範例示範，讓 LLM 觀察並學習任務模式。&lt;br>
缺點：成效高度依賴範例品質、當缺乏必要知識或資訊時，可能導致生成結果不理想。&lt;/p>
&lt;p>為克服這些問題，發展出 RAG（檢索增強生成）技術，RAG 結合檢索與生成，提升 LLM 在多任務中的表現與適應性。&lt;/p>
&lt;h1 id="內文">內文
&lt;/h1>&lt;p>LLMs 時代的 RAG 架構大致包含檢索、產生和增強三個主要流程。&lt;/p>
&lt;p>&lt;img src="https://ar5iv.labs.arxiv.org/html/2405.06211/assets/x2.png"
loading="lazy"
alt="RAG 系統總覽"
>&lt;br>
&lt;em>圖 1：RAG 系統總覽，涵蓋檢索、生成與增強三大流程。來源：原論文&lt;/em>&lt;/p>
&lt;p>&lt;img src="https://ar5iv.labs.arxiv.org/html/2405.06211/assets/x3.png"
loading="lazy"
alt="RAG 系統細節流程"
>&lt;br>
&lt;em>圖 2：RAG 在 RA-LLM 中的流程圖，展示各模組間的互動。來源：原論文&lt;/em>&lt;/p>
&lt;h2 id="retrieval">Retrieval
&lt;/h2>&lt;p>RAG 旨在從外部知識源提供關鍵訊息給 LLM。&lt;/p>
&lt;h3 id="retriever-type">Retriever Type
&lt;/h3>&lt;p>依照資訊編碼區分。&lt;/p>
&lt;ul>
&lt;li>稀疏檢索（Sparse Retrieval）：直接匹配詞彙並依頻率排名。&lt;/li>
&lt;li>稠密檢索（Dense Retrieval）：將查詢與文檔嵌入為向量，透過語意相似度檢索。&lt;/li>
&lt;/ul>
&lt;h3 id="retrieval-granularity">Retrieval Granularity
&lt;/h3>&lt;p>檢索單位的選擇對效能與計算成本有重大影響。&lt;/p>
&lt;ul>
&lt;li>Chunk(passages): 包含緊湊且完整的資訊，冗餘和不相關性較少，是 RAG 中主流的檢索文本粒度。&lt;/li>
&lt;li>Token: 實現更快的搜尋，但會給資料庫儲存帶來更多負擔。適用於需要稀有模式或領域外資料的情況。&lt;/li>
&lt;li>Entity: 實體檢索是從知識而非語言的角度檢索，對於以實體為中心的任務更有效，並且與詞元檢索相比，在空間上更高效。&lt;/li>
&lt;/ul>
&lt;h3 id="retrieval-enhancement-strategies">Retrieval Enhancement strategies
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>檢索前優化（Pre-retrieval）&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Query Expansion (查詢擴展)：透過加入相關詞彙或概念來擴大原始查詢的範圍。例如，利用大型語言模型 (LLM) 生成偽文件，並從中提取相關資訊來擴展查詢，有助於消除歧義並引導檢索器。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Query Rewrite (查詢重寫)：旨在重新彌合原始查詢，使其更適合檢索。這可能涉及澄清查詢意圖、使其更精確，或是將其轉換為檢索功能更容易理解的形式。例如，利用 LLM 將原始問題重寫為更利於檢索的版本。&lt;br>
舉例，&lt;strong>多次&lt;/strong>詢問模型他的檢索資料是否正確。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Query Augmentation (查詢增強)：將原始查詢與初步生成的內容結合，形成一個新的查詢。這種策略可以增加查詢與潛在相關文件之間的詞彙和語義重疊，有助於檢索出更多有助於答案生成的資訊。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>檢索後優化（Post-retrieval）&lt;/p>
&lt;ul>
&lt;li>
&lt;p>重排序與過濾&lt;br>
對檢索到的文件進行重新排序，將最相關的資訊排在前面，並過濾掉不相關或低品質的文件。例如，透過不同的檢索方法組裝文件並進行重排序，以提升檢索結果的穩健性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>雜訊過濾與整合&lt;br>
處理檢索到的資訊中可能存在的雜訊或不相關內容，以避免其對生成過程產生負面影響。同時，將清洗過的資訊有效地整合進生成模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>壓縮與摘要&lt;br>
針對檢索到的長篇文件，進行壓縮或生成摘要，以解決大型語言模型輸入長度限制的問題。例如，將檢索到的文件處理成文本摘要，再用於模型生成。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="database">Database
&lt;/h3>&lt;p>RA-LLM 的檢索資料庫可為封閉式或開放式來源。&lt;/p>
&lt;ul>
&lt;li>封閉式資料庫:
通常以鍵值對 (key-value pairs) 的形式儲存知識。&lt;/li>
&lt;li>開放式資料庫:
利用搜尋引擎（如 Bing、Google）獲取即時資訊。&lt;/li>
&lt;/ul>
&lt;h2 id="生成generation">生成（Generation）
&lt;/h2>&lt;p>生成模組的設計高度依賴於下游任務需求，因而得以適應不同的任務需求。&lt;/p>
&lt;h3 id="可調參數生成器白箱parameter-accessible-generators">可調參數生成器（白箱，Parameter-Accessible Generators）
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>Encoder-Decoder&lt;/p>
&lt;ul>
&lt;li>擁有獨立的編碼器（Encoder）與解碼器（Decoder），分別處理輸入與生成的目標。&lt;/li>
&lt;li>Encoder 先將輸入編碼為上下文表示，Decoder 以 Cross-Attention 讀取 Encoder 輸出，逐步生成結果。&lt;/li>
&lt;li>模型的目標是「根據編碼後的輸入與先前生成的結果，預測下一個 token」。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>輸入：請介紹 Transformer。
Encoder 編碼後 → [內部上下文表示]
Decoder 讀取表示 → 生成：Transformer 是一種...
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Decoder-only&lt;/p>
&lt;ul>
&lt;li>沒有獨立的編碼器。&lt;/li>
&lt;li>輸入（如問題、提示） 和 目標（要生成的內容） 會被串接成同一序列，並從左到右進行處理。&lt;/li>
&lt;li>模型的目標是學會「根據前面內容，預測下一個 token」。&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>輸入：請介紹 Transformer。
模型看到的內容：請介紹 Transformer。&amp;lt;接著是生成的回答...&amp;gt;
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ul>
&lt;h3 id="不可調參數生成器黑箱parameter-inaccessible-generators">不可調參數生成器（黑箱，Parameter-Inaccessible Generators）
&lt;/h3>&lt;p>無法直接修改模型本身，且難以進行微調，因此更側重於優化檢索和增強的過程。它們的目標是透過為輸入 (prompts) 提供更優質的知識、指導或範例來增強 Generator 的性能。&lt;/p>
&lt;h2 id="增強augmentation">增強（Augmentation）
&lt;/h2>&lt;h3 id="input-layer-integration">Input-Layer Integration:
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>串聯整合&lt;/strong>：如 In-Context RALM (Ram et al., 2023)，將原始輸入與所有檢索文件串聯為單一序列輸入生成模型。&lt;/p>
&lt;ul>
&lt;li>問題：輸入長度易超過模型處理上限，需移除部分詞元，可能導致資訊遺失。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>平行整合&lt;/strong>：如 FID (Izacard and Grave, 2021b)、Atlas、REPLUG，將每個檢索文件獨立編碼，僅在後續步驟聚合結果。&lt;/p>
&lt;ul>
&lt;li>優點：更能擴展至大量上下文，減少資訊丟失風險。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>通常，大多數基於黑盒生成的 RAG 方法都採用此法，因為生成模型的中間層和輸出分佈都無法存取。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="output-layer-integration">Output-Layer Integration:
&lt;/h3>&lt;p>一種後處理 (post-hoc) 的檢索增強方式，它不直接干預生成模型的內部運作或其生成過程，而是在模型產生初步結果之後，才將檢索到的資訊與這些結果進行結合。&lt;/p>
&lt;h3 id="intermediate-layer-integration">Intermediate-Layer Integration:
&lt;/h3>&lt;p>在生成模型內部的中間層注入檢索資訊，相較於輸入層與輸出層整合，屬於 半參數式（Semi-parametric） 的強化方式，具有更高的資訊融合深度與潛力。&lt;/p>
&lt;h3 id="34retrieval-augmentation-necessity-and-frequency">3.4.Retrieval Augmentation Necessity and Frequency
&lt;/h3>&lt;p>基於 LLM 的生成中，檢索操作旨在補充知識以增強生成。儘管檢索增強模型前景光明，但若不加區分地使用不相關的段落進行增強，可能會覆蓋 LLM 已有的正確知識，導致錯誤回應，甚至使幻覺率翻倍。因此，對於檢索增強型 LLM (RA-LLMs) 來說，&lt;strong>準確回憶先驗知識並僅在必要時選擇性地整合檢索資訊&lt;/strong>至關重要，這是實現穩健 RA-LLMs 的關鍵。&lt;/p>
&lt;h4 id="檢索必要性判斷">檢索必要性判斷
&lt;/h4>&lt;p>大多數方法基於 LLM 的初步答案或內部推理結果來判斷是否需要檢索：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>特殊標記控制&lt;/strong>：如 Self-RAG，引入特殊標記評估檢索必要性並控制行為。&lt;/li>
&lt;li>&lt;strong>迭代提示決策&lt;/strong>：設計迭代提示決定生成中是否需要額外資訊。&lt;/li>
&lt;li>&lt;strong>基於信賴度 (Logits Confidence)&lt;/strong>：傳統 RAG 中透過評估生成模型輸出的 logits 信賴度來判斷。如 FLARE，當 logits 低於閾值時動態觸發 RAG。&lt;/li>
&lt;li>&lt;strong>協同檢測&lt;/strong>：如 SlimPLM，利用輕量級代理模型生成「啟發式答案」檢測 LLM 缺失知識，並用於查詢重寫以促進檢索。&lt;/li>
&lt;/ul>
&lt;h4 id="檢索頻率-retrieval-frequency">檢索頻率 (Retrieval Frequency)
&lt;/h4>&lt;p>檢索頻率（或稱檢索步長）是決定生成過程中檢索使用程度的重要設計考量，影響模型的效率和有效性。當不考慮檢索必要性時，檢索頻率通常是預定義和固定的，主要有三種設定：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>一次性檢索 (One-time retrieval)&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>方式&lt;/strong>：在生成過程開始時只調用一次檢索功能，檢索所有所需資訊，然後提供給生成模型。&lt;/li>
&lt;li>&lt;strong>適用場景&lt;/strong>：外部資料庫資訊需求對 LLM 來說很明確的情況。&lt;/li>
&lt;li>&lt;strong>限制&lt;/strong>：對於需要長篇輸出的任務（如開放域摘要），預先檢索的文件可能不足以支持整個生成序列，需要生成中進行檢索操作。&lt;/li>
&lt;li>&lt;strong>範例&lt;/strong>：REALM。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>每 N 個詞元檢索 (Every-n-token retrieval)&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>方式&lt;/strong>：在生成過程中每隔 N 個詞元觸發一次檢索。&lt;/li>
&lt;li>&lt;strong>適用場景&lt;/strong>：需要持續資訊補充的長篇生成任務。&lt;/li>
&lt;li>&lt;strong>範例&lt;/strong>：In-Context RALM、RETRO。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>每個詞元檢索 (Every-token retrieval)&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>方式&lt;/strong>：在生成過程中，為每個詞元的預測都檢索資訊。&lt;/li>
&lt;li>&lt;strong>頻率&lt;/strong>：最頻繁的檢索策略。&lt;/li>
&lt;li>&lt;strong>範例&lt;/strong>：kNN-LM。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>權衡&lt;/strong>：
總體而言，檢索頻率影響 RAG 方法的有效性和效率。更頻繁的檢索通常帶來更好的性能，但也顯著增加計算成本。&lt;/p>
&lt;h2 id="ra-llms-訓練策略概述">RA-LLMs 訓練策略概述
&lt;/h2>&lt;p>&lt;img src="https://ar5iv.labs.arxiv.org/html/2405.06211/assets/x4.png"
loading="lazy"
alt="RA-LLMs 訓練策略總覽"
>&lt;br>
&lt;em>圖 3：RA-LLMs 訓練策略總覽，涵蓋免訓練與需訓練方法。來源：原論文&lt;/em>&lt;/p>
&lt;h3 id="免訓練方法training-free">免訓練方法（Training-Free）
&lt;/h3>&lt;h4 id="prompt-engineering-based-methods">Prompt Engineering-based Methods
&lt;/h4>&lt;p>將檢索到的外部知識，直接整合進 LLM 的提示（Prompt），作為上下文輔助模型生成。&lt;br>
舉例，In-Context RALM 在不改動 LLM 參數的情況下，直接將檢索到的文件插入於原始提示之前，增強生成過程。IRCoT 則交錯進行 chain-of-thought（CoT）生成與知識檢索步驟，使每一步推理都能檢索到更相關的資訊。GENREAD 不是從大型語料庫檢索知識，而是先讓 LLM 根據查詢生成上下文文件，再根據這些上下文與問題產生答案。SKR 則引導 LLM 判斷是否能僅依靠內部知識回答問題，若不足再選擇性調用檢索器，靈活結合內外部知識。TOC 針對模糊問題，先檢索相關知識，並遞迴將問題拆解為多個明確子問題，最終聚合生成長篇答案。&lt;/p>
&lt;ul>
&lt;li>特點：
&lt;ul>
&lt;li>無需模型訓練&lt;/li>
&lt;li>靠設計合理的提示與檢索流程提升效果&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="retrieval-guided-token-generation-methods">Retrieval-Guided Token Generation Methods
&lt;/h4>&lt;p>透過檢索結果來調整 LLM 的 Token 預測分布，影響每一步的生成。&lt;br>
舉例，例如 KNN-LMs 會根據當前查詢從資料庫檢索出 k 個最相關的上下文，計算鄰近分布，並將其與原模型的輸出分布進行插值校正，以提升生成結果的準確性。Rest 則以非參數檢索資料庫取代傳統的參數式草稿模型，根據當前上下文檢索相關 token，輔助推測式生成（speculative decoding）。&lt;/p>
&lt;ul>
&lt;li>特點：
&lt;ul>
&lt;li>不更改模型權重&lt;/li>
&lt;li>通常作為後處理或推測性生成的輔助&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>※ 這兩類免訓練方法，分別著重於：&lt;/p>
&lt;ul>
&lt;li>提示工程 — 調整輸入&lt;/li>
&lt;li>生成控制 — 調整輸出過程&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="需訓練方法training-based">需訓練方法（Training-Based）
&lt;/h3>&lt;ol>
&lt;li>Independent Training&lt;br>
獨立訓練方法會將 RAG 流程中的每個組件分開、獨立地進行訓練，這意味著在訓練過程中，這兩個組件之間沒有任何交互作用。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>目的與優勢：&lt;/strong>&lt;br>
相較於無需訓練的方法，獨立訓練能有效提升 RAG 模型的性能。&lt;br>
1. 訓練 LLMs 以更好地利用檢索到的知識。&lt;br>
2. 訓練檢索器以彌合資訊檢索與語言生成之間的差距。&lt;/p>
&lt;p>&lt;strong>檢索器類型：&lt;/strong>
* 稀疏檢索器 (Sparse Retriever) ：
這類檢索器通常利用稀疏特徵，例如詞頻，來表示文件，並根據任務特定的指標（如 TF-IDF 和 BM25）計算相關性分數 。&lt;/p>
&lt;pre>&lt;code>* 密集檢索器 (Dense Retriever) ：
密集檢索器則採用深度神經網絡將查詢和文件編碼成密集表示 (dense representations)。然後，通常使用內積計算相關性分數並檢索相關的外部知識。序列訓練透過協調訓練的方式，尋求更深層次的整合效果。
&lt;/code>&lt;/pre>
&lt;ol start="2">
&lt;li>
&lt;p>Sequential Training&lt;br>
序列訓練方法則採取分階段的訓練方式。首先訓練一個模組（例如檢索器），然後再利用這個訓練好的模組去指導另一個模組（例如生成器）的調整過程，目的在改善模組間的協同作用。&lt;/p>
&lt;p>&lt;strong>訓練流程：&lt;/strong> 序列訓練通常分為兩個階段&lt;/p>
&lt;ol>
&lt;li>**初始預訓練：**首先對檢索器或生成器中的一個模組進行獨立的預訓練。&lt;/li>
&lt;li>**固定與訓練：**一旦其中一個模組完成預訓練，它就會被固定（freeze）下來，而另一個模組則在其輔助下進行訓練。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>優勢與靈活性：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>協同增益：與獨立訓練相比，序列訓練的優勢在於可訓練的模組能夠受益於固定模組的引導和協助，從而更好地適應彼此。&lt;/li>
&lt;li>利用現有模型：值得注意的是，許多已經預訓練好的強大模型（例如 BERT、CLIP、T5）可以直接作為固定模組使用，從而省略了初始的預訓練步驟，進一步提高了效率。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>根據檢索器和生成器之間的訓練順序，序列訓練可分為兩大類：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>檢索器優先 (Retriever First)：&lt;br>
此類方法首先訓練檢索器，然後將其固定，再訓練生成器。&lt;/li>
&lt;li>LLMs 優先 (LLMs First)：&lt;br>
此類方法則相反，先訓練 LLM，再將其固定，然後訓練檢索器。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Joint Training&lt;br>
聯合訓練方法則是同時訓練檢索器和生成器，這種方式是為了讓兩個模組在訓練過程中相互協調、共同進步。&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>LangChain 記憶型檢索問答：《小王子》文本互動實踐</title><link>https://Dandelionlibra.github.io/post/langchain/retrieverqa-2/</link><pubDate>Fri, 18 Jul 2025 08:39:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/retrieverqa-2/</guid><description>&lt;h2 id="以-langchain-記憶型檢索問答實現小王子文本互動">以 LangChain 記憶型檢索問答實現《小王子》文本互動
&lt;/h2>&lt;p>本文介紹如何利用 LangChain 框架，結合 Ollama Embeddings、ChromaDB 與記憶型問答鏈（RunnableWithMessageHistory），實現能記住上下文的互動式檢索問答。以《小王子》文本為例，展示記憶型問答與一般檢索問答的差異。&lt;/p>
&lt;h3 id="一記憶型問答鏈設計">一、記憶型問答鏈設計
&lt;/h3>&lt;p>LangChain 提供 &lt;code>RunnableWithMessageHistory&lt;/code>，可根據 session_id 保存對話歷程，讓模型具備「記憶」功能。核心流程如下：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>建立 InMemoryHistory 類&lt;/strong>：用於儲存每個 session 的訊息。&lt;/li>
&lt;li>&lt;strong>載入 PDF 並分割文本&lt;/strong>：使用 &lt;code>PyPDFLoader&lt;/code> 和 &lt;code>RecursiveCharacterTextSplitter&lt;/code>。&lt;/li>
&lt;li>&lt;strong>建立向量資料庫&lt;/strong>：用 Ollama Embeddings 將文本轉向量，存入 ChromaDB。&lt;/li>
&lt;li>&lt;strong>設計 Prompt 與 Chain&lt;/strong>：結合歷史訊息與提問，串接 LLM。&lt;/li>
&lt;li>&lt;strong>啟動記憶型問答鏈&lt;/strong>：每次提問都能保留上下文，實現多輪互動。&lt;/li>
&lt;/ol>
&lt;h4 id="主要程式片段">主要程式片段
&lt;/h4>&lt;p>完整程式碼請參考：&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/example/LangChain_memory_ask_via_pdf.ipynb" target="_blank" rel="noopener"
>GitHub 範例程式&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 建立記憶管理器&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">InMemoryHistory&lt;/span>(BaseChatMessageHistory, BaseModel):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> messages: list[BaseMessage] &lt;span style="color:#f92672">=&lt;/span> Field(default_factory&lt;span style="color:#f92672">=&lt;/span>list)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">add_messages&lt;/span>(self, messages: list[BaseMessage]) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>messages&lt;span style="color:#f92672">.&lt;/span>extend(messages)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">clear&lt;/span>(self) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>messages &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>store &lt;span style="color:#f92672">=&lt;/span> {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_by_session_id&lt;/span>(session_id: str) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> BaseChatMessageHistory:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> session_id &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#f92672">in&lt;/span> store:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> store[session_id] &lt;span style="color:#f92672">=&lt;/span> InMemoryHistory()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> store[session_id]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 啟動記憶型問答鏈&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chain_with_history &lt;span style="color:#f92672">=&lt;/span> RunnableWithMessageHistory(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> chain,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> get_by_session_id,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_messages_key&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> history_messages_key&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;history&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="二互動範例">二、互動範例
&lt;/h3>&lt;h4 id="問答一你看過經典故事小王子嗎">問答一：你看過經典故事小王子嗎？
&lt;/h4>&lt;p>模型回答：&lt;/p>
&lt;blockquote>
&lt;p>我看過《小王子》！這是個非常著名的小說，作者是安托瓦內·德·聖-埃克絮佩里。故事充滿哲理與寓意，讓人思考生命、愛情和友誼。&lt;/p>&lt;/blockquote>
&lt;h4 id="問答二啟蒙了你什麼">問答二：啟蒙了你什麼？
&lt;/h4>&lt;p>模型回答：&lt;/p>
&lt;blockquote>
&lt;p>小王子和這個故事都啟蒙了我對生命、愛情和友誼的看法。它教會我要珍惜生命、關心他人和追求夢想。&lt;/p>&lt;/blockquote>
&lt;h4 id="問答三你覺得小王子是個怎樣的人">問答三：你覺得小王子是個怎樣的人？
&lt;/h4>&lt;p>模型回答：&lt;/p>
&lt;blockquote>
&lt;p>小王子是一個獨特、敏感和浪漫的年輕人。他能看到世界的美麗和價值，願意為之付出努力，但也有些缺乏勇氣承認自己的情感。&lt;/p>&lt;/blockquote>
&lt;h4 id="問答四續寫第二部小王子">問答四：續寫第二部小王子
&lt;/h4>&lt;p>模型回答：&lt;/p>
&lt;blockquote>
&lt;p>根據小王子的故事，我們可以繼續他的冒險旅程。他想探索更大的世界，沿途遇到許多新奇的生物和景色，對每件事都充滿好奇和興趣。&lt;/p>&lt;/blockquote>
&lt;h3 id="三記憶型問答-vs-一般檢索問答">三、記憶型問答 VS 一般檢索問答
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>記憶型問答&lt;/strong>：能保留上下文，支持多輪互動，回答更貼合對話脈絡。&lt;/li>
&lt;li>&lt;strong>一般檢索問答&lt;/strong>：每次提問獨立，無法記住前文，回答較為片段。&lt;/li>
&lt;/ul>
&lt;h4 id="一般檢索問答範例">一般檢索問答範例
&lt;/h4>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>qa_chain &lt;span style="color:#f92672">=&lt;/span> RetrievalQA&lt;span style="color:#f92672">.&lt;/span>from_chain_type(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> llm&lt;span style="color:#f92672">=&lt;/span>ollama_llm,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> retriever&lt;span style="color:#f92672">=&lt;/span>vector_db&lt;span style="color:#f92672">.&lt;/span>as_retriever(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>qa_chain&lt;span style="color:#f92672">.&lt;/span>invoke(&lt;span style="color:#e6db74">&amp;#39;你看過經典故事小王子嘛？&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 回答：是的，我看過《小王子》。&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="四總結">四、總結
&lt;/h3>&lt;p>結合 LangChain 記憶型問答鏈，可針對文本進行多輪互動，模型能記住上下文，回答更自然且具延續性。適合用於深入文本探索、故事續寫等場景。&lt;/p>
&lt;h2 id="參考資料">參考資料
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html" target="_blank" rel="noopener"
>LangChain RunnableWithMessageHistory 官方文件&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dandelionlibra.github.io/post/langchain/retrieverqa-1/" target="_blank" rel="noopener"
>LangChain 檢索問答基礎篇&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>使用 Langchain 框架進行檢索提問</title><link>https://Dandelionlibra.github.io/post/langchain/retrieverqa-1/</link><pubDate>Fri, 18 Jul 2025 02:59:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/retrieverqa-1/</guid><description>&lt;h2 id="程式運行詳細步驟">程式運行詳細步驟
&lt;/h2>&lt;p>以下以 Jupyter Notebook 格式，記錄如何使用 LangChain 框架結合 Ollama Embeddings 與 ChromaDB，實現 PDF 文件的檢索式問答。&lt;br>
詳細程式參考：&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/example/LangChain_ask_via_pdf.ipynb" target="_blank" rel="noopener"
>GitHub 範例程式&lt;/a>&lt;/p>
&lt;h3 id="1-載入必要套件與初始化-embedding-模型">1. 載入必要套件與初始化 Embedding 模型
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_community.document_loaders &lt;span style="color:#f92672">import&lt;/span> PyPDFLoader
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_text_splitters &lt;span style="color:#f92672">import&lt;/span> RecursiveCharacterTextSplitter
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaEmbeddings
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_chroma &lt;span style="color:#f92672">import&lt;/span> Chroma
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 初始化 Ollama Embeddings&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>embeddings_model &lt;span style="color:#f92672">=&lt;/span> OllamaEmbeddings(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> base_url&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;http://dandelion-ollama-1:11434&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;bge-m3:567m&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-載入-pdf-文件並分割文本">2. 載入 PDF 文件並分割文本
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 載入 PDF&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loader &lt;span style="color:#f92672">=&lt;/span> PyPDFLoader(&lt;span style="color:#e6db74">&amp;#39;./data/PDF_file.pdf&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docs &lt;span style="color:#f92672">=&lt;/span> loader&lt;span style="color:#f92672">.&lt;/span>load_and_split()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 設定分段參數&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chunk_size &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">256&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chunk_overlap &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>text_splitter &lt;span style="color:#f92672">=&lt;/span> RecursiveCharacterTextSplitter(chunk_size&lt;span style="color:#f92672">=&lt;/span>chunk_size, chunk_overlap&lt;span style="color:#f92672">=&lt;/span>chunk_overlap)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>documents &lt;span style="color:#f92672">=&lt;/span> text_splitter&lt;span style="color:#f92672">.&lt;/span>split_documents(docs)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="3-建立-chroma-向量資料庫">3. 建立 Chroma 向量資料庫
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>db &lt;span style="color:#f92672">=&lt;/span> Chroma&lt;span style="color:#f92672">.&lt;/span>from_documents(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> documents,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> embedding&lt;span style="color:#f92672">=&lt;/span>embeddings_model,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> persist_directory&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;./story-db&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="4-啟動檢索式問答鏈-retrievalqa-chain">4. 啟動檢索式問答鏈 (RetrievalQA Chain)
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.chains &lt;span style="color:#f92672">import&lt;/span> RetrievalQA
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ollama_llm &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> base_url&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;http://dandelion-ollama-1:11434&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> temperature&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_predict&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">512&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>qa_chain &lt;span style="color:#f92672">=&lt;/span> RetrievalQA&lt;span style="color:#f92672">.&lt;/span>from_chain_type(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> llm&lt;span style="color:#f92672">=&lt;/span>ollama_llm,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> retriever&lt;span style="color:#f92672">=&lt;/span>db&lt;span style="color:#f92672">.&lt;/span>as_retriever(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="5-問答範例及模型回答">5. 問答範例及模型回答
&lt;/h3>&lt;p>以下僅列出部分問答範例，其餘可自行嘗試：&lt;/p>
&lt;hr>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>query &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;玫瑰是誰？&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>result &lt;span style="color:#f92672">=&lt;/span> qa_chain&lt;span style="color:#f92672">.&lt;/span>invoke(query)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(result)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>模型回答：&lt;/strong>&lt;/p>
&lt;pre tabindex="0">&lt;code>{&amp;#39;query&amp;#39;: &amp;#39;玫瑰是誰？&amp;#39;, &amp;#39;result&amp;#39;: &amp;#39;玫瑰是小王子的玫瑰花，還有園中其他五千朵玫瑰花（但小王子的玫瑰花是獨一無二的）。&amp;#39;}
&lt;/code>&lt;/pre>&lt;hr>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>qa_chain&lt;span style="color:#f92672">.&lt;/span>invoke(&lt;span style="color:#e6db74">&amp;#39;小王子的來歷是什？&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>模型回答：&lt;/strong>&lt;/p>
&lt;pre tabindex="0">&lt;code>{&amp;#39;query&amp;#39;: &amp;#39;小王子的來歷是什？&amp;#39;, &amp;#39;result&amp;#39;: &amp;#39;小王子所來自的那個星球是小行星B612。&amp;#39;}
&lt;/code>&lt;/pre>&lt;hr>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>qa_chain&lt;span style="color:#f92672">.&lt;/span>invoke(&lt;span style="color:#e6db74">&amp;#39;你覺得小王子是個怎樣的人？&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>模型回答：&lt;/strong>&lt;/p>
&lt;pre tabindex="0">&lt;code>{&amp;#39;query&amp;#39;: &amp;#39;你覺得小王子是個怎樣的人？&amp;#39;, &amp;#39;result&amp;#39;: &amp;#39;根據文中描述，小王子的性格可以看出來。他似乎是一個敏感、浪漫、獨立的年輕人。他對他所遇到的陌生人的評價很細致，能夠看穿別人的真實面目。他也顯示出對自由和自主的渴望。&amp;#39;}
&lt;/code>&lt;/pre>&lt;hr>
&lt;blockquote>
&lt;p>更多問題可依據文本內容自由發揮，探索不同答案。&lt;/p>&lt;/blockquote>
&lt;h3 id="筆記重點">筆記重點
&lt;/h3>&lt;ul>
&lt;li>透過 &lt;code>PyPDFLoader&lt;/code> 讀取 PDF，並用 &lt;code>RecursiveCharacterTextSplitter&lt;/code> 分割文本，利於後續檢索。&lt;/li>
&lt;li>使用 Ollama Embeddings 將文本轉為向量，存入 ChromaDB。&lt;/li>
&lt;li>結合 Ollama LLM 與 RetrievalQA Chain，實現自然語言問答。&lt;/li>
&lt;li>可針對文本內容進行多樣化提問，快速獲得答案。&lt;/li>
&lt;/ul></description></item><item><title>使用 Docker 快速建立 Jupyter Notebook 環境教學</title><link>https://Dandelionlibra.github.io/post/virtual-environment/docker/setup-jupyter-notebook-with-docker/</link><pubDate>Thu, 17 Jul 2025 10:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/virtual-environment/docker/setup-jupyter-notebook-with-docker/</guid><description>&lt;h2 id="內容大綱">內容大綱
&lt;/h2>&lt;ol>
&lt;li>為什麼用 Docker 建立 Jupyter Notebook？&lt;/li>
&lt;li>安裝 Docker
&lt;ul>
&lt;li>Linux&lt;/li>
&lt;li>Mac&lt;/li>
&lt;li>Windows&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>下載與執行 Jupyter Notebook Docker 映像檔&lt;/li>
&lt;li>設定 Notebook 存取與資料掛載&lt;/li>
&lt;li>使用 GPU&lt;/li>
&lt;li>參考資料&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="1-為什麼用-docker-建立-jupyter-notebook">1. 為什麼用 Docker 建立 Jupyter Notebook？
&lt;/h2>&lt;p>Docker 可讓你快速建立隔離的開發環境，避免本機安裝衝突。Jupyter Notebook 是資料科學常用的互動式開發工具，透過 Docker 可輕鬆部署、移植與分享。&lt;/p>
&lt;hr>
&lt;h2 id="2-安裝-docker">2. 安裝 Docker
&lt;/h2>&lt;h3 id="linux">Linux
&lt;/h3>&lt;p>大多數 Linux 發行版可透過套件管理器安裝 Docker：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 更新套件清單&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt update
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 安裝 Docker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install docker.io
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 啟動 Docker 服務&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo systemctl start docker
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 設定開機自動啟動&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo systemctl enable docker
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="mac">Mac
&lt;/h3>&lt;p>前往 &lt;a class="link" href="https://www.docker.com/products/docker-desktop/" target="_blank" rel="noopener"
>Docker Desktop for Mac&lt;/a> 下載並安裝。&lt;/p>
&lt;h3 id="windows">Windows
&lt;/h3>&lt;p>前往 &lt;a class="link" href="https://www.docker.com/products/docker-desktop/" target="_blank" rel="noopener"
>Docker Desktop for Windows&lt;/a> 下載並安裝。&lt;/p>
&lt;hr>
&lt;h2 id="3-下載與執行-jupyter-notebook-docker-映像檔">3. 下載與執行 Jupyter Notebook Docker 映像檔
&lt;/h2>&lt;p>官方映像檔推薦使用 &lt;a class="link" href="https://hub.docker.com/r/jupyter/base-notebook" target="_blank" rel="noopener"
>&lt;code>jupyter/base-notebook&lt;/code>&lt;/a> 或 &lt;a class="link" href="https://hub.docker.com/r/jupyter/scipy-notebook" target="_blank" rel="noopener"
>&lt;code>jupyter/scipy-notebook&lt;/code>&lt;/a>：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>拉取映像檔&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker pull jupyter/base-notebook
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>建立容器&lt;br>
&lt;code>docker run [OPTIONS] IMAGE [COMMAND] [ARG...]&lt;/code>&lt;/p>
&lt;p>啟動容器並開啟本機 8888 端口：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -p 8888:8888 jupyter/base-notebook
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>啟動後，終端機會顯示一組 token，複製網址（如 &lt;code>http://127.0.0.1:8888/?token=...&lt;/code>）在瀏覽器開啟即可進入 Jupyter Notebook。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>※ &lt;a class="link" href="https://hub.docker.com" target="_blank" rel="noopener"
>&lt;code>DockerHub&lt;/code>&lt;/a>: DockerHub 是官方的 Docker 映像檔集中平台，提供各種應用程式的映像檔下載與分享，可以在這裡搜尋、取得映像檔，快速部署環境。&lt;/p>
&lt;hr>
&lt;h2 id="4-設定-notebook-存取與資料掛載">4. 設定 Notebook 存取與資料掛載
&lt;/h2>&lt;p>若要將本機資料夾掛載到容器，方便存取與保存 notebook 檔案：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -p 8888:8888 -v /your/local/path:/home/jovyan/work --name my-jupyter jupyter/base-notebook
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>-p&lt;/code>: Assigns the internal port to the external port&lt;/li>
&lt;li>&lt;code>-v&lt;/code>: Assigns a local directory to a container directory (mounts a volume)&lt;/li>
&lt;li>&lt;code>/your/local/path&lt;/code>：本機資料夾路徑&lt;/li>
&lt;li>&lt;code>/home/jovyan/work&lt;/code>：容器內預設工作目錄&lt;/li>
&lt;li>&lt;code>--name&lt;/code>: Sets the container name; otherwise, a random name will be assigned&lt;/li>
&lt;/ul>
&lt;p>可自訂密碼或 token，詳見 &lt;a class="link" href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#docker-options" target="_blank" rel="noopener"
>官方文件&lt;/a>。&lt;/p>
&lt;h2 id="5-使用-gpu">5. 使用 GPU
&lt;/h2>&lt;p>若你的主機支援 NVIDIA GPU，可利用 &lt;a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html" target="_blank" rel="noopener"
>NVIDIA Container Toolkit&lt;/a> 讓 Docker 容器存取 GPU 資源。&lt;/p>
&lt;h3 id="步驟">步驟
&lt;/h3>&lt;ol>
&lt;li>
&lt;p>&lt;strong>安裝 NVIDIA 驅動程式&lt;/strong>&lt;br>
請先安裝對應作業系統的 NVIDIA 顯示卡驅動。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>安裝 NVIDIA Container Toolkit&lt;/strong>&lt;br>
依照官方文件安裝 &lt;code>nvidia-docker&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt-get install -y nvidia-docker2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo systemctl restart docker
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>&lt;strong>啟動支援 GPU 的 Jupyter Notebook 容器&lt;/strong>&lt;br>
使用 &lt;code>--gpus all&lt;/code> 參數啟動容器：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run --gpus all -p 8888:8888 --name gpu_note -v ~/name:/tf/name tensorflow/tensorflow:latest-gpu-jupyter
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>&lt;strong>驗證 GPU 是否可用&lt;/strong>&lt;br>
在 Notebook 中執行下列程式碼，確認 GPU 是否被偵測到：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> tensorflow &lt;span style="color:#66d9ef">as&lt;/span> tf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(tf&lt;span style="color:#f92672">.&lt;/span>config&lt;span style="color:#f92672">.&lt;/span>list_physical_devices(&lt;span style="color:#e6db74">&amp;#39;GPU&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>注意：部分映像檔可能需額外安裝 CUDA、cuDNN 或深度學習框架，請參考 &lt;a class="link" href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/recipes.html#using-gpus" target="_blank" rel="noopener"
>Jupyter Docker Stacks 官方說明&lt;/a>。&lt;/p>&lt;/blockquote>
&lt;hr>
&lt;h2 id="6-參考資料">6. 參考資料
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://jupyter-docker-stacks.readthedocs.io/" target="_blank" rel="noopener"
>Jupyter Docker Stacks 官方文件&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.docker.com/" target="_blank" rel="noopener"
>Docker 官方網站&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://jupyter.org/" target="_blank" rel="noopener"
>Jupyter Notebook 官方網站&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>LangChain 基本使用-4</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-4/</link><pubDate>Tue, 15 Jul 2025 21:12:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-4/</guid><description>&lt;h1 id="甚麼是-langchain-的鏈結構">甚麼是 Langchain 的鏈結構?
&lt;/h1>&lt;h2 id="定義">定義
&lt;/h2>&lt;p>將小的模組串起來，而形成的串列結構。&lt;br>
舉例: 定義提示詞 -&amp;gt; 選擇 LLM -&amp;gt; 運行 inferencing(呼叫 function) -&amp;gt; 得到結果。&lt;/p>
&lt;ul>
&lt;li>優點:
&lt;ul>
&lt;li>模組化更容易修改個別功能，而不影響其他部分&lt;/li>
&lt;li>提高了模組的標準化、可再用性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="鏈結構分類">鏈結構分類
&lt;/h1>&lt;ul>
&lt;li>
&lt;p>基礎鏈結構&lt;/p>
&lt;ul>
&lt;li>
&lt;p>LLM chain (單鏈)&lt;br>
對應直接調用大型語言模型，最少 1 次 LLM call。&lt;br>
ex. llm.invoke()&lt;/p>
&lt;ol>
&lt;li>定義 prompt&lt;/li>
&lt;li>定義 llm&lt;/li>
&lt;li>定義 chain&lt;/li>
&lt;li>運行 predict&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Router chain (多鏈)&lt;br>
判斷要使用哪個鏈，最少 2 次 LLM call，第一次呼叫是為了決定使用哪條鏈，第二次是為了得到回答。&lt;/p>
&lt;ol>
&lt;li>定義 prompt&lt;/li>
&lt;li>定義 llm/emdeddings&lt;/li>
&lt;li>定義 chain (多鏈併行，選一條鏈處理)&lt;/li>
&lt;li>運行 predict
&lt;img src="https://Dandelionlibra.github.io/image/Router_chain.JPG"
loading="lazy"
alt="Data_Connection"
>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Sequential chain (多鏈)&lt;br>
上一個語言模型的調用結果是下一個語言模型調用的輸入。&lt;/p>
&lt;ol>
&lt;li>定義 prompt&lt;/li>
&lt;li>定義 llm/emdeddings&lt;/li>
&lt;li>定義 chain (多鏈併行，依照順序執行)&lt;/li>
&lt;li>運行 predict&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Transformation chain (文本處理鏈)&lt;br>
將輸入文本處理後。
&lt;img src="https://Dandelionlibra.github.io/image/Transformation_chain.JPG"
loading="lazy"
alt="Data_Connection"
>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>應用鏈結構&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Document chains type (長文本處理鏈): 總結、向量數據庫&lt;/p>
&lt;ul>
&lt;li>Stuff:
當要詢問模型沒有訓練過的訊息時，要透過 prompt 將資訊傳入，但若輸入長度超過模型可接受的最大 token 會無法運行。
&lt;img src="https://Dandelionlibra.github.io/image/Stuff.JPG"
loading="lazy"
alt="Data_Connection"
>&lt;/li>
&lt;li>Refine:
調用多次語言模型，將原本的長上下文分段落，避免輸入超過最大 token 的問題，將上一輪的輸出作為中間回答放到第三部分中
&lt;img src="https://Dandelionlibra.github.io/image/Refine.JPG"
loading="lazy"
alt="Data_Connection"
>&lt;/li>
&lt;li>Map reduce&lt;/li>
&lt;li>Map rerank&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Retrieval QA&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="程式事例">程式事例
&lt;/h2>&lt;p>&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_link.ipynb" target="_blank" rel="noopener"
>詳細程式請參閱&lt;/a>&lt;/p>
&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>LangChain 基本使用-3</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-3/</link><pubDate>Mon, 14 Jul 2025 10:56:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-3/</guid><description>&lt;h1 id="data-connection">Data Connection
&lt;/h1>&lt;h2 id="定義">定義
&lt;/h2>&lt;p>許多基於大型語言模型而執行的應用常會用到模型數據集中沒有的數據。而針對這類需求，Langchain 提供了許多工具使用戶可以從各類數據源中加載新的數據、轉換數據、儲存數據、訪問數據。&lt;/p>
&lt;p>※大型語言模型不可能在訓練階段就涵蓋所有數據，且每時每刻都有新的數據產生。&lt;/p>
&lt;ul>
&lt;li>文檔載入器(Document loaders): 從多種數據源加載文檔，ex.網頁、pdf。&lt;/li>
&lt;li>文檔轉換器: 拆分文檔、丟棄冗餘文檔，主要運行在文檔載入器之後，針對加載出來的文檔做處理。&lt;/li>
&lt;li>文本嵌入(embedding)模型: 將非結構化的文本轉為浮點數列表。&lt;/li>
&lt;li>向量數據庫: 儲存和搜尋 embedding 數據。&lt;/li>
&lt;li>檢索器: 查詢向量數據。&lt;/li>
&lt;/ul>
&lt;h2 id="data-connection-處理流程">Data Connection 處理流程
&lt;/h2>&lt;p>&lt;img src="https://Dandelionlibra.github.io/image/Data_Connection.JPG"
loading="lazy"
alt="Data_Connection"
>&lt;/p>
&lt;h3 id="1-文本載入器document-loaders">1. 文本載入器(Document loaders)
&lt;/h3>&lt;p>將文本數據從原始數據(Source)中提取出來，改成 langchain 認識的語言，總而言之就是將非結構化的文本數據加載到結構化的字符串中。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>輸入: 各種數據源，ex.PDF、URL、影片。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>輸出: 一系列的 Document 對象，例，有6頁pdf會產出6個 documents，以分別對應。
&lt;img src="https://Dandelionlibra.github.io/image/Document_loaders.JPG"
loading="lazy"
alt="Document_loaders.JPG"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>舉例&lt;/p>
&lt;ul>
&lt;li>
&lt;p>結構化文件: 加載 CSV 文件&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.document_loaders.csv_loader &lt;span style="color:#f92672">import&lt;/span> CSVLoader
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loader &lt;span style="color:#f92672">=&lt;/span> CSVLoader(file_path&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;./data/file.csv&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#f92672">=&lt;/span> loader&lt;span style="color:#f92672">.&lt;/span>load()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>非結構化文件: 純文本、ppt、html、pdf、圖片。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://python.langchain.com/docs/integrations/document_loaders/" target="_blank" rel="noopener"
>全部文件格式&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="2-文本分割器document-transformers">2. 文本分割器(Document transformers)
&lt;/h3>&lt;p>將加載好的文檔進行轉換，從而更好的適應各種場景。舉例，將文檔拆分成較小的塊，以避免大型語言模型對於輸入長度的限制。&lt;br>
Langchain 中提供的文檔轉換器可以提供拆分、合併、過濾等功能。&lt;/p>
&lt;ul>
&lt;li>文本分割器-拆分: 分割長文本，根據語意相關性將所有有關聯的文本放在同一個分割段中。&lt;br>
&lt;img src="https://Dandelionlibra.github.io/image/Document_transformers.JPG"
loading="lazy"
alt="Document_transformers.JPG.JPG"
>&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>將文本拆分為小、具語意意義的塊。&lt;/li>
&lt;li>將小塊組合成大塊，直到達到一定規模。&lt;/li>
&lt;li>將達到一定規模的塊作為獨立的文本片段，然後創建新的文本塊，此外，為了維持塊間的連貫性，兩個文本塊之間會有重疊的部分。&lt;br>
以圖例而言，Document 由一塊變為三塊。&lt;/li>
&lt;/ol>
&lt;h3 id="3-文本詞嵌入word-embedding">3. 文本詞嵌入(Word Embedding)
&lt;/h3>&lt;p>詞嵌入是將詞語數值化表達的方式，通常會將詞映射到高維的向量中，使電腦藉由高維的數字化表達得以理解自然語言的語意，接近的語意=接近的向量距離。&lt;/p>
&lt;h3 id="4-向量數據庫">4. 向量數據庫
&lt;/h3>&lt;p>用於儲存嵌入的數據向量。&lt;/p>
&lt;h3 id="5-檢索器">5. 檢索器
&lt;/h3>&lt;p>根據輸入的非結構化查詢語句返回對應文檔的接口(一系列 Documents 對象)。&lt;br>
不同於向量數據庫，向量數據庫可以視為一種具備儲存功能的檢索器，但檢索器不一定需要具備儲存的功能。&lt;/p>
&lt;h2 id="程式事例">程式事例
&lt;/h2>&lt;p>&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_csv_loader.ipynb" target="_blank" rel="noopener"
>詳細程式請參閱&lt;/a>&lt;/p>
&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>LangChain 基本使用-2</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</link><pubDate>Sun, 13 Jul 2025 08:06:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</guid><description>&lt;h1 id="提示模板">提示模板
&lt;/h1>&lt;ul>
&lt;li>對語言模型的指令&lt;/li>
&lt;li>提供簡單的事例給語言模型使模型接近理想結果&lt;/li>
&lt;li>提給語言模型的問題&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 使用 PromptTemplate 來定義對話的提示模板&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>no_input_prompt_template &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;說個故事&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>multi_input_prompt_template &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;主題&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;風格&amp;#34;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;請講一個關於&lt;/span>&lt;span style="color:#e6db74">{主題}&lt;/span>&lt;span style="color:#e6db74">的故事，風格是&lt;/span>&lt;span style="color:#e6db74">{風格}&lt;/span>&lt;span style="color:#e6db74">。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>multi_input_prompt_template&lt;span style="color:#f92672">.&lt;/span>format(主題&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;勇氣&amp;#34;&lt;/span>, 風格&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;童話&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># other example，由 from_template 將 string 轉成 PromptTemplate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>template &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;請講一個關於&lt;/span>&lt;span style="color:#e6db74">{主題}&lt;/span>&lt;span style="color:#e6db74">的故事，風格是&lt;/span>&lt;span style="color:#e6db74">{風格}&lt;/span>&lt;span style="color:#e6db74">。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prompt_template &lt;span style="color:#f92672">=&lt;/span> PromptTemplate&lt;span style="color:#f92672">.&lt;/span>from_template(template)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 此時輸出 [&amp;#34;主題&amp;#34;, &amp;#34;風格&amp;#34;]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prompt_template&lt;span style="color:#f92672">.&lt;/span>input_variables
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="接收部分參數">接收部分參數
&lt;/h2>&lt;ol>
&lt;li>
&lt;p>在所有參數無法同步獲取時，可以先用現有參數傳入第一個模板，以獲得新的參數，再將新參數傳入新的模板中，以得到最終想問的問題。&lt;br>
&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_1.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>有些參數要用特定方式獲取 (ex.函式呼叫)
&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_2.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_date&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> now &lt;span style="color:#f92672">=&lt;/span> datetime&lt;span style="color:#f92672">.&lt;/span>now()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> now&lt;span style="color:#f92672">.&lt;/span>strftime(&lt;span style="color:#e6db74">&amp;#34;%m月&lt;/span>&lt;span style="color:#e6db74">%d&lt;/span>&lt;span style="color:#e6db74">日&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prompt &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;告訴我&lt;/span>&lt;span style="color:#e6db74">{城市}&lt;/span>&lt;span style="color:#e6db74">在&lt;/span>&lt;span style="color:#e6db74">{年份}&lt;/span>&lt;span style="color:#e6db74">年&lt;/span>&lt;span style="color:#e6db74">{日期}&lt;/span>&lt;span style="color:#e6db74">的平均氣溫是多少？&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;城市&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;年份&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;日期&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>PromptTemplate_2 &lt;span style="color:#f92672">=&lt;/span> prompt&lt;span style="color:#f92672">.&lt;/span>partial(城市&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;台北&amp;#34;&lt;/span>, 日期&lt;span style="color:#f92672">=&lt;/span>get_date())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(PromptTemplate_2&lt;span style="color:#f92672">.&lt;/span>format(年份&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;2023&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出:&lt;/p>
&lt;pre tabindex="0">&lt;code>告訴我台北在2023年07月13日的平均氣溫是多少？
&lt;/code>&lt;/pre>&lt;h2 id="少樣本學習-few-shot">少樣本學習 (few-shot)
&lt;/h2>&lt;ul>
&lt;li>藉由少量的樣本、範例，使語言模型能處理特定問題&lt;/li>
&lt;li>不同於微調 (fine-tuning)，微調會使用大量樣本，最終會改變模型本身&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>例子:&lt;br>
&amp;ldquo;你好嗎?&amp;rdquo; - &amp;ldquo;主人，我很好。&amp;rdquo;&lt;br>
&amp;ldquo;今天禮拜幾?&amp;rdquo; - &amp;ldquo;主人，今天禮拜日。&amp;rdquo;&lt;br>
&amp;ldquo;天氣真好呀。&amp;rdquo; - &amp;ldquo;主人，是的，今天天氣非常好。&amp;rdquo;&lt;/p>
&lt;p>希望模型學會&amp;quot;主人&amp;quot;的前綴。&lt;/p>&lt;/blockquote>
&lt;h3 id="fewshot-prompt-template">FewShot Prompt Template
&lt;/h3>&lt;p>利用提示模板，將樣本數據加載成完整的提示詞，接著將樣本連同提示詞一併送給樣本提示模板，最終得到完整的提示詞。&lt;/p>
&lt;p>&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_3.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.prompts.few_shot &lt;span style="color:#f92672">import&lt;/span> FewShotPromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.prompts.prompt &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># FewShot examples&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>examples &lt;span style="color:#f92672">=&lt;/span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;你好嗎?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;主人，我很好。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;今天禮拜幾?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;主人，今天禮拜日。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;天氣真好呀。&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;主人，是的，今天天氣非常好。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># FewShotPromptTemplate-樣本提示模板&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 提示模板以 Question:開頭&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>example_prompt &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>], template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Question: &lt;/span>&lt;span style="color:#e6db74">{question}&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">Answer: &lt;/span>&lt;span style="color:#e6db74">{answer}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>few_shot_prompt &lt;span style="color:#f92672">=&lt;/span> FewShotPromptTemplate(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> examples&lt;span style="color:#f92672">=&lt;/span>examples, &lt;span style="color:#75715e"># 傳入樣本&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> example_prompt&lt;span style="color:#f92672">=&lt;/span>example_prompt, &lt;span style="color:#75715e"># 傳入樣本模板&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> suffix&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Question: &lt;/span>&lt;span style="color:#e6db74">{input}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 問題的提示詞&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;input&amp;#34;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(few_shot_prompt&lt;span style="color:#f92672">.&lt;/span>format(input&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;你今天過得怎麼樣?&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出完整提示詞如下，但前面三組為提供的範例案例，最後一組是輸入的提問。&lt;/p>
&lt;pre tabindex="0">&lt;code>Question: 你好嗎?
Answer: 主人，我很好。
Question: 今天禮拜幾?
Answer: 主人，今天禮拜日。
Question: 天氣真好呀。
Answer: 主人，是的，今天天氣非常好。
Question: 你今天過得怎麼樣?
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> llm&lt;span style="color:#f92672">.&lt;/span>invoke(few_shot_prompt&lt;span style="color:#f92672">.&lt;/span>format(input&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;你今天過得怎麼樣?&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(response)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出結果：&lt;/p>
&lt;pre tabindex="0">&lt;code>你的問題是問你今天過得怎麼樣？我可以回答說：您也很好。或者，我可以詢問一下您今天過得怎麼樣？
如果你想知道我的答案，那就是：主人，今天我很好，謝謝您的關心！
&lt;/code>&lt;/pre>&lt;h3 id="樣本篩選器-exampleselector">樣本篩選器 (ExampleSelector)
&lt;/h3>&lt;ul>
&lt;li>樣本數量太多時&lt;/li>
&lt;li>不是所有樣本都能幫助提升輸出質量
&lt;img src="https://Dandelionlibra.github.io/image/ExampleSelector.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/li>
&lt;li>舉例: SemanticSimilarityExampleSelector (語意相似度篩選器)，依據最終提的問題，在所有樣本中尋找語意最為接近的樣本。&lt;/li>
&lt;/ul>
&lt;h2 id="大型語言模型的封裝">大型語言模型的封裝
&lt;/h2>&lt;ul>
&lt;li>Langchain 不提供現成的大型語言模型&lt;/li>
&lt;li>Langchain 提供的是針對不同語言模型的標準化接口&lt;/li>
&lt;/ul>
&lt;h3 id="大型語言模型llm模塊的基本用法">大型語言模型(LLM)模塊的基本用法
&lt;/h3>&lt;ul>
&lt;li>直接呼叫
&lt;ul>
&lt;li>類似直接呼叫.invoke()，讓語言模型根據輸入回答內容。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(llm(&lt;span style="color:#e6db74">&amp;#34;跟我說一個笑話，盡量簡短。&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出：&lt;/p>
&lt;pre tabindex="0">&lt;code>為什麼電池走路去了? 因為它想充電
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>批量生成
&lt;ul>
&lt;li>generate()&lt;/li>
&lt;li>輸入：文本的列表&lt;/li>
&lt;li>輸出：文本的列表&lt;/li>
&lt;li>ex. 輸入問題的列表，輸出回答的列表。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>generate_res &lt;span style="color:#f92672">=&lt;/span> llm&lt;span style="color:#f92672">.&lt;/span>generate([&lt;span style="color:#e6db74">&amp;#34;跟我說一個笑話，盡量簡短。&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;跟我說一個悲傷的故事，盡量簡短。&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(generate_res)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出：&lt;/p>
&lt;pre tabindex="0">&lt;code>generations=[[GenerationChunk(text=&amp;#39;為什麼人類會走路?\n\n因為鳥不喜歡吃路上的東西!&amp;#39;, generation_info={&amp;#39;model&amp;#39;: &amp;#39;llama3.1:8b&amp;#39;, &amp;#39;created_at&amp;#39;: &amp;#39;2025-07-13T14:22:01.5478452Z&amp;#39;, &amp;#39;done&amp;#39;: True, &amp;#39;done_reason&amp;#39;: &amp;#39;stop&amp;#39;, &amp;#39;total_duration&amp;#39;: 2588937700, &amp;#39;load_duration&amp;#39;: 39039000, &amp;#39;prompt_eval_count&amp;#39;: 23, &amp;#39;prompt_eval_duration&amp;#39;: 335147300, &amp;#39;eval_count&amp;#39;: 22, &amp;#39;eval_duration&amp;#39;: 2214149200, &amp;#39;response&amp;#39;: &amp;#39;&amp;#39;, &amp;#39;thinking&amp;#39;: None, &amp;#39;context&amp;#39;: [128006, 882, 128007, 271, 104142, 37046, 106336, 114634, 49838, 87177, 3922, 16555, 94, 33857, 112825, 106649, 1811, 128009, 128006, 78191, 128007, 271, 101399, 101567, 114064, 17792, 104770, 101835, 102149, 47095, 1980, 63212, 101399, 116750, 16937, 104940, 125741, 105271, 47095, 106583, 101778, 61786, 0]})], [GenerationChunk(text=&amp;#39;有一個年輕女孩，她與自己的父親非常相愛。可是因為工作太忙，爸爸長期外出，並且忽略了女兒。直到一天，一場重大事故讓爸爸去世。在悲痛中，女孩發現了之前父親給她的信，裡面有對她的溫暖告白和深情懷念。這個消息使她心痛欲裂，從此女孩再也沒有恢復過。&amp;#39;, generation_info={&amp;#39;model&amp;#39;: &amp;#39;llama3.1:8b&amp;#39;, &amp;#39;created_at&amp;#39;: &amp;#39;2025-07-13T14:22:16.1064263Z&amp;#39;, &amp;#39;done&amp;#39;: True, &amp;#39;done_reason&amp;#39;: &amp;#39;stop&amp;#39;, &amp;#39;total_duration&amp;#39;: 14556868200, &amp;#39;load_duration&amp;#39;: 39856500, &amp;#39;prompt_eval_count&amp;#39;: 25, &amp;#39;prompt_eval_duration&amp;#39;: 516644200, &amp;#39;eval_count&amp;#39;: 104, &amp;#39;eval_duration&amp;#39;: 13999594200, &amp;#39;response&amp;#39;: &amp;#39;&amp;#39;, &amp;#39;thinking&amp;#39;: None, &amp;#39;context&amp;#39;: [128006, 882, 128007, 271, 104142, 37046, 106336, 114634, 116292, 114218, 9554, 117625, 3922, 16555, 94, 33857, 112825, 106649, 1811, 128009, 128006, 78191, 128007, 271, 108830, 102159, 8107, 125063, 58850, 105989, 105902, 102789, 107924, 104503, 106759, 108008, 50021, 103926, 1811, 113426, 63212, 101399, 102301, 101402, 112008, 3922, 117283, 117283, 101544, 23538, 48915, 20834, 113415, 103786, 120994, 105838, 35287, 58850, 114763, 1811, 74245, 28037, 15120, 36827, 104295, 75267, 125478, 123429, 114816, 117283, 117283, 86436, 101083, 107644, 116292, 108631, 16325, 3922, 58850, 105989, 103106, 102321, 35287, 112065, 104503, 106759, 110698, 109506, 22023, 3922, 115556, 28190, 19361, 104314, 109506, 117986, 118937, 58655, 101828, 34208, 102987, 40474, 103435, 115, 104611, 1811, 103864, 102159, 65305, 33655, 100911, 64209, 108631, 111654, 117068, 3922, 110039, 33091, 58850, 105989, 88356, 75863, 116721, 123843, 109095, 103188, 1811]})]] llm_output=None run=[RunInfo(run_id=UUID(&amp;#39;bc24e5b6-0c3f-4d2c-afb4-95f477e81adf&amp;#39;)), RunInfo(run_id=UUID(&amp;#39;f8f5fe28-4c1d-4b6f-8a74-fdcc6f397f7a&amp;#39;))] type=&amp;#39;LLMResult&amp;#39;
&lt;/code>&lt;/pre>&lt;p>可用陣列獲取特定輸出。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>print(generate_res&lt;span style="color:#f92672">.&lt;/span>generations[&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(generate_res&lt;span style="color:#f92672">.&lt;/span>generations[&lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>為什麼人類會走路?
因為鳥不喜歡吃路上的東西!
有一個年輕女孩，她與自己的父親非常相愛。可是因為工作太忙，爸爸長期外出，並且忽略了女兒。直到一天，一場重大事故讓爸爸去世。在悲痛中，女孩發現了之前父親給她的信，裡面有對她的溫暖告白和深情懷念。這個消息使她心痛欲裂，從此女孩再也沒有恢復過。
&lt;/code>&lt;/pre>&lt;h3 id="自定義-llm-模組">自定義 LLM 模組
&lt;/h3>&lt;ul>
&lt;li>用於封裝 Langchain 尚未支持的大型語言模型&lt;/li>
&lt;li>可以用來模擬測試&lt;/li>
&lt;li>自行定義當 LLM 被調用時，如何根據輸入的文本內容來輸出&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_code.ipynb" target="_blank" rel="noopener"
>詳細程式請參閱&lt;/a>&lt;/p>
&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>如何使用 SSH 進行遠端連線教學</title><link>https://Dandelionlibra.github.io/post/ssh/how-to-use-ssh/</link><pubDate>Thu, 10 Jul 2025 16:03:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/ssh/how-to-use-ssh/</guid><description>&lt;h2 id="內容大綱">內容大綱
&lt;/h2>&lt;ol>
&lt;li>SSH 基本介紹&lt;/li>
&lt;li>安裝 SSH 客戶端
&lt;ul>
&lt;li>Linux&lt;/li>
&lt;li>Mac&lt;/li>
&lt;li>Windows&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>產生 SSH 金鑰&lt;/li>
&lt;li>設定 SSH 連線
&lt;ul>
&lt;li>將公鑰加入遠端主機&lt;/li>
&lt;li>測試連線&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>常見應用情境
&lt;ul>
&lt;li>使用 VSCode 透過 SSH 遠端開發&lt;/li>
&lt;li>使用 Git 透過 SSH 進行版本控制&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>參考資料&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="1-ssh-基本介紹">1. SSH 基本介紹
&lt;/h2>&lt;p>SSH（Secure Shell）是一種加密的網路協定，用於在不安全的網路上安全地進行遠端登入與其他網路服務。常見用途包括遠端伺服器管理、檔案傳輸等。&lt;/p>
&lt;hr>
&lt;h2 id="2-安裝-ssh-客戶端">2. 安裝 SSH 客戶端
&lt;/h2>&lt;h3 id="linux">Linux
&lt;/h3>&lt;p>大多數 Linux 發行版預設已安裝 OpenSSH。若未安裝，可使用以下指令：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt update
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install openssh-client
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="mac">Mac
&lt;/h3>&lt;p>macOS 預設已安裝 SSH 客戶端，可直接在終端機使用 &lt;code>ssh&lt;/code> 指令。&lt;/p>
&lt;h3 id="windows">Windows
&lt;/h3>&lt;p>建議安裝 &lt;a class="link" href="https://gitforwindows.org/" target="_blank" rel="noopener"
>Git for Windows&lt;/a> 或 &lt;a class="link" href="https://aka.ms/terminal" target="_blank" rel="noopener"
>Windows Terminal&lt;/a>。Windows 10 以上可啟用內建 OpenSSH：&lt;/p>
&lt;ol>
&lt;li>開啟「設定」&amp;gt;「應用程式」&amp;gt;「選擇性功能」。&lt;/li>
&lt;li>找到並安裝「OpenSSH Client」。&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="3-產生-ssh-金鑰">3. 產生 SSH 金鑰
&lt;/h2>&lt;p>在本地端產生 SSH 金鑰：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ssh-keygen -t rsa -b &lt;span style="color:#ae81ff">4096&lt;/span> -C &lt;span style="color:#e6db74">&amp;#34;your_email@example.com&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>依照提示設定檔案名稱與密碼。預設會產生於 &lt;code>~/.ssh/id_rsa&lt;/code>（私鑰）與 &lt;code>~/.ssh/id_rsa.pub&lt;/code>（公鑰）。&lt;/p>
&lt;ul>
&lt;li>&lt;code>ssh-keygen&lt;/code>:
&lt;ul>
&lt;li>Private key: Stored locally, default path is &lt;code>~/.ssh/id_rsa&lt;/code>&lt;/li>
&lt;li>Public key: Placed on the server to enable passwordless login, default path is &lt;code>~/.ssh/id_rsa.pub&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>-t&lt;/code>: Assign the key type&lt;/li>
&lt;li>&lt;code>-b&lt;/code>: Assign the key length&lt;/li>
&lt;li>&lt;code>-C&lt;/code>: Adds a comment to the key for identifying the user and purpose&lt;/li>
&lt;/ul>
&lt;p>Press Enter save as default, if exist same name key, will prompt if you want to cover it or not, if not, need to use other key name.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>C:&lt;span style="color:#ae81ff">\W&lt;/span>INDOWS&lt;span style="color:#ae81ff">\s&lt;/span>ystem32&amp;gt;ssh-keygen -t rsa -b &lt;span style="color:#ae81ff">4096&lt;/span> -C &lt;span style="color:#e6db74">&amp;#34;test@gmail.com&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Generating public/private rsa key pair.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Enter file in which to save the key &lt;span style="color:#f92672">(&lt;/span>C:&lt;span style="color:#ae81ff">\U&lt;/span>sers&lt;span style="color:#ae81ff">\u&lt;/span>sername/.ssh/id_rsa&lt;span style="color:#f92672">)&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># press enter login without password（安全性較低）&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 設定密碼的話，即使 private key 被盜，仍須密碼&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Enter passphrase &lt;span style="color:#f92672">(&lt;/span>empty &lt;span style="color:#66d9ef">for&lt;/span> no passphrase&lt;span style="color:#f92672">)&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Enter same passphrase again:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Your identification has been saved in C:&lt;span style="color:#ae81ff">\U&lt;/span>sers&lt;span style="color:#ae81ff">\u&lt;/span>sername/.ssh/id_rsa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Your public key has been saved in C:&lt;span style="color:#ae81ff">\U&lt;/span>sers&lt;span style="color:#ae81ff">\u&lt;/span>sername/.ssh/id_rsa.pub
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>The key fingerprint is:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SHA256:...省略... test@gmail.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>The key&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>s randomart image is:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>+---&lt;span style="color:#f92672">[&lt;/span>RSA 4096&lt;span style="color:#f92672">]&lt;/span>----+
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...省略...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="4-設定-ssh-連線">4. 設定 SSH 連線
&lt;/h2>&lt;h3 id="將公鑰加入遠端主機">將公鑰加入遠端主機
&lt;/h3>&lt;p>將本地的公鑰內容 (&lt;code>~/.ssh/id_rsa.pub&lt;/code>) 複製到遠端主機的 &lt;code>~/.ssh/authorized_keys&lt;/code> 檔案中，可使用指令：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ssh-copy-id user@remote_host
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>或手動複製本地內容到 server 中。&lt;/p>
&lt;p>On Linux or Mac, you can use the following command in the terminal to display your public key:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat ~/.ssh/id_rsa.pub
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="測試連線">測試連線
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ssh user@remote_host
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>若成功登入並且不需輸入密碼即設定完成。&lt;/p>
&lt;hr>
&lt;h2 id="5-常見應用情境">5. 常見應用情境
&lt;/h2>&lt;h3 id="使用-vscode-透過-ssh-遠端開發">使用 VSCode 透過 SSH 遠端開發
&lt;/h3>&lt;ol>
&lt;li>
&lt;p>安裝 &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh" target="_blank" rel="noopener"
>Remote - SSH 擴充套件&lt;/a>。&lt;br>
在 VSCode 中可看到 Remote-SSH 圖示，點擊後可進行連線設定：
&lt;img src="https://Dandelionlibra.github.io/image/Remote-SSH.png"
loading="lazy"
alt="Remote-SSH"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>點擊 VScode 左下角的雙箭頭圖標，或者按下 &lt;code>F1&lt;/code>，輸入 &lt;code>Remote-SSH: Connect to Host...&lt;/code>，選擇或新增主機。&lt;/p>
&lt;pre tabindex="0">&lt;code># remote_host 輸入伺服器 ip 位址
user@remote_host [-p port_number]
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>連線後輸入用戶在 server 上的密碼即可在遠端主機上開發，或者已經設定過金鑰可不用再輸密碼。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="使用-git-透過-ssh-進行版本控制">使用 Git 透過 SSH 進行版本控制
&lt;/h3>&lt;ol>
&lt;li>將公鑰加入 Git 服務（如 GitHub、GitLab）。&lt;/li>
&lt;li>使用 SSH 方式 clone 或 push：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>git clone git@github.com:username/repo.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="6-參考資料">6. 參考資料
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.openssh.com/manual.html" target="_blank" rel="noopener"
>OpenSSH 官方文件&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh" target="_blank" rel="noopener"
>GitHub SSH 教學&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://code.visualstudio.com/docs/remote/ssh" target="_blank" rel="noopener"
>VSCode Remote SSH 官方說明&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>LangChain 安裝與基本使用-1</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-1/</link><pubDate>Sun, 06 Jul 2025 15:33:11 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-1/</guid><description>&lt;h1 id="安裝-langchain">安裝 LangChain
&lt;/h1>&lt;p>使用 pip 指令安裝 LangChain 核心套件，其中提供各組件與基本框架。&lt;br>
LangChain 相關套件的詳細資訊可以參考&lt;a class="link" href="https://python.langchain.com/api_reference/" target="_blank" rel="noopener"
>langchain 官方文件&lt;/a>。&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install langchain
&lt;/code>&lt;/pre>&lt;p>安裝 LangChain 社群套件，其中包含由社群維護的第三方整合模組。&lt;br>
隨著 LangChain 的模組化，許多原本內建於核心套件的整合功能被轉移到此套件中，以保持核心套件的輕量化。&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install langchain_community
&lt;/code>&lt;/pre>&lt;p>安裝 LangChain 與本地 Ollama 模型整合專用驅動，
可以在 LangChain 中使用本地 Ollama 模型作為 LLM。
LangChain 官方維護的專門用於整合本地 Ollama LLM 的插件套件。&lt;/p>
&lt;p>因為 LangChain 在 0.3.1 後將原本內建於 &lt;code>langchain_community.llms.Ollama&lt;/code> 的 Ollama 整合模組 拆分為獨立的 &lt;code>langchain-ollama&lt;/code> 套件。&lt;br>
詳細資訊可以參考&lt;a class="link" href="https://python.langchain.com/api_reference/ollama/index.html" target="_blank" rel="noopener"
>langchain 官方文件&lt;/a>。&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install langchain-ollama
&lt;/code>&lt;/pre>&lt;h1 id="簡單應用">簡單應用
&lt;/h1>&lt;p>本文所有範例程式碼都可以在 &lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_code.ipynb" target="_blank" rel="noopener"
>Jupyter Notebook&lt;/a> 中找到。&lt;/p>
&lt;h2 id="文本生成">文本生成
&lt;/h2>&lt;p>LangChain 中 LLM 的最基本功能是根據輸入的文本生成新的文本。&lt;/p>
&lt;p>註:不清楚 Ollama 如何使用的可以去看我關於 Ollama 的基礎使用文章。&lt;/p>
&lt;pre tabindex="0">&lt;code>from langchain_ollama import OllamaLLM
llm = OllamaLLM(model=&amp;#34;llama3.1:8b&amp;#34;)
response = llm.invoke(&amp;#34;幫我取一個文雅的中國男孩名&amp;#34;)
print(response)
&lt;/code>&lt;/pre>&lt;p>temperature 用於控制 LLM 生成回答的隨機性與創造性。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;code>temperature&lt;/code> 值&lt;/th>
&lt;th>行為特性&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>0&lt;/code>&lt;/td>
&lt;td>完全可重現，幾乎總是給出相同回答，適合需要準確且穩定輸出時使用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>0.3 ~ 0.7&lt;/code>&lt;/td>
&lt;td>中度創造性，適合一般應用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>1.0&lt;/code>&lt;/td>
&lt;td>高度創造性，回答可能更多樣化與隨機&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>&amp;gt;1&lt;/code>&lt;/td>
&lt;td>非常隨機，回答可能跳脫常規&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>例如可以在剛剛的 response 中使用 options 將 temperature 設為 0，使輸出每次都會得到一樣的答案。&lt;/p>
&lt;pre tabindex="0">&lt;code>response = llm.invoke(&amp;#34;幫我取一個文雅的中國男孩名&amp;#34;, options={&amp;#34;temperature&amp;#34;: 0})
&lt;/code>&lt;/pre>&lt;h2 id="聊天模組">聊天模組
&lt;/h2>&lt;pre tabindex="0">&lt;code>from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage
Chatllm = ChatOllama(model=&amp;#34;llama3.1:8b&amp;#34;)
test = &amp;#34;幫我取一個文雅的中國男孩名&amp;#34;
messages = [HumanMessage(content=test)]
response = Chatllm.invoke(messages)
print(response)
&lt;/code>&lt;/pre>&lt;h3 id="ollamallm-vschatollama">OllamaLLM vs.ChatOllama
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>項目&lt;/th>
&lt;th>&lt;strong>OllamaLLM&lt;/strong>&lt;/th>
&lt;th>&lt;strong>ChatOllama&lt;/strong>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>來源&lt;/strong>&lt;/td>
&lt;td>&lt;code>from langchain_ollama import OllamaLLM&lt;/code>&lt;/td>
&lt;td>&lt;code>from langchain_ollama import ChatOllama&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>用途&lt;/strong>&lt;/td>
&lt;td>單輪文字生成（Single-turn LLM）&lt;/td>
&lt;td>多輪對話（Chat-based LLM）&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>典型應用場景&lt;/strong>&lt;/td>
&lt;td>單次回答、批次生成資料、文字生成工具&lt;/td>
&lt;td>聊天機器人、多輪上下文對話、Memory 結合&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>輸入型態&lt;/strong>&lt;/td>
&lt;td>&lt;code>str&lt;/code>（純文字 prompt）&lt;/td>
&lt;td>&lt;code>List[BaseMessage]&lt;/code>（包含 &lt;code>SystemMessage&lt;/code>, &lt;code>HumanMessage&lt;/code>, &lt;code>AIMessage&lt;/code>）&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>回傳型態&lt;/strong>&lt;/td>
&lt;td>&lt;code>str&lt;/code>（文字回應）&lt;/td>
&lt;td>&lt;code>AIMessage(content='...')&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>回傳內容存取&lt;/strong>&lt;/td>
&lt;td>直接使用 &lt;code>print(response)&lt;/code>&lt;/td>
&lt;td>使用 &lt;code>print(response.content)&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>是否支援多輪上下文&lt;/strong>&lt;/td>
&lt;td>X&lt;/td>
&lt;td>O&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>適合結合 Agent&lt;/strong>&lt;/td>
&lt;td>作為推論引擎&lt;/td>
&lt;td>作為 Chat Agent 對話引擎&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>可搭配 Memory&lt;/strong>&lt;/td>
&lt;td>X&lt;/td>
&lt;td>可搭配 Memory 實現上下文持續對話&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="鏈式結構">鏈式結構
&lt;/h2>&lt;p>連接多個 LLM 模組。
&lt;img src="https://Dandelionlibra.github.io/image/LLMChain.png"
loading="lazy"
alt="LLMChain"
>&lt;/p>
&lt;h3 id="如何避免重複定義相似的-llm-模組">如何避免重複定義相似的 LLM 模組?
&lt;/h3>&lt;p>使用提示模板(prompt template)去避免重複定義功能相似的組件。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.prompts &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm_model &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>user_prompt &lt;span style="color:#f92672">=&lt;/span> PromptTemplate&lt;span style="color:#f92672">.&lt;/span>from_template(&lt;span style="color:#e6db74">&amp;#34;幫我取一個&lt;/span>&lt;span style="color:#e6db74">{形容詞}{對象}&lt;/span>&lt;span style="color:#e6db74">名, 並對應一個小名。&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(user_prompt&lt;span style="color:#f92672">.&lt;/span>format(對象 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;寵物&amp;#39;&lt;/span>, 形容詞 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;可愛的&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(user_prompt&lt;span style="color:#f92672">.&lt;/span>format(對象 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;男孩&amp;#39;&lt;/span>, 形容詞 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;文雅的&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.chains &lt;span style="color:#f92672">import&lt;/span> LLMChain
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chain &lt;span style="color:#f92672">=&lt;/span> LLMChain(llm&lt;span style="color:#f92672">=&lt;/span>llm_model, prompt&lt;span style="color:#f92672">=&lt;/span>user_prompt)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(chain&lt;span style="color:#f92672">.&lt;/span>run(對象 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;小狗&amp;#39;&lt;/span>, 形容詞 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;有趣的&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="代理人">代理人
&lt;/h2>&lt;p>主要用於處理鏈式結構無法處理的問題，並可達成動態決策。
舉例而言，一般大型語言模型是無法聯網的，而為了讓 LangChain 去獲得最新的內容或者現有資料庫中不存在的資訊，就需要使用代理人 (Agents) 組件達成聯網。&lt;/p>
&lt;h3 id="行為方式">行為方式
&lt;/h3>&lt;p>代理人可以使用一系列預設的工具&lt;/p>
&lt;ul>
&lt;li>選擇工具&lt;/li>
&lt;li>使用工具&lt;/li>
&lt;li>觀測並處理工具使用結果&lt;/li>
&lt;li>重複以上步驟&lt;/li>
&lt;/ul>
&lt;h3 id="範例">範例
&lt;/h3>&lt;p>使代理人能完成數學運算任務。&lt;/p>
&lt;p>&lt;strong>step1: 定義底層 LLM 模組&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm_model &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>step2: 定義允許代理人使用的工具&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.agents &lt;span style="color:#f92672">import&lt;/span> initialize_agent, load_tools
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tools &lt;span style="color:#f92672">=&lt;/span> load_tools([&lt;span style="color:#e6db74">&amp;#34;llm-math&amp;#34;&lt;/span>], llm&lt;span style="color:#f92672">=&lt;/span>llm_model)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>step3: 初始化代理人&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>agent &lt;span style="color:#f92672">=&lt;/span> initialize_agent(tools, llm_model, agent&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;zero-shot-react-description&amp;#34;&lt;/span>, verbose&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>step4: 運行代理人&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>agent&lt;span style="color:#f92672">.&lt;/span>invoke(&lt;span style="color:#e6db74">&amp;#34;如果我有 100 元，買了 3 個蘋果，每個蘋果 10 元，剩下多少錢？&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="聊天紀錄">聊天紀錄
&lt;/h2>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm_model &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.chains &lt;span style="color:#f92672">import&lt;/span> ConversationChain
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>conversation &lt;span style="color:#f92672">=&lt;/span> ConversationChain(llm&lt;span style="color:#f92672">=&lt;/span>llm_model, verbose&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>conversation&lt;span style="color:#f92672">.&lt;/span>run(&lt;span style="color:#e6db74">&amp;#34;我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: 我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?
AI:
&amp;gt; Finished chain.
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>&amp;#39;啊哈！你想要一個聰明又可愛的伴侶嗎？我有一些超好的建議！基於你的描述，我推測你可能是新手狗主人，所以我要首先介紹一下最適合初學者的犬種。有了這些犬種，你就能輕鬆地培養起一個聽話又善良的伴侶。\n\n其中，拉布拉多犬和金氏體型小獵犬（Cavalier King Charles Spaniel）都很受人喜愛，.......你對於犬種的偏好是什麼？你想要一隻大犬還是一隻小犬呢？&amp;#39;
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>conversation&lt;span style="color:#f92672">.&lt;/span>run(&lt;span style="color:#e6db74">&amp;#34;那貓呢?&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: 我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?
AI: 啊哈！你想要一個聰明又可愛的伴侶嗎？我有一些超好的建議！基於你的描述，我推測你可能是新手狗主人，所以我要首先介紹一下最適合初學者的犬種。有了這些犬種，你就能輕鬆地培養起一個聽話又善良的伴侶。
...省略...
最後，我想問一下，你對於犬種的偏好是什麼？你想要一隻大犬還是一隻小犬呢？
Human: 那貓呢?
AI:
&amp;gt; Finished chain.
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>&amp;#39;貓！我很樂意幫助你找一個適合你的貓伴侶！但是，值得注意的是，我之前主要是在說狗的話題，因為我的訓練資料集中在犬類上。\n\n但是在貓類方面，我可以提供一些基本信息。...省略...或者你對貓的需求和生活方式是否有所變化？&amp;#39;
&lt;/code>&lt;/pre>&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Introduction langchain</title><link>https://Dandelionlibra.github.io/post/langchain/introlangchain/</link><pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/introlangchain/</guid><description>&lt;h1 id="介紹-langchain">介紹 LangChain
&lt;/h1>&lt;p>LangChain 為 2022 年發布的開源框架，主要用於開發由語言模型驅動的應用程式，可連接多種語言模型與外部工具。&lt;br>
&lt;a class="link" href="https://www.langchain.com" target="_blank" rel="noopener"
>LangChain 官方網站&lt;/a>
&lt;img src="https://Dandelionlibra.github.io/image/ecosystem_packages-32943b32657e7a187770c9b585f22a64.png"
loading="lazy"
alt="LLMChain"
>&lt;/p>
&lt;h2 id="優點">優點
&lt;/h2>&lt;ul>
&lt;li>開源工具&lt;/li>
&lt;li>支持多種開源模型&lt;/li>
&lt;li>可整合多項外部服務&lt;/li>
&lt;/ul>
&lt;h2 id="主要組件">主要組件
&lt;/h2>&lt;ul>
&lt;li>模型 (Models)
&lt;ul>
&lt;li>語言模型、文本嵌入模型等等&amp;hellip;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>記憶體 (Memory)
&lt;ul>
&lt;li>短期與長期記憶，用於儲存與檢索聊天歷史&lt;/li>
&lt;li>包含對話緩衝記憶體、實體記憶體、向量儲存記憶體&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>代理 (Agents)
&lt;ul>
&lt;li>推理引擎&lt;/li>
&lt;li>可以根據給定的情境與數據做出合理的決策與推理&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>LangChain 藉由這些組件連結各種模型與工具，以達成檢索與分析數據，並可進行個性化的訂製。&lt;/p>
&lt;h2 id="主要解決問題">主要解決問題
&lt;/h2>&lt;ul>
&lt;li>如何格式化輸出?&lt;/li>
&lt;li>如何輸出很長的文本?&lt;/li>
&lt;li>如何呼叫多次 api?&lt;/li>
&lt;li>如何使 api 能呼叫外部的服務、工具?&lt;/li>
&lt;li>如何進行標準化的開發?&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://python.langchain.com/docs/introduction/" target="_blank" rel="noopener"
>https://python.langchain.com/docs/introduction/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=feFp5TbrVMo" target="_blank" rel="noopener"
>https://www.youtube.com/watch?v=feFp5TbrVMo&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>How to install and use Ollama?</title><link>https://Dandelionlibra.github.io/post/ollama/ollama/</link><pubDate>Sat, 05 Jul 2025 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/ollama/ollama/</guid><description>&lt;h1 id="介紹-ollama">介紹 Ollama
&lt;/h1>&lt;p>Ollama 是一個能在 本地（Windows/Mac/Linux）執行大型語言模型（LLM）和 Vision Language Model（VLM） 的框架。&lt;/p>
&lt;ul>
&lt;li>開源工具&lt;/li>
&lt;li>在本地端運行大型語言模型&lt;/li>
&lt;li>離線特性以保護隱私&lt;/li>
&lt;/ul>
&lt;h1 id="安裝-ollama">安裝 Ollama
&lt;/h1>&lt;h2 id="windows">Windows
&lt;/h2>&lt;p>至 &lt;a class="link" href="https://ollama.com/" target="_blank" rel="noopener"
>Ollama 官方網站&lt;/a>
下載 windows 版本後，點擊執行檔安裝。&lt;br>
安裝後於終端機中測試是否安裝成功。&lt;/p>
&lt;pre tabindex="0">&lt;code>ollama --help
&lt;/code>&lt;/pre>&lt;h2 id="mac">Mac
&lt;/h2>&lt;p>參考官方文件的下載指令。&lt;/p>
&lt;pre tabindex="0">&lt;code>brew install ollama
&lt;/code>&lt;/pre>&lt;h2 id="linux">Linux
&lt;/h2>&lt;p>參考官方文件的下載指令。&lt;/p>
&lt;pre tabindex="0">&lt;code>curl -fsSL https://ollama.com/install.sh | sh
&lt;/code>&lt;/pre>&lt;h1 id="如何使用-ollama">如何使用 Ollama?
&lt;/h1>&lt;h3 id="在本地啟動服務">在本地啟動服務
&lt;/h3>&lt;pre tabindex="0">&lt;code>ollama serve
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama serve
&lt;/code>&lt;/pre>&lt;h3 id="執行語言模型">執行語言模型
&lt;/h3>&lt;p>可以參考官方文件中提供的模型 &lt;a class="link" href="https://ollama.com/search" target="_blank" rel="noopener"
>https://ollama.com/search&lt;/a>&lt;/p>
&lt;pre tabindex="0">&lt;code>ollama run [model name]
&lt;/code>&lt;/pre>&lt;p>若是第一次運行該模型則會執行下載。
minicpm-V 是可用於解說圖片的語言模型，使用 &lt;code>/bye&lt;/code> 離開。&lt;/p>
&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama run minicpm-v:latest
pulling manifest
pulling 262843d4806a: 100% ▕█████████████████▏ 4.4 GB
pulling f8a805e9e620: 100% ▕█████████████████▏ 1.0 GB
pulling 60ed67c565f8: 100% ▕█████████████████▏ 506 B
pulling 8603ca877636: 100% ▕█████████████████▏ 5.7 KB
pulling f02dd72bb242: 100% ▕█████████████████▏ 59 B
pulling 175e3bb367ab: 100% ▕█████████████████▏ 566 B
verifying sha256 digest
writing manifest
success
&amp;gt;&amp;gt;&amp;gt; Discribe this picture &amp;#34;C:\Users\user\Downloads\picture.png&amp;#34;
Added image &amp;#39;C:\Users\user\Downloads\picture.png&amp;#39;
This image depicts a small white rodent sitting on the ground in an
outdoor setting. The animal appears to have soft fur with light
brownish-grey patches around its eyes and ears. Its pink nose is
prominent, as are its large black eyes which stand out against its pale
face.
&amp;gt;&amp;gt;&amp;gt; /bye
&lt;/code>&lt;/pre>&lt;p>終端呼叫模型並輸入指令。&lt;/p>
&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama run llama3.1:8b &amp;#34;define what is atom&amp;#34;
An **atom** (from the Greek word &amp;#34;atomos,&amp;#34; meaning indivisible) is the smallest
unit of a chemical element that retains its chemical properties and is
considered the fundamental building block of matter.
In simpler terms, an atom is:
1. **Indivisible**: An atom cannot be broken down into smaller particles using
any known means.
2. **Stable**: Atoms are stable entities that do not change their structure or
composition over time.
3. **Unique**: Each element has a unique set of atoms with specific properties.
... 忽略 ...
Would you like me to explain any related concepts or clarify anything about
atoms?
&lt;/code>&lt;/pre>&lt;h3 id="查看目前已安裝的語言模型">查看目前已安裝的語言模型
&lt;/h3>&lt;pre tabindex="0">&lt;code>ollama list
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama list
NAME ID SIZE MODIFIED
minicpm-v:latest c92bfad01205 5.5 GB 2 hours ago
llama3.1:8b 46e0c10c039e 4.9 GB 2 hours ago
&lt;/code>&lt;/pre>&lt;h3 id="刪除已安裝的語言模型">刪除已安裝的語言模型
&lt;/h3>&lt;pre tabindex="0">&lt;code>ollama rm [model name]
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama rm minicpm-v:latest
deleted &amp;#39;minicpm-v:latest&amp;#39;
C:\Users\user&amp;gt;ollama list
NAME ID SIZE MODIFIED
llama3.1:8b 46e0c10c039e 4.9 GB 8 hours ago
&lt;/code>&lt;/pre>&lt;h3 id="">
&lt;/h3>&lt;h3 id="role-的-3-個主要類型">&lt;code>role&lt;/code> 的 3 個主要類型
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>role&lt;/th>
&lt;th>說明&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>system&lt;/code>&lt;/td>
&lt;td>系統角色，設定「這個模型該如何表現自己」，定義整個對話的角色背景、口吻、限制。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>user&lt;/code>&lt;/td>
&lt;td>使用者角色，模擬真實使用者輸入的訊息。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>assistant&lt;/code>&lt;/td>
&lt;td>模型扮演的角色回覆。用來提供上下文（例如多輪對話）。&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="使用-python-與程式串接">使用 Python 與程式串接
&lt;/h2>&lt;h3 id="使用-requests-呼叫">使用 requests 呼叫
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> requests
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># API URL&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>url &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;http://127.0.0.1:11434/v1/chat/completions&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 請求資料&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>payload &lt;span style="color:#f92672">=&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;model&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 對應你本地拉取的模型名稱&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;messages&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;system&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;You are a helpful assistant.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What is the capital of France?&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;assistant&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;The capital of France is Paris.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What is the population of Paris?&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;assistant&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;As of 2023, the population of Paris is about 2.1 million.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What river flows through Paris?&amp;#34;&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Headers&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>headers &lt;span style="color:#f92672">=&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;Content-Type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;application/json&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># &amp;#34;Authorization&amp;#34;: &amp;#34;Bearer ollama&amp;#34; # 傳遞身份驗證資訊，本地伺服器預設不驗證金鑰可省略&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 發送 POST 請求&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> requests&lt;span style="color:#f92672">.&lt;/span>post(url, headers&lt;span style="color:#f92672">=&lt;/span>headers, data&lt;span style="color:#f92672">=&lt;/span>json&lt;span style="color:#f92672">.&lt;/span>dumps(payload))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 顯示結果&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> response&lt;span style="color:#f92672">.&lt;/span>status_code &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span>: &lt;span style="color:#75715e"># HTTP 狀態碼 200 代表請求成功。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> response&lt;span style="color:#f92672">.&lt;/span>json() &lt;span style="color:#75715e"># 解析 JSON 資料，此方法將回應內容（ex.字串）轉換成 Python 的資料結構（ex.dict）&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(data[&lt;span style="color:#e6db74">&amp;#34;choices&amp;#34;&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;message&amp;#34;&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;Error:&amp;#34;&lt;/span>, response&lt;span style="color:#f92672">.&lt;/span>status_code, response&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>response 返回結構類似：&lt;/p>
&lt;pre tabindex="0">&lt;code>{
&amp;#34;id&amp;#34;: &amp;#34;chatcmpl-1234567890abcdef&amp;#34;,
&amp;#34;object&amp;#34;: &amp;#34;chat.completion&amp;#34;,
&amp;#34;created&amp;#34;: 1700000000,
&amp;#34;model&amp;#34;: &amp;#34;llama3.1:8b&amp;#34;,
&amp;#34;choices&amp;#34;: [
{
&amp;#34;index&amp;#34;: 0,
&amp;#34;message&amp;#34;: {
&amp;#34;role&amp;#34;: &amp;#34;assistant&amp;#34;,
&amp;#34;content&amp;#34;: &amp;#34;The capital of France is Paris.&amp;#34;
},
&amp;#34;finish_reason&amp;#34;: &amp;#34;stop&amp;#34;
}
],
&amp;#34;usage&amp;#34;: {
&amp;#34;prompt_tokens&amp;#34;: 20,
&amp;#34;completion_tokens&amp;#34;: 10,
&amp;#34;total_tokens&amp;#34;: 30
}
}
&lt;/code>&lt;/pre>&lt;h3 id="使用-openai-sdk-呼叫">使用 openai SDK 呼叫
&lt;/h3>&lt;h4 id="安裝-openai">安裝 openai
&lt;/h4>&lt;p>使用 pip 指令進行安裝。&lt;br>
ps.若沒有 pip 我未來再寫一篇安裝與使用 pip 的文章 ;)&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install openai
&lt;/code>&lt;/pre>&lt;p>查看安裝版本 &amp;amp; 是否已安裝過&lt;/p>
&lt;pre tabindex="0">&lt;code>pip show openai
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>WARNING: Package(s) not found: openai
&lt;/code>&lt;/pre>&lt;p>若已安裝過且版本小於 1.0.0，更新 openai 套件&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install --upgrade openai
&lt;/code>&lt;/pre>&lt;h3 id="使用語言模型">使用語言模型
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> openai &lt;span style="color:#f92672">import&lt;/span> OpenAI
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>client &lt;span style="color:#f92672">=&lt;/span> OpenAI(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># base_url = &amp;#34;http://localhost:11434/v1&amp;#34;,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> base_url &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;http://127.0.0.1:11434/v1&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 本地 Ollama 伺服器的 URL，預設端口為 11434&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> api_key &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;ollama&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 本地 Ollama 不驗證密鑰，只要隨意填入即可，習慣使用 ollama&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 呼叫本地 Ollama 伺服器進行 Chat Completion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> client&lt;span style="color:#f92672">.&lt;/span>chat&lt;span style="color:#f92672">.&lt;/span>completions&lt;span style="color:#f92672">.&lt;/span>create(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> messages&lt;span style="color:#f92672">=&lt;/span>[ &lt;span style="color:#75715e"># 設定對話內容&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;system&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 設定模型行為&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;You are a helpful assistant.&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 使用者輸入的問題&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What is the capital of France?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(response&lt;span style="color:#f92672">.&lt;/span>choices[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>message&lt;span style="color:#f92672">.&lt;/span>content)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="使用-vision-model">使用 Vision model
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> base64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> openai &lt;span style="color:#f92672">import&lt;/span> OpenAI
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_path &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">r&lt;/span>&lt;span style="color:#e6db74">&amp;#34;C:\圖片路徑.png&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> open(image_path, &lt;span style="color:#e6db74">&amp;#34;rb&amp;#34;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> img_file:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> b64_string &lt;span style="color:#f92672">=&lt;/span> base64&lt;span style="color:#f92672">.&lt;/span>b64encode(img_file&lt;span style="color:#f92672">.&lt;/span>read())&lt;span style="color:#f92672">.&lt;/span>decode(&lt;span style="color:#e6db74">&amp;#34;utf-8&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 建立可傳入 Ollama 的完整 URL 字串&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_b64_url &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;data:image/png;base64,&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>b64_string&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>client &lt;span style="color:#f92672">=&lt;/span> OpenAI(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> base_url&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;http://127.0.0.1:11434/v1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> api_key&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;ollama&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> client&lt;span style="color:#f92672">.&lt;/span>chat&lt;span style="color:#f92672">.&lt;/span>completions&lt;span style="color:#f92672">.&lt;/span>create(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;minicpm-v&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 支援圖片輸入的模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> messages&lt;span style="color:#f92672">=&lt;/span>[
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Please describe the image in detail.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;image_url&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;image_url&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;url&amp;#34;&lt;/span>: image_b64_url
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(response&lt;span style="color:#f92672">.&lt;/span>choices[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>message&lt;span style="color:#f92672">.&lt;/span>content)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>31. Next Permutation</title><link>https://Dandelionlibra.github.io/post/leetcode/31/leetcode/</link><pubDate>Sun, 02 Feb 2025 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/leetcode/31/leetcode/</guid><description>&lt;h2 id="題目">題目
&lt;/h2>&lt;p>A permutation of an array of integers is an arrangement of its members into a sequence or linear order.&lt;/p>
&lt;p>For example, for arr = [1,2,3], the following are all the permutations of arr: [1,2,3], [1,3,2], [2, 1, 3], [2, 3, 1], [3,1,2], [3,2,1].
The next permutation of an array of integers is the next lexicographically greater permutation of its integer. More formally, if all the permutations of the array are sorted in one container according to their lexicographical order, then the next permutation of that array is the permutation that follows it in the sorted container. If such arrangement is not possible, the array must be rearranged as the lowest possible order (i.e., sorted in ascending order).&lt;/p>
&lt;p>For example, the next permutation of arr = [1,2,3] is [1,3,2].
Similarly, the next permutation of arr = [2,3,1] is [3,1,2].
While the next permutation of arr = [3,2,1] is [1,2,3] because [3,2,1] does not have a lexicographical larger rearrangement.
Given an array of integers nums, find the next permutation of nums.&lt;/p>
&lt;p>The replacement must be in place and use only constant extra memory.&lt;/p>
&lt;h3 id="constraints">Constraints:
&lt;/h3>&lt;ul>
&lt;li>1 &amp;lt;= nums.length &amp;lt;= 100&lt;/li>
&lt;li>0 &amp;lt;= nums[i] &amp;lt;= 100&lt;/li>
&lt;/ul>
&lt;h3 id="example-1">Example 1:
&lt;/h3>&lt;blockquote>
&lt;p>Input: nums = [1,2,3]&lt;br>
Output: [1,3,2]&lt;/p>&lt;/blockquote>
&lt;h3 id="example-2">Example 2:
&lt;/h3>&lt;blockquote>
&lt;p>Input: nums = [3,2,1]&lt;br>
Output: [1,2,3]&lt;/p>&lt;/blockquote>
&lt;h3 id="example-2-1">Example 2:
&lt;/h3>&lt;blockquote>
&lt;p>Input: nums = [1,1,5]&lt;br>
Output: [1,5,1]&lt;/p>&lt;/blockquote>
&lt;h2 id="解題方法">解題方法
&lt;/h2>&lt;ol>
&lt;li>
&lt;p>從右向左尋找遞減序列的轉折點：
找到第一個位置 i，使得 nums[i] &amp;lt; nums[i + 1]。這表示從 i 之後的數字是遞減的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果找不到，說明當前排列是最大的，直接反轉陣列：
如果整個陣列是遞減的（如 [3, 2, 1]），則直接反轉整個陣列變為最小排列（如 [1, 2, 3]）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>找到比 nums[i] 大的最小數字並交換：
在 i 右邊的數字中，找到最接近且比 nums[i] 大的數字 nums[j]，然後交換 nums[i] 和 nums[j]。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>反轉 i + 1 之後的子陣列：
這樣能保證轉折點後的數字變為最小排列，確保整體是下一個排列。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="程式">程式
&lt;/h2>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-C" data-lang="C">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#include&lt;/span> &lt;span style="color:#75715e">&amp;lt;bits/stdc++.h&amp;gt;&lt;/span>&lt;span style="color:#75715e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>using namespace std;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>class Solution {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>public:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">nextPermutation&lt;/span>(vector&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#66d9ef">int&lt;/span>&lt;span style="color:#f92672">&amp;gt;&amp;amp;&lt;/span> nums) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> size &lt;span style="color:#f92672">=&lt;/span> nums.&lt;span style="color:#a6e22e">size&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cout &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> size ;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">int&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>(){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Solution sol;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cout &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> sol.&lt;span style="color:#a6e22e">divide&lt;/span>(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2147483648&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> endl;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>Photo by &lt;a class="link" href="https://unsplash.com/@pawel_czerwinski" target="_blank" rel="noopener"
>Pawel Czerwinski&lt;/a> on &lt;a class="link" href="https://unsplash.com/" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>&lt;/blockquote></description></item><item><title>29. Divide Two Integers</title><link>https://Dandelionlibra.github.io/post/leetcode/29/leetcode/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/leetcode/29/leetcode/</guid><description>&lt;h2 id="題目">題目
&lt;/h2>&lt;p>Given two integers dividend and divisor, divide two integers without using multiplication, division, and mod operator.&lt;/p>
&lt;p>The integer division should truncate toward zero, which means losing its fractional part. For example, 8.345 would be truncated to 8, and -2.7335 would be truncated to -2.&lt;/p>
&lt;p>Return the quotient after dividing dividend by divisor.&lt;/p>
&lt;p>Note: Assume we are dealing with an environment that could only store integers within the 32-bit signed integer range: $[−2^{31}, 2^{31} − 1]$. For this problem, if the quotient is strictly greater than $2^{31} - 1$, then return $2^{31} - 1$, and if the quotient is strictly less than $-2^{31}$, then return $-2^{31}$.&lt;/p>
&lt;h3 id="constraints">Constraints:
&lt;/h3>&lt;ul>
&lt;li>$-2^{31}$ &amp;lt;= dividend, divisor &amp;lt;= $-2^{31}-1$&lt;/li>
&lt;li>divisor != 0&lt;/li>
&lt;/ul>
&lt;h3 id="example-1">Example 1:
&lt;/h3>&lt;blockquote>
&lt;p>Input: dividend = 10, divisor = 3&lt;br>
Output: 3&lt;br>
Explanation: 10/3 = 3.33333.. which is truncated to 3.&lt;/p>&lt;/blockquote>
&lt;h3 id="example-2">Example 2:
&lt;/h3>&lt;blockquote>
&lt;p>Input: dividend = 7, divisor = -3&lt;br>
Output: -2&lt;br>
Explanation: 7/-3 = -2.33333.. which is truncated to -2.&lt;/p>&lt;/blockquote>
&lt;h2 id="解題方法">解題方法
&lt;/h2>&lt;h2 id="程式">程式
&lt;/h2>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-C" data-lang="C">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#include&lt;/span> &lt;span style="color:#75715e">&amp;lt;bits/stdc++.h&amp;gt;&lt;/span>&lt;span style="color:#75715e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>using namespace std;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>class Solution {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>public:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> &lt;span style="color:#a6e22e">divide&lt;/span>(&lt;span style="color:#66d9ef">int&lt;/span> dividend, &lt;span style="color:#66d9ef">int&lt;/span> divisor) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 特殊情況處理，避免溢出
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (dividend &lt;span style="color:#f92672">==&lt;/span> INT_MIN &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> divisor &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#66d9ef">return&lt;/span> INT_MAX;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (dividend &lt;span style="color:#f92672">==&lt;/span> INT_MIN &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> divisor &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#66d9ef">return&lt;/span> INT_MIN;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 計算商的正負
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> positive &lt;span style="color:#f92672">=&lt;/span> (dividend &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#f92672">==&lt;/span> (divisor &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 使用 long long 來避免 INT_MIN 的溢出
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">long&lt;/span> divd &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">labs&lt;/span>(dividend);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">long&lt;/span> div &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">labs&lt;/span>(divisor);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">long&lt;/span> result &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 當被除數大於除數時，進行除法
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">while&lt;/span> (divd &lt;span style="color:#f92672">&amp;gt;=&lt;/span> div) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">long&lt;/span> temp &lt;span style="color:#f92672">=&lt;/span> div, multiple &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 進行倍增操作，找到最大的倍數
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">while&lt;/span> (divd &lt;span style="color:#f92672">&amp;gt;=&lt;/span> (temp &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>)) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> temp &lt;span style="color:#f92672">&amp;lt;&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> multiple &lt;span style="color:#f92672">&amp;lt;&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 減去倍數對應的部分，並將商加到結果中
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> divd &lt;span style="color:#f92672">-=&lt;/span> temp;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result &lt;span style="color:#f92672">+=&lt;/span> multiple;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 根據正負符號調整結果
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> result &lt;span style="color:#f92672">=&lt;/span> positive &lt;span style="color:#f92672">?&lt;/span> result : &lt;span style="color:#f92672">-&lt;/span>result;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 最後檢查是否溢出
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">return&lt;/span> result &lt;span style="color:#f92672">&amp;gt;&lt;/span> INT_MAX &lt;span style="color:#f92672">?&lt;/span> INT_MAX : (result &lt;span style="color:#f92672">&amp;lt;&lt;/span> INT_MIN &lt;span style="color:#f92672">?&lt;/span> INT_MIN : result);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">int&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>(){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Solution sol;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cout &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> sol.&lt;span style="color:#a6e22e">divide&lt;/span>(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2147483648&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> endl;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>Photo by &lt;a class="link" href="https://unsplash.com/@pawel_czerwinski" target="_blank" rel="noopener"
>Pawel Czerwinski&lt;/a> on &lt;a class="link" href="https://unsplash.com/" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>&lt;/blockquote></description></item><item><title>微表情(Micro Facial Expression)</title><link>https://Dandelionlibra.github.io/post/note/micro_facial_expression/</link><pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/note/micro_facial_expression/</guid><description>&lt;img src="https://Dandelionlibra.github.io/unsplash.jpg" alt="Featured image of post 微表情(Micro Facial Expression)" />&lt;h2 id="臉部表情種類">臉部表情種類
&lt;/h2>&lt;p>&lt;a class="link" href="https://zh.wikipedia.org/zh-tw/%E4%BF%9D%E7%BD%97%C2%B7%E8%89%BE%E5%85%8B%E6%9B%BC" target="_blank" rel="noopener"
>保羅·艾克曼&lt;/a>（Paul Ekman）從1970年代以來的研究，把臉部微表情分成：&lt;/p>
&lt;ul>
&lt;li>快樂(happy)&lt;/li>
&lt;li>悲傷(sad)&lt;/li>
&lt;li>生氣(angry)&lt;/li>
&lt;li>驚訝(surprised)&lt;/li>
&lt;li>害怕(scared)&lt;/li>
&lt;li>厭惡(disgusted)&lt;/li>
&lt;li>鄙視(contempt)&lt;/li>
&lt;li>中性(neutral)&lt;/li>
&lt;/ul>
&lt;h2 id="微表情應用">微表情應用
&lt;/h2>&lt;blockquote>
&lt;p>臺師大邱美虹：「我希望用新興科技找到學生在學習科學知識時的難點，改善科學學習時的困境。而其中的一步，就是用辨識微表情的AI系統，找出學生面對非預期的科學現象和多重表徵的解釋所出現的某些特定微表情時所代表的意義，以瞭解學生面對這些情況時的反應與效益，以便設計有意義的學習和教學策略。」&lt;br>
&lt;a class="link" href="https://humanityisland.nccu.edu.tw/qiumeihong_a/" target="_blank" rel="noopener"
>文章報導&lt;/a>&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>迪士尼研究中心(FVAE – 深度學習觀眾表情，安排劇情走向)，在黑暗的影廳內觀察觀眾的臉部表情，並學習分辨微笑、大笑等不同程度的情緒。這樣的神經網絡學習，不只要調查你有多喜歡當下的劇情，更要預測你是否可能喜歡接下來的走向，它能根據過去學習的結果，在開演的前十分鐘就預測觀眾之後的情緒！&lt;br>
&lt;a class="link" href="https://mile.cloud/zh/resources/blog/facial-detection-technology-is-popular-quantifying-micro-expressions-into-big-data_39" target="_blank" rel="noopener"
>文章報導&lt;/a>&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>將微表情應用於面試上，也能準確抓出應徵者的職場性格與溝通能力，提前協助面試官篩除不適任的員工。&lt;br>
&lt;a class="link" href="https://www.ithome.com.tw/news/143000" target="_blank" rel="noopener"
>文章報導&lt;/a>&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>監控升級：人臉識別系統能讀出情緒和威脅性&lt;br>
&lt;a class="link" href="https://www.bbc.com/zhongwen/trad/world-44859007" target="_blank" rel="noopener"
>文章報導&lt;/a>&lt;/p>&lt;/blockquote>
&lt;h2 id="參考內容">參考內容
&lt;/h2>&lt;p>淺談為表情心理學：https://www.thenewslens.com/article/128732&lt;/p>
&lt;blockquote>
&lt;p>Photo by &lt;a class="link" href="https://unsplash.com/@pawel_czerwinski" target="_blank" rel="noopener"
>Pawel Czerwinski&lt;/a> on &lt;a class="link" href="https://unsplash.com/" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>&lt;/blockquote></description></item><item><title>Example content</title><link>https://Dandelionlibra.github.io/post/hello-world/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/hello-world/</guid><description>&lt;img src="https://Dandelionlibra.github.io/post/hello-world/unsplash.jpg" alt="Featured image of post Example content" />&lt;p>Welcome to Hugo theme Stack. This is your first post. Edit or delete it, then start writing!&lt;/p>
&lt;p>For more information about this theme, check the documentation: &lt;a class="link" href="https://stack.jimmycai.com/" target="_blank" rel="noopener"
>https://stack.jimmycai.com/&lt;/a>&lt;/p>
&lt;p>Want a site like this? Check out &lt;a class="link" href="https://github.com/CaiJimmy/hugo-theme-stack-starter" target="_blank" rel="noopener"
>hugo-theme-stack-stater&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Photo by &lt;a class="link" href="https://unsplash.com/@pawel_czerwinski" target="_blank" rel="noopener"
>Pawel Czerwinski&lt;/a> on &lt;a class="link" href="https://unsplash.com/" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>&lt;/blockquote></description></item><item><title>Profile</title><link>https://Dandelionlibra.github.io/about/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/about/</guid><description>&lt;p>你好:)&lt;/p></description></item><item><title>使用 Docker-compose 快速建立多個關聯的 container</title><link>https://Dandelionlibra.github.io/post/virtual-environment/docker/docker-compose/</link><pubDate>Thu, 17 Jul 2025 10:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/virtual-environment/docker/docker-compose/</guid><description>&lt;h2 id="內容大綱">內容大綱
&lt;/h2>&lt;ol>
&lt;li>為什麼要用 Docker-compose?&lt;/li>
&lt;li>Docker-compose 基本語法與結構&lt;/li>
&lt;li>建立多個關聯容器的範例&lt;/li>
&lt;li>常用指令與管理方式&lt;/li>
&lt;li>參考資料&lt;/li>
&lt;/ol>
&lt;h2 id="1-為什麼要用-docker-compose">1. 為什麼要用 Docker-compose？
&lt;/h2>&lt;p>當專案需要多個服務（如資料庫、後端、前端）協同運作時，單靠 &lt;code>docker run&lt;/code> 指令管理多個容器會變得複雜。Docker-compose 讓你能用一份 YAML 設定檔，定義多個 container 的建置、網路、資料掛載與依賴關係，一鍵啟動或關閉整個應用環境，提升開發效率與可維護性。&lt;/p>
&lt;hr>
&lt;h2 id="2-docker-compose-基本語法與結構">2. Docker-compose 基本語法與結構
&lt;/h2>&lt;p>Docker-compose 透過 &lt;code>docker-compose.yml&lt;/code> 檔案描述多個服務、網路、資料卷，並可設定健康檢查與指定 GPU。基本結構如下：&lt;/p>
&lt;p>詳細說明可參考官方文件：&lt;a class="link" href="https://docs.docker.com/reference/compose-file/services/" target="_blank" rel="noopener"
>Docker Compose&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;3.8&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">服務名稱&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">映像檔名稱&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;主機port:容器port&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">主機路徑:容器路徑&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">自訂網路名稱&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">deploy&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">reservations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">devices&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">driver&lt;/span>: &lt;span style="color:#ae81ff">nvidia&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">count&lt;/span>: &lt;span style="color:#ae81ff">all&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">capabilities&lt;/span>: [&lt;span style="color:#ae81ff">gpu]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">healthcheck&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">test&lt;/span>: [&lt;span style="color:#e6db74">&amp;#34;CMD&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;你的健康檢查指令&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">interval&lt;/span>: &lt;span style="color:#ae81ff">30s&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">timeout&lt;/span>: &lt;span style="color:#ae81ff">10s&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">retries&lt;/span>: &lt;span style="color:#ae81ff">3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">start_period&lt;/span>: &lt;span style="color:#ae81ff">60s&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">自訂網路名稱&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">driver&lt;/span>: &lt;span style="color:#ae81ff">bridge&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>services&lt;/code>: 定義多個容器服務。&lt;/li>
&lt;li>&lt;code>image&lt;/code>: 指定映像檔。&lt;/li>
&lt;li>&lt;code>ports&lt;/code>: 對應主機與容器的 port。&lt;/li>
&lt;li>&lt;code>volumes&lt;/code>: 掛載主機資料夾到容器。&lt;/li>
&lt;li>&lt;code>networks&lt;/code>: 定義自訂網路，讓服務間可互通。&lt;/li>
&lt;li>&lt;code>deploy.resources.reservations.devices&lt;/code>: 指定 GPU 資源。&lt;/li>
&lt;li>&lt;code>healthcheck&lt;/code>: 健康檢查設定，確保服務正常運作。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="3-建立多個關聯容器的範例">3. 建立多個關聯容器的範例
&lt;/h2>&lt;p>以下範例說明如何用 Docker-compose 同時啟動 Jupyter（支援 GPU）與 Ollama 兩個服務，並讓它們透過自訂網路 &lt;code>ollama_net&lt;/code> 互相溝通：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">dandelion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ollama_net&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">driver&lt;/span>: &lt;span style="color:#ae81ff">bridge&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">jupyter&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tty&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;8888:8888&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">~/yuchen:/workspace/yuchen&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">ollama_net&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">deploy&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">reservations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">devices&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">driver&lt;/span>: &lt;span style="color:#ae81ff">nvidia&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">count&lt;/span>: &lt;span style="color:#ae81ff">all&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">capabilities&lt;/span>: [&lt;span style="color:#ae81ff">gpu]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ollama&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tty&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">ollama/ollama&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">ollama_net&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">~/yuchen/ollama:/root/.ollama&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;11435:11434&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">deploy&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">reservations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">devices&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">driver&lt;/span>: &lt;span style="color:#ae81ff">nvidia&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">count&lt;/span>: &lt;span style="color:#ae81ff">all&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">capabilities&lt;/span>: [&lt;span style="color:#ae81ff">gpu]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">healthcheck&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">test&lt;/span>: &lt;span style="color:#ae81ff">/usr/local/bin/docker-healthcheck.sh&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">interval&lt;/span>: &lt;span style="color:#ae81ff">30s&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">timeout&lt;/span>: &lt;span style="color:#ae81ff">10s&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">retries&lt;/span>: &lt;span style="color:#ae81ff">3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">start_period&lt;/span>: &lt;span style="color:#ae81ff">60s&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>networks&lt;/code> 讓 jupyter 與 ollama 服務可互通。&lt;/li>
&lt;li>&lt;code>port&lt;/code>
&lt;ul>
&lt;li>&amp;ldquo;11435:11434&amp;rdquo; 表示將主機（對外）上的 11435 端口映射到容器（對內）中的 11434 端口。&lt;/li>
&lt;li>外部訪問主機的 11435 端口時，實際會轉發到容器內部的 11434 端口。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>deploy.resources.reservations.devices&lt;/code> 指定兩個服務都可使用所有 GPU。&lt;/li>
&lt;li>&lt;code>healthcheck&lt;/code> 可自動檢查服務健康狀態。&lt;/li>
&lt;li>&lt;code>volumes&lt;/code> 保持資料持久化。&lt;/li>
&lt;/ul>
&lt;p>這樣設定後，只需一行指令即可同時啟動、管理多個容器，並確保它們能互相連線與資料共享。&lt;/p>
&lt;p>啟動所有服務：&lt;br>
&lt;code>-d&lt;/code> 參數代表「detached mode」，也就是讓 Docker-Compose 在背景執行所有服務，而不佔用目前的終端視窗，不會顯示即時日誌。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker-compose up -d
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>停止並移除所有服務：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker-compose down
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="4-常用指令與管理方式">4. 常用指令與管理方式
&lt;/h2>&lt;ul>
&lt;li>啟動所有服務：&lt;code>docker-compose up&lt;/code>&lt;/li>
&lt;li>背景執行：&lt;code>docker-compose up -d&lt;/code>&lt;/li>
&lt;li>停止服務：&lt;code>docker-compose down&lt;/code>&lt;/li>
&lt;li>查看日誌：&lt;code>docker-compose logs&lt;/code>&lt;/li>
&lt;li>進入容器：&lt;code>docker-compose exec &amp;lt;service&amp;gt; bash&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>更多指令可參考 &lt;a class="link" href="https://docs.docker.com/compose/reference/overview/" target="_blank" rel="noopener"
>官方文件&lt;/a>。&lt;/p>
&lt;hr>
&lt;h2 id="5-參考資料">5. 參考資料
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.docker.com/compose/" target="_blank" rel="noopener"
>Docker Compose 官方文件&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.docker.com/" target="_blank" rel="noopener"
>Docker 官方網站&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dandelionlibra.github.io/post/virtual-environment/docker/setup-jupyter-notebook-with-docker/" target="_blank" rel="noopener"
>如何安裝 Docker（延伸閱讀）&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docker 基本使用指令</title><link>https://Dandelionlibra.github.io/post/virtual-environment/docker/docker/</link><pubDate>Thu, 10 Jul 2025 10:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/virtual-environment/docker/docker/</guid><description>&lt;h2 id="內容大綱">內容大綱
&lt;/h2>&lt;ol>
&lt;li>Docker 是什麼？&lt;/li>
&lt;li>Docker 常用指令與參數說明&lt;/li>
&lt;li>Docker 實用操作範例&lt;/li>
&lt;li>參考資料&lt;/li>
&lt;/ol>
&lt;h2 id="1-docker-是什麼">1. Docker 是什麼？
&lt;/h2>&lt;p>Docker 是一套開源的容器化平台，讓開發者能夠將應用程式及其依賴環境打包成一個輕量級、可攜帶的容器（Container）。這些容器可以在任何支援 Docker 的作業系統上快速部署與執行，解決「在我電腦可以跑」的問題，提升開發、測試與部署的效率。&lt;/p>
&lt;hr>
&lt;h2 id="2-docker-常用指令與參數說明">2. Docker 常用指令與參數說明
&lt;/h2>&lt;p>以下介紹幾個 Docker 常用指令及其重要參數：&lt;/p>
&lt;h3 id="啟動容器">啟動容器
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#f92672">[&lt;/span>OPTIONS&lt;span style="color:#f92672">]&lt;/span> IMAGE &lt;span style="color:#f92672">[&lt;/span>COMMAND&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">[&lt;/span>ARG...&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="常用參數">常用參數
&lt;/h3>&lt;ul>
&lt;li>&lt;code>-d, --detach&lt;/code>：在背景執行容器。&lt;/li>
&lt;li>&lt;code>--detach-keys&lt;/code>：自訂分離容器的鍵組合。&lt;/li>
&lt;li>&lt;code>-e, --env&lt;/code>：設定環境變數。&lt;/li>
&lt;li>&lt;code>--env-file&lt;/code>：從檔案讀取環境變數。&lt;/li>
&lt;li>&lt;code>-i, --interactive&lt;/code>：保持標準輸入開啟（互動模式）。&lt;/li>
&lt;li>&lt;code>-t, --tty&lt;/code>：分配一個虛擬終端機。&lt;/li>
&lt;li>&lt;code>--privileged&lt;/code>：給予容器額外的權限。&lt;/li>
&lt;li>&lt;code>-u, --user&lt;/code>：以指定使用者身份執行容器。&lt;/li>
&lt;li>&lt;code>-w, --workdir&lt;/code>：指定容器內的工作目錄。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="3-docker-實用操作範例">3. Docker 實用操作範例
&lt;/h2>&lt;h3 id="以互動模式啟動-ubuntu-容器">以互動模式啟動 Ubuntu 容器
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -it ubuntu:latest /bin/bash
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>-i&lt;/code> 保持標準輸入開啟，&lt;code>-t&lt;/code> 分配終端機，方便互動操作。&lt;/li>
&lt;/ul>
&lt;h3 id="在背景執行-nginx-容器">在背景執行 Nginx 容器
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -d -p 8080:80 nginx:latest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>-d&lt;/code> 讓容器在背景執行，&lt;code>-p&lt;/code> 對應主機與容器的埠口。&lt;/li>
&lt;/ul>
&lt;h3 id="設定環境變數並指定工作目錄">設定環境變數並指定工作目錄
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -e ENV_VAR&lt;span style="color:#f92672">=&lt;/span>value -w /app -it python:3.10 bash
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>-e&lt;/code> 設定環境變數，&lt;code>-w&lt;/code> 指定工作目錄。&lt;/li>
&lt;/ul>
&lt;h3 id="以指定使用者執行">以指定使用者執行
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -u 1000:1000 -it ubuntu bash
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>-u&lt;/code> 指定使用者與群組 ID。&lt;/li>
&lt;/ul>
&lt;h3 id="從檔案讀取環境變數">從檔案讀取環境變數
&lt;/h3>&lt;p>假設有 &lt;code>.env&lt;/code> 檔案：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run --env-file .env ubuntu env
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="4-參考資料">4. 參考資料
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.docker.com/" target="_blank" rel="noopener"
>Docker 官方文件&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.docker.com/engine/reference/commandline/docker/" target="_blank" rel="noopener"
>Docker 指令參考&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://hub.docker.com/" target="_blank" rel="noopener"
>Docker Hub&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dandelionlibra.github.io/post/virtual-environment/docker/setup-jupyter-notebook-with-docker/" target="_blank" rel="noopener"
>Docker 安裝教學（延伸閱讀）&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>
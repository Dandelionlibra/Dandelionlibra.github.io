{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb39e26a-4a61-45e3-a196-180b3ea22b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "NVIDIA RTX 6000 Ada Generation\n",
      "NVIDIA RTX 6000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7131e-6467-4512-835d-1f6abf14ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://dandelion-ollama-1:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca0bfed4-ee39-47cc-98cc-aad2b7b967ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    22  100    22    0     0  12134      0 --:--:-- --:--:-- --:--:-- 22000\n",
      "\u001b[0;39m405\u001b[0m\n",
      "parse error: Invalid numeric literal at line 1, column 11\n"
     ]
    }
   ],
   "source": [
    "!curl http://dandelion-ollama-1:11434/api/embeddings | jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6077b09b-dd76-4237-ae34-00b6becef021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2052    0  2052    0     0   816k      0 --:--:-- --:--:-- --:--:-- 1001k\n",
      "      \"name\": \"snowflake-arctic-embed:137m\",\n",
      "      \"model\": \"snowflake-arctic-embed:137m\",\n",
      "      \"name\": \"snowflake-arctic-embed:335m\",\n",
      "      \"model\": \"snowflake-arctic-embed:335m\",\n",
      "      \"name\": \"nomic-embed-text:latest\",\n",
      "      \"model\": \"nomic-embed-text:latest\",\n"
     ]
    }
   ],
   "source": [
    "# list models\n",
    "!curl http://dandelion-ollama-1:11434/api/tags | jq | grep embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cb746-059d-4d90-a05b-9ab8daa87c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull model\n",
    "curl -X POST http://dandelion-ollama-1:11434/api/pull -H \"Content-Type: application/json\" -d '{\n",
    "  \"name\": \"bge-m3:567m\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd6ef4e-320c-4ad2-9279-4ace0db03f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'models': [{'name': 'llama3.1:8b', 'model': 'llama3.1:8b', 'modified_at': '2025-07-16T10:00:52.352347186Z', 'size': 4920753328, 'digest': '46e0c10c039e019119339687c3c1757cc81b9da49709a3b3924863ba87ca666e', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '8.0B', 'quantization_level': 'Q4_K_M'}}, {'name': 'nomic-embed-text:latest', 'model': 'nomic-embed-text:latest', 'modified_at': '2025-07-16T09:48:21.743163953Z', 'size': 274302450, 'digest': '0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'nomic-bert', 'families': ['nomic-bert'], 'parameter_size': '137M', 'quantization_level': 'F16'}}, {'name': 'qwen2.5:0.5b', 'model': 'qwen2.5:0.5b', 'modified_at': '2025-07-16T06:49:08.343900724Z', 'size': 397821319, 'digest': 'a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '494.03M', 'quantization_level': 'Q4_K_M'}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# °²³] docker-compose ¸ÌªºªA°È¦WºÙ¬O ollama\n",
    "response = requests.get(\"http://dandelion-ollama-1:11434/api/tags\")\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354545b-13f1-4527-a85e-406d09f1fa81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18f9b67c-3064-48a6-a32f-b2bcd29b2218",
   "metadata": {},
   "source": [
    "\n",
    "### pull model\n",
    "`curl -X POST http://dandelion-ollama-1:11434/api/pull -H \"Content-Type: application/json\" -d '{ \n",
    "  \"name\": \"bge-m3:567m\" \n",
    "}' ` \n",
    "\n",
    "| 部份                                             | 說明                        |\n",
    "| ------------------------------------------------ | -------------------------- |\n",
    "| `curl -X POST`                                   | 用 POST 方法呼叫 HTTP API         |\n",
    "| `http://dandelion-ollama-1:11434/api/pull`       | 呼叫 Ollama 服務器的 **pull 接口** |\n",
    "| `-H \"Content-Type: application/json\"`            | 告訴伺服器這是 JSON 格式            |\n",
    "| `-d '{ \"name\": \"snowflake-arctic-embed:335m\" }'` | 請求內容, 指定拉取的模型名稱         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96faa9c9-057e-477a-8475-8c0dde23ff20",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path ./data/PDF_file.pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 32\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03mnomic-embed-text\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03msnowflake-arctic-embed:335m\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# ***********************\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 載入 PDF 文件\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/PDF_file.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_and_split()\n\u001b[1;32m     35\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:281\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[0;34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    240\u001b[0m     file_path: Union[\u001b[38;5;28mstr\u001b[39m, PurePath],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m     extraction_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    251\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m        `aload` methods to retrieve parsed documents with content and metadata.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(\n\u001b[1;32m    283\u001b[0m         password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[1;32m    284\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m         extraction_kwargs\u001b[38;5;241m=\u001b[39mextraction_kwargs,\n\u001b[1;32m    291\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:140\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a valid file or url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n",
      "\u001b[0;31mValueError\u001b[0m: File path ./data/PDF_file.pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/versions/v0_2/deprecations/\n",
    "# 從 langchain 引入 pdf 載入器\n",
    "# from langchain.document_loaders import PyPDFLoader #! 已棄用\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter #! 已棄用\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 使用 ollama 的模型\n",
    "# llm_model = OllamaLLM(\n",
    "#     base_url='http://dandelion-ollama-1:11434', \n",
    "#     model=\"llama3.1:8b\"\n",
    "# )\n",
    "\n",
    "# 使用 ollama 的 embedding 模型\n",
    "embeddings_model = OllamaEmbeddings(\n",
    "    base_url='http://dandelion-ollama-1:11434', \n",
    "    model=\"nomic-embed-text\",\n",
    "    # model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "'''\n",
    "nomic-embed-text\n",
    "snowflake-arctic-embed:335m\n",
    "'''\n",
    "\n",
    "\n",
    "# ***********************\n",
    "# 載入 PDF 文件\n",
    "loader = PyPDFLoader('./data/PDF_file.pdf')\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=128)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 將文檔寫入 ChromaDB\n",
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=\"./nomic-db\"\n",
    ")\n",
    "\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "query = \"我想要一隻綿羊\"\n",
    "print(\"--------\")\n",
    "print(\"embeddings_model:\", embeddings_model.model)\n",
    "print(\"query:\", query)\n",
    "print(\"--------\")\n",
    "\n",
    "# k=3 表示返回最相似的3個文檔\n",
    "# results = db.similarity_search(query,k = 3)\n",
    "results = db.similarity_search(query)\n",
    "print(\"相似度：\", results)\n",
    "\n",
    "print(f\"找到 {len(results)} 個相關文檔\\n\")\n",
    "\n",
    "c = 1;\n",
    "for r in results:\n",
    "    print(f\"[{c}] {r.page_content}\\n---\\n\")\n",
    "    c = c +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92bcbeba-3d62-447e-8e3c-a3803ec5e974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m699.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m857.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m846.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, pyparsing, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.0 joblib-1.5.1 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3 scikit-learn-1.7.0 scipy-1.15.3 seaborn-0.13.2 threadpoolctl-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U matplotlib scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbe3a0-b2cc-4ebd-a6ac-c135b9c000d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

<!doctype html><html lang=zh-Hant-TW dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="A Survey on RAG Meeting LLMs Towards Retrieval-Augmented Large Language Models"><title>檢索增強大型語言模型綜述 — RA-LLMs 系統性回顧與應用解析</title><link rel=canonical href=https://Dandelionlibra.github.io/post/note/rag-llms-survey-note/><link rel=stylesheet href=/scss/style.min.946cca6c6259ef94ac55abfae7c7bf3291ea3ed5eea17ef77500b257217c6710.css><meta property='og:title' content="檢索增強大型語言模型綜述 — RA-LLMs 系統性回顧與應用解析"><meta property='og:description' content="A Survey on RAG Meeting LLMs Towards Retrieval-Augmented Large Language Models"><meta property='og:url' content='https://Dandelionlibra.github.io/post/note/rag-llms-survey-note/'><meta property='og:site_name' content='YuChen'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='AI'><meta property='article:tag' content='Large Language Model'><meta property='article:tag' content='Retrieval-Augmented Generation'><meta property='article:tag' content='RAG'><meta property='article:tag' content='LLM'><meta property='article:tag' content='Research Summary'><meta property='article:published_time' content='2025-07-20T08:50:00+08:00'><meta property='article:modified_time' content='2025-07-20T08:50:00+08:00'><meta name=twitter:title content="檢索增強大型語言模型綜述 — RA-LLMs 系統性回顧與應用解析"><meta name=twitter:description content="A Survey on RAG Meeting LLMs Towards Retrieval-Augmented Large Language Models"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column compact"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_a0443a4a03d93adb.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>YuChen</a></h1><h2 class=site-description></h2></div></header><ol class=menu-social><li><a href=https://github.com/Dandelionlibra target=_blank title=Github rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://x.com/ target=_blank title=Twitter rel=me><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/note/>Note</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/post/note/rag-llms-survey-note/>檢索增強大型語言模型綜述 — RA-LLMs 系統性回顧與應用解析</a></h2><h3 class=article-subtitle>A Survey on RAG Meeting LLMs Towards Retrieval-Augmented Large Language Models</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jul 20, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>2 minute read</time></div></footer></div></header><section class=article-content><blockquote><p>本文整理自：<a class=link href=https://arxiv.org/abs/2405.06211 target=_blank rel=noopener>A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models</a><br>作者：Ting-Rui Chiang, Xiangyu Zhang, Tianyu Zhao, Xiangyang Xue, Xipeng Qiu<br>發佈於 arXiv，2024年5月</p></blockquote><h1 id=摘要>摘要</h1><p>大型語言模型（LLMs）雖展現強大生成能力，但受限於內部知識與幻覺問題。檢索增強生成（Retrieval-Augmented Generation;RAG）透過即時檢索外部資訊，提升回應的可靠性與時效性。本文整理 RA-LLMs 的架構、訓練策略與應用，並探討其面臨的挑戰與未來發展，展現檢索對提升 LLM 實用性的關鍵價值。</p><h1 id=前言>前言</h1><p>檢索增強生成（RAG）技術透過結合資訊檢索與大型語言模型（LLMs），補足模型知識不足與幻覺問題，近年受到廣泛關注。LLMs 雖具強大生成能力，卻常受限於知識時效與專領域應用，而 RA-LLMs 則透過檢索外部資料提升生成品質。</p><h1 id=背景>背景</h1><h2 id=大型語言模型>大型語言模型</h2><ul><li><p>應用</p><ul><li>在特定資料集上進行微調，LLM 可以適應各種下游任務，使其能夠專注於特定領域或應用。</li></ul></li><li><p>架構:</p><ul><li>Encoder-only 模型，雙向編碼，可同時考慮單詞左右語境。<br>ex. BERT</li><li>Decoder-only 模型，單向生成（左至右），根據前文預測下個字元。<br>ex. GPT</li><li>Encoder-Decoder 模型，將輸入編碼後，再由解碼器生成對應輸出。<br>ex. T5</li></ul></li></ul><h2 id=提示學習>提示學習</h2><h3 id=提示工程prompt-engineering>提示工程（Prompt Engineering）</h3><p>因為 LLM 的參數量通常非常龐大，因此提示學習的發展可使 LLM 不需為了特定任務進行大量微調，就可以實現各項任務。<br>缺點：當缺乏專業領域知識時，生成結果可能不夠精確。</p><h3 id=上下文學習in-context-learning-icl>上下文學習（In-Context Learning, ICL）</h3><p>為提示學習的一種形式，透過在提示中提供範例示範，讓 LLM 觀察並學習任務模式。<br>缺點：成效高度依賴範例品質、當缺乏必要知識或資訊時，可能導致生成結果不理想。</p><p>為克服這些問題，發展出 RAG（檢索增強生成）技術，RAG 結合檢索與生成，提升 LLM 在多任務中的表現與適應性。</p><h1 id=內文>內文</h1><p>LLMs 時代的 RAG 架構大致包含檢索、產生和增強三個主要流程。</p><p><img src=https://ar5iv.labs.arxiv.org/html/2405.06211/assets/x2.png loading=lazy alt="RAG 系統總覽"><br><em>圖 1：RAG 系統總覽，涵蓋檢索、生成與增強三大流程。來源：原論文</em></p><p><img src=https://ar5iv.labs.arxiv.org/html/2405.06211/assets/x3.png loading=lazy alt="RAG 系統細節流程"><br><em>圖 2：RAG 在 RA-LLM 中的流程圖，展示各模組間的互動。來源：原論文</em></p><h2 id=retrieval>Retrieval</h2><p>RAG 旨在從外部知識源提供關鍵訊息給 LLM。</p><h3 id=retriever-type>Retriever Type</h3><p>依照資訊編碼區分。</p><ul><li>稀疏檢索（Sparse Retrieval）：直接匹配詞彙並依頻率排名。</li><li>稠密檢索（Dense Retrieval）：將查詢與文檔嵌入為向量，透過語意相似度檢索。</li></ul><h3 id=retrieval-granularity>Retrieval Granularity</h3><p>檢索單位的選擇對效能與計算成本有重大影響。</p><ul><li>Chunk(passages): 包含緊湊且完整的資訊，冗餘和不相關性較少，是 RAG 中主流的檢索文本粒度。</li><li>Token: 實現更快的搜尋，但會給資料庫儲存帶來更多負擔。適用於需要稀有模式或領域外資料的情況。</li><li>Entity: 實體檢索是從知識而非語言的角度檢索，對於以實體為中心的任務更有效，並且與詞元檢索相比，在空間上更高效。</li></ul><h3 id=retrieval-enhancement-strategies>Retrieval Enhancement strategies</h3><ul><li><p>檢索前優化（Pre-retrieval）</p><ul><li><p>Query Expansion (查詢擴展)：透過加入相關詞彙或概念來擴大原始查詢的範圍。例如，利用大型語言模型 (LLM) 生成偽文件，並從中提取相關資訊來擴展查詢，有助於消除歧義並引導檢索器。</p></li><li><p>Query Rewrite (查詢重寫)：旨在重新彌合原始查詢，使其更適合檢索。這可能涉及澄清查詢意圖、使其更精確，或是將其轉換為檢索功能更容易理解的形式。例如，利用 LLM 將原始問題重寫為更利於檢索的版本。<br>舉例，<strong>多次</strong>詢問模型他的檢索資料是否正確。</p></li><li><p>Query Augmentation (查詢增強)：將原始查詢與初步生成的內容結合，形成一個新的查詢。這種策略可以增加查詢與潛在相關文件之間的詞彙和語義重疊，有助於檢索出更多有助於答案生成的資訊。</p></li></ul></li><li><p>檢索後優化（Post-retrieval）</p><ul><li><p>重排序與過濾<br>對檢索到的文件進行重新排序，將最相關的資訊排在前面，並過濾掉不相關或低品質的文件。例如，透過不同的檢索方法組裝文件並進行重排序，以提升檢索結果的穩健性。</p></li><li><p>雜訊過濾與整合<br>處理檢索到的資訊中可能存在的雜訊或不相關內容，以避免其對生成過程產生負面影響。同時，將清洗過的資訊有效地整合進生成模型。</p></li><li><p>壓縮與摘要<br>針對檢索到的長篇文件，進行壓縮或生成摘要，以解決大型語言模型輸入長度限制的問題。例如，將檢索到的文件處理成文本摘要，再用於模型生成。</p></li></ul></li></ul><h3 id=database>Database</h3><p>RA-LLM 的檢索資料庫可為封閉式或開放式來源。</p><ul><li>封閉式資料庫:
通常以鍵值對 (key-value pairs) 的形式儲存知識。</li><li>開放式資料庫:
利用搜尋引擎（如 Bing、Google）獲取即時資訊。</li></ul><h2 id=生成generation>生成（Generation）</h2><p>生成模組的設計高度依賴於下游任務需求，因而得以適應不同的任務需求。</p><h3 id=可調參數生成器白箱parameter-accessible-generators>可調參數生成器（白箱，Parameter-Accessible Generators）</h3><ul><li><p>Encoder-Decoder</p><ul><li>擁有獨立的編碼器（Encoder）與解碼器（Decoder），分別處理輸入與生成的目標。</li><li>Encoder 先將輸入編碼為上下文表示，Decoder 以 Cross-Attention 讀取 Encoder 輸出，逐步生成結果。</li><li>模型的目標是「根據編碼後的輸入與先前生成的結果，預測下一個 token」。</li></ul><pre tabindex=0><code>輸入：請介紹 Transformer。  
Encoder 編碼後 → [內部上下文表示]  
Decoder 讀取表示 → 生成：Transformer 是一種...  
</code></pre></li><li><p>Decoder-only</p><ul><li>沒有獨立的編碼器。</li><li>輸入（如問題、提示） 和 目標（要生成的內容） 會被串接成同一序列，並從左到右進行處理。</li><li>模型的目標是學會「根據前面內容，預測下一個 token」。</li></ul><pre tabindex=0><code>輸入：請介紹 Transformer。
模型看到的內容：請介紹 Transformer。&lt;接著是生成的回答...&gt;
</code></pre></li></ul><h3 id=不可調參數生成器黑箱parameter-inaccessible-generators>不可調參數生成器（黑箱，Parameter-Inaccessible Generators）</h3><p>無法直接修改模型本身，且難以進行微調，因此更側重於優化檢索和增強的過程。它們的目標是透過為輸入 (prompts) 提供更優質的知識、指導或範例來增強 Generator 的性能。</p><h2 id=增強augmentation>增強（Augmentation）</h2><h3 id=input-layer-integration>Input-Layer Integration:</h3><ul><li><p><strong>串聯整合</strong>：如 In-Context RALM (Ram et al., 2023)，將原始輸入與所有檢索文件串聯為單一序列輸入生成模型。</p><ul><li>問題：輸入長度易超過模型處理上限，需移除部分詞元，可能導致資訊遺失。</li></ul></li><li><p><strong>平行整合</strong>：如 FID (Izacard and Grave, 2021b)、Atlas、REPLUG，將每個檢索文件獨立編碼，僅在後續步驟聚合結果。</p><ul><li>優點：更能擴展至大量上下文，減少資訊丟失風險。</li></ul></li><li><p>通常，大多數基於黑盒生成的 RAG 方法都採用此法，因為生成模型的中間層和輸出分佈都無法存取。</p></li></ul><h3 id=output-layer-integration>Output-Layer Integration:</h3><p>一種後處理 (post-hoc) 的檢索增強方式，它不直接干預生成模型的內部運作或其生成過程，而是在模型產生初步結果之後，才將檢索到的資訊與這些結果進行結合。</p><h3 id=intermediate-layer-integration>Intermediate-Layer Integration:</h3><p>在生成模型內部的中間層注入檢索資訊，相較於輸入層與輸出層整合，屬於 半參數式（Semi-parametric） 的強化方式，具有更高的資訊融合深度與潛力。</p><h3 id=34retrieval-augmentation-necessity-and-frequency>3.4.Retrieval Augmentation Necessity and Frequency</h3><p>還未整理</p><h2 id=ra-llms-訓練策略概述>RA-LLMs 訓練策略概述</h2><p><img src=https://ar5iv.labs.arxiv.org/html/2405.06211/assets/x4.png loading=lazy alt="RA-LLMs 訓練策略總覽"><br><em>圖 3：RA-LLMs 訓練策略總覽，涵蓋免訓練與需訓練方法。來源：原論文</em></p><h3 id=免訓練方法training-free>免訓練方法（Training-Free）</h3><h4 id=prompt-engineering-based-methods>Prompt Engineering-based Methods</h4><p>將檢索到的外部知識，直接整合進 LLM 的提示（Prompt），作為上下文輔助模型生成。<br>舉例，In-Context RALM 在不改動 LLM 參數的情況下，直接將檢索到的文件插入於原始提示之前，增強生成過程。IRCoT 則交錯進行 chain-of-thought（CoT）生成與知識檢索步驟，使每一步推理都能檢索到更相關的資訊。GENREAD 不是從大型語料庫檢索知識，而是先讓 LLM 根據查詢生成上下文文件，再根據這些上下文與問題產生答案。SKR 則引導 LLM 判斷是否能僅依靠內部知識回答問題，若不足再選擇性調用檢索器，靈活結合內外部知識。TOC 針對模糊問題，先檢索相關知識，並遞迴將問題拆解為多個明確子問題，最終聚合生成長篇答案。</p><ul><li>特點：<ul><li>無需模型訓練</li><li>靠設計合理的提示與檢索流程提升效果</li></ul></li></ul><h4 id=retrieval-guided-token-generation-methods>Retrieval-Guided Token Generation Methods</h4><p>透過檢索結果來調整 LLM 的 Token 預測分布，影響每一步的生成。<br>舉例，例如 KNN-LMs 會根據當前查詢從資料庫檢索出 k 個最相關的上下文，計算鄰近分布，並將其與原模型的輸出分布進行插值校正，以提升生成結果的準確性。Rest 則以非參數檢索資料庫取代傳統的參數式草稿模型，根據當前上下文檢索相關 token，輔助推測式生成（speculative decoding）。</p><ul><li>特點：<ul><li>不更改模型權重</li><li>通常作為後處理或推測性生成的輔助</li></ul></li></ul><p>※ 這兩類免訓練方法，分別著重於：</p><ul><li>提示工程 — 調整輸入</li><li>生成控制 — 調整輸出過程</li></ul><h3 id=需訓練方法training-based>需訓練方法（Training-Based）</h3><ol><li>Independent Training<br>獨立訓練方法會將 RAG 流程中的每個組件分開、獨立地進行訓練。這意味著檢索器和生成器各自最佳化，互不干擾。</li></ol><p>檢索器類型：</p><ul><li><p>稀疏檢索器 (Sparse Retriever) ：
這類檢索器通常利用稀疏特徵，例如詞頻，來表示文件，並根據任務特定的指標（如 TF-IDF 和 BM25）計算相關性分數 。</p></li><li><p>密集檢索器 (Dense Retriever) ：
密集檢索器則採用深度神經網絡將查詢和文件編碼成密集表示 (dense representations)。然後，通常使用內積計算相關性分數並檢索相關的外部知識。</p></li></ul><ol start=2><li><p>Sequential Training<br>序列訓練方法則採取分階段的訓練方式。首先訓練一個模組（例如檢索器），然後將這個訓練好的組件固定下來，再利用它來指導另一個模組（例如生成器）的調整過程。</p></li><li><p>Joint Training<br>聯合訓練方法則是同時訓練檢索器和生成器。這種方式旨在讓兩個模組在訓練過程中相互協調、共同進步。</p></li></ol></section><footer class=article-footer><section class=article-tags><a href=/tags/ai/>AI</a>
<a href=/tags/large-language-model/>Large Language Model</a>
<a href=/tags/retrieval-augmented-generation/>Retrieval-Augmented Generation</a>
<a href=/tags/rag/>RAG</a>
<a href=/tags/llm/>LLM</a>
<a href=/tags/research-summary/>Research Summary</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/post/langchain/retrieverqa-2/><div class=article-details><h2 class=article-title>LangChain 記憶型檢索問答：《小王子》文本互動實踐</h2></div></a></article><article><a href=/post/langchain/retrieverqa-1/><div class=article-details><h2 class=article-title>使用 Langchain 框架進行檢索提問</h2></div></a></article><article><a href=/post/langchain/uselangchain-4/><div class=article-details><h2 class=article-title>LangChain 基本使用-4</h2></div></a></article><article><a href=/post/langchain/uselangchain-3/><div class=article-details><h2 class=article-title>LangChain 基本使用-3</h2></div></a></article><article><a href=/post/langchain/uselangchain-2/><div class=article-details><h2 class=article-title>LangChain 基本使用-2</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2025 YuChen</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tutorial on YuChen</title><link>https://Dandelionlibra.github.io/categories/tutorial/</link><description>Recent content in Tutorial on YuChen</description><generator>Hugo -- gohugo.io</generator><language>zh-Hant-TW</language><lastBuildDate>Mon, 14 Jul 2025 10:56:00 +0000</lastBuildDate><atom:link href="https://Dandelionlibra.github.io/categories/tutorial/index.xml" rel="self" type="application/rss+xml"/><item><title>LangChain 基本使用-3</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</link><pubDate>Mon, 14 Jul 2025 10:56:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</guid><description>&lt;h1 id="data-connection">Data Connection
&lt;/h1>&lt;h2 id="定義">定義
&lt;/h2>&lt;p>許多基於大型語言模型而執行的應用常會用到模型數據集中沒有的數據。而針對這類需求，Langchain 提供了許多工具使用戶可以從各類數據源中加載新的數據、轉換數據、儲存數據、訪問數據。&lt;/p>
&lt;p>※大型語言模型不可能在訓練階段就涵蓋所有數據，且每時每刻都有新的數據產生。&lt;/p>
&lt;ul>
&lt;li>文檔載入器(Document loaders): 從多種數據源加載文檔，ex.網頁、pdf。&lt;/li>
&lt;li>文檔轉換器: 拆分文檔、丟棄冗餘文檔，主要運行在文檔載入器之後，針對加載出來的文檔做處理。&lt;/li>
&lt;li>文本嵌入(embedding)模型: 將非結構化的文本轉為浮點數列表。&lt;/li>
&lt;li>向量數據庫: 儲存和搜尋 embedding 數據。&lt;/li>
&lt;li>檢索器: 查詢向量數據。&lt;/li>
&lt;/ul>
&lt;h2 id="data-connection-處理流程">Data Connection 處理流程
&lt;/h2>&lt;p>&lt;img src="https://Dandelionlibra.github.io/image/Data_Connection.JPG"
loading="lazy"
alt="Data_Connection"
>&lt;/p>
&lt;h3 id="1-文本載入器document-loaders">1. 文本載入器(Document loaders)
&lt;/h3>&lt;p>將文本數據從原始數據(Source)中提取出來，改成 langchain 認識的語言，總而言之就是將非結構化的文本數據加載到結構化的字符串中。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>輸入: 各種數據源，ex.PDF、URL、影片。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>輸出: 一系列的 Document 對象，例，有6頁pdf會產出6個 documents，以分別對應。
&lt;img src="https://Dandelionlibra.github.io/image/Document_loaders.JPG"
loading="lazy"
alt="Document_loaders.JPG"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>舉例&lt;/p>
&lt;ul>
&lt;li>
&lt;p>結構化文件: 加載 CSV 文件&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.document_loaders.csv_loader &lt;span style="color:#f92672">import&lt;/span> CSVLoader
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loader &lt;span style="color:#f92672">=&lt;/span> CSVLoader(file_path&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;./data/file.csv&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#f92672">=&lt;/span> loader&lt;span style="color:#f92672">.&lt;/span>load()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>非結構化文件: 純文本、ppt、html、pdf、圖片。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://python.langchain.com/docs/integrations/document_loaders/" target="_blank" rel="noopener"
>全部文件格式&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="2-文本分割器document-transformers">2. 文本分割器(Document transformers)
&lt;/h3>&lt;p>將加載好的文檔進行轉換，從而更好的適應各種場景。舉例，將文檔拆分成較小的塊，以避免大型語言模型對於輸入長度的限制。&lt;br>
Langchain 中提供的文檔轉換器可以提供拆分、合併、過濾等功能。&lt;/p>
&lt;ul>
&lt;li>文本分割器-拆分: 分割長文本，根據語意相關性將所有有關聯的文本放在同一個分割段中。&lt;br>
&lt;img src="https://Dandelionlibra.github.io/image/Document_transformers.JPG"
loading="lazy"
alt="Document_transformers.JPG.JPG"
>&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>將文本拆分為小、具語意意義的塊。&lt;/li>
&lt;li>將小塊組合成大塊，直到達到一定規模。&lt;/li>
&lt;li>將達到一定規模的塊作為獨立的文本片段，然後創建新的文本塊，此外，為了維持塊間的連貫性，兩個文本塊之間會有重疊的部分。&lt;br>
以圖例而言，Document 由一塊變為三塊。&lt;/li>
&lt;/ol>
&lt;h3 id="3-文本詞嵌入word-embedding">3. 文本詞嵌入(Word Embedding)
&lt;/h3>&lt;p>詞嵌入是將詞語數值化表達的方式，通常會將詞映射到高維的向量中，使電腦藉由高維的數字化表達得以理解自然語言的語意，接近的語意=接近的向量距離。&lt;/p>
&lt;h3 id="4-向量數據庫">4. 向量數據庫
&lt;/h3>&lt;p>用於儲存嵌入的數據向量。&lt;/p>
&lt;h3 id="5-檢索器">5. 檢索器
&lt;/h3>&lt;p>根據輸入的非結構化查詢語句返回對應文檔的接口(一系列 Documents 對象)。&lt;br>
不同於向量數據庫，向量數據庫可以視為一種具備儲存功能的檢索器，但檢索器不一定需要具備儲存的功能。&lt;/p>
&lt;h2 id="程式事例">程式事例
&lt;/h2>&lt;p>&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_csv_loader.ipynb" target="_blank" rel="noopener"
>詳細程式請參閱&lt;/a>&lt;/p>
&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>LangChain 基本使用-2</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</link><pubDate>Sun, 13 Jul 2025 08:06:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</guid><description>&lt;h1 id="提示模板">提示模板
&lt;/h1>&lt;ul>
&lt;li>對語言模型的指令&lt;/li>
&lt;li>提供簡單的事例給語言模型使模型接近理想結果&lt;/li>
&lt;li>提給語言模型的問題&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 使用 PromptTemplate 來定義對話的提示模板&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>no_input_prompt_template &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;說個故事&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>multi_input_prompt_template &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;主題&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;風格&amp;#34;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;請講一個關於&lt;/span>&lt;span style="color:#e6db74">{主題}&lt;/span>&lt;span style="color:#e6db74">的故事，風格是&lt;/span>&lt;span style="color:#e6db74">{風格}&lt;/span>&lt;span style="color:#e6db74">。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>multi_input_prompt_template&lt;span style="color:#f92672">.&lt;/span>format(主題&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;勇氣&amp;#34;&lt;/span>, 風格&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;童話&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># other example，由 from_template 將 string 轉成 PromptTemplate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>template &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;請講一個關於&lt;/span>&lt;span style="color:#e6db74">{主題}&lt;/span>&lt;span style="color:#e6db74">的故事，風格是&lt;/span>&lt;span style="color:#e6db74">{風格}&lt;/span>&lt;span style="color:#e6db74">。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prompt_template &lt;span style="color:#f92672">=&lt;/span> PromptTemplate&lt;span style="color:#f92672">.&lt;/span>from_template(template)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 此時輸出 [&amp;#34;主題&amp;#34;, &amp;#34;風格&amp;#34;]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prompt_template&lt;span style="color:#f92672">.&lt;/span>input_variables
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="接收部分參數">接收部分參數
&lt;/h2>&lt;ol>
&lt;li>
&lt;p>在所有參數無法同步獲取時，可以先用現有參數傳入第一個模板，以獲得新的參數，再將新參數傳入新的模板中，以得到最終想問的問題。&lt;br>
&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_1.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>有些參數要用特定方式獲取 (ex.函式呼叫)
&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_2.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_date&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> now &lt;span style="color:#f92672">=&lt;/span> datetime&lt;span style="color:#f92672">.&lt;/span>now()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> now&lt;span style="color:#f92672">.&lt;/span>strftime(&lt;span style="color:#e6db74">&amp;#34;%m月&lt;/span>&lt;span style="color:#e6db74">%d&lt;/span>&lt;span style="color:#e6db74">日&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prompt &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;告訴我&lt;/span>&lt;span style="color:#e6db74">{城市}&lt;/span>&lt;span style="color:#e6db74">在&lt;/span>&lt;span style="color:#e6db74">{年份}&lt;/span>&lt;span style="color:#e6db74">年&lt;/span>&lt;span style="color:#e6db74">{日期}&lt;/span>&lt;span style="color:#e6db74">的平均氣溫是多少？&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;城市&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;年份&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;日期&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>PromptTemplate_2 &lt;span style="color:#f92672">=&lt;/span> prompt&lt;span style="color:#f92672">.&lt;/span>partial(城市&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;台北&amp;#34;&lt;/span>, 日期&lt;span style="color:#f92672">=&lt;/span>get_date())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(PromptTemplate_2&lt;span style="color:#f92672">.&lt;/span>format(年份&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;2023&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出:&lt;/p>
&lt;pre tabindex="0">&lt;code>告訴我台北在2023年07月13日的平均氣溫是多少？
&lt;/code>&lt;/pre>&lt;h2 id="少樣本學習-few-shot">少樣本學習 (few-shot)
&lt;/h2>&lt;ul>
&lt;li>藉由少量的樣本、範例，使語言模型能處理特定問題&lt;/li>
&lt;li>不同於微調 (fine-tuning)，微調會使用大量樣本，最終會改變模型本身&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>例子:&lt;br>
&amp;ldquo;你好嗎?&amp;rdquo; - &amp;ldquo;主人，我很好。&amp;rdquo;&lt;br>
&amp;ldquo;今天禮拜幾?&amp;rdquo; - &amp;ldquo;主人，今天禮拜日。&amp;rdquo;&lt;br>
&amp;ldquo;天氣真好呀。&amp;rdquo; - &amp;ldquo;主人，是的，今天天氣非常好。&amp;rdquo;&lt;/p>
&lt;p>希望模型學會&amp;quot;主人&amp;quot;的前綴。&lt;/p>&lt;/blockquote>
&lt;h3 id="fewshot-prompt-template">FewShot Prompt Template
&lt;/h3>&lt;p>利用提示模板，將樣本數據加載成完整的提示詞，接著將樣本連同提示詞一併送給樣本提示模板，最終得到完整的提示詞。&lt;/p>
&lt;p>&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_3.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.prompts.few_shot &lt;span style="color:#f92672">import&lt;/span> FewShotPromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.prompts.prompt &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># FewShot examples&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>examples &lt;span style="color:#f92672">=&lt;/span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;你好嗎?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;主人，我很好。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;今天禮拜幾?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;主人，今天禮拜日。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;天氣真好呀。&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;主人，是的，今天天氣非常好。&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># FewShotPromptTemplate-樣本提示模板&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 提示模板以 Question:開頭&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>example_prompt &lt;span style="color:#f92672">=&lt;/span> PromptTemplate(input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;question&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;answer&amp;#34;&lt;/span>], template&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Question: &lt;/span>&lt;span style="color:#e6db74">{question}&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">Answer: &lt;/span>&lt;span style="color:#e6db74">{answer}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>few_shot_prompt &lt;span style="color:#f92672">=&lt;/span> FewShotPromptTemplate(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> examples&lt;span style="color:#f92672">=&lt;/span>examples, &lt;span style="color:#75715e"># 傳入樣本&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> example_prompt&lt;span style="color:#f92672">=&lt;/span>example_prompt, &lt;span style="color:#75715e"># 傳入樣本模板&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> suffix&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Question: &lt;/span>&lt;span style="color:#e6db74">{input}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 問題的提示詞&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_variables&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;input&amp;#34;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(few_shot_prompt&lt;span style="color:#f92672">.&lt;/span>format(input&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;你今天過得怎麼樣?&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出完整提示詞如下，但前面三組為提供的範例案例，最後一組是輸入的提問。&lt;/p>
&lt;pre tabindex="0">&lt;code>Question: 你好嗎?
Answer: 主人，我很好。
Question: 今天禮拜幾?
Answer: 主人，今天禮拜日。
Question: 天氣真好呀。
Answer: 主人，是的，今天天氣非常好。
Question: 你今天過得怎麼樣?
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> llm&lt;span style="color:#f92672">.&lt;/span>invoke(few_shot_prompt&lt;span style="color:#f92672">.&lt;/span>format(input&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;你今天過得怎麼樣?&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(response)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出結果：&lt;/p>
&lt;pre tabindex="0">&lt;code>你的問題是問你今天過得怎麼樣？我可以回答說：您也很好。或者，我可以詢問一下您今天過得怎麼樣？
如果你想知道我的答案，那就是：主人，今天我很好，謝謝您的關心！
&lt;/code>&lt;/pre>&lt;h3 id="樣本篩選器-exampleselector">樣本篩選器 (ExampleSelector)
&lt;/h3>&lt;ul>
&lt;li>樣本數量太多時&lt;/li>
&lt;li>不是所有樣本都能幫助提升輸出質量
&lt;img src="https://Dandelionlibra.github.io/image/ExampleSelector.JPG"
loading="lazy"
alt="partial_prompt_template"
>&lt;/li>
&lt;li>舉例: SemanticSimilarityExampleSelector (語意相似度篩選器)，依據最終提的問題，在所有樣本中尋找語意最為接近的樣本。&lt;/li>
&lt;/ul>
&lt;h2 id="大型語言模型的封裝">大型語言模型的封裝
&lt;/h2>&lt;ul>
&lt;li>Langchain 不提供現成的大型語言模型&lt;/li>
&lt;li>Langchain 提供的是針對不同語言模型的標準化接口&lt;/li>
&lt;/ul>
&lt;h3 id="大型語言模型llm模塊的基本用法">大型語言模型(LLM)模塊的基本用法
&lt;/h3>&lt;ul>
&lt;li>直接呼叫
&lt;ul>
&lt;li>類似直接呼叫.invoke()，讓語言模型根據輸入回答內容。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(llm(&lt;span style="color:#e6db74">&amp;#34;跟我說一個笑話，盡量簡短。&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出：&lt;/p>
&lt;pre tabindex="0">&lt;code>為什麼電池走路去了? 因為它想充電
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>批量生成
&lt;ul>
&lt;li>generate()&lt;/li>
&lt;li>輸入：文本的列表&lt;/li>
&lt;li>輸出：文本的列表&lt;/li>
&lt;li>ex. 輸入問題的列表，輸出回答的列表。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>generate_res &lt;span style="color:#f92672">=&lt;/span> llm&lt;span style="color:#f92672">.&lt;/span>generate([&lt;span style="color:#e6db74">&amp;#34;跟我說一個笑話，盡量簡短。&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;跟我說一個悲傷的故事，盡量簡短。&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(generate_res)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出：&lt;/p>
&lt;pre tabindex="0">&lt;code>generations=[[GenerationChunk(text=&amp;#39;為什麼人類會走路?\n\n因為鳥不喜歡吃路上的東西!&amp;#39;, generation_info={&amp;#39;model&amp;#39;: &amp;#39;llama3.1:8b&amp;#39;, &amp;#39;created_at&amp;#39;: &amp;#39;2025-07-13T14:22:01.5478452Z&amp;#39;, &amp;#39;done&amp;#39;: True, &amp;#39;done_reason&amp;#39;: &amp;#39;stop&amp;#39;, &amp;#39;total_duration&amp;#39;: 2588937700, &amp;#39;load_duration&amp;#39;: 39039000, &amp;#39;prompt_eval_count&amp;#39;: 23, &amp;#39;prompt_eval_duration&amp;#39;: 335147300, &amp;#39;eval_count&amp;#39;: 22, &amp;#39;eval_duration&amp;#39;: 2214149200, &amp;#39;response&amp;#39;: &amp;#39;&amp;#39;, &amp;#39;thinking&amp;#39;: None, &amp;#39;context&amp;#39;: [128006, 882, 128007, 271, 104142, 37046, 106336, 114634, 49838, 87177, 3922, 16555, 94, 33857, 112825, 106649, 1811, 128009, 128006, 78191, 128007, 271, 101399, 101567, 114064, 17792, 104770, 101835, 102149, 47095, 1980, 63212, 101399, 116750, 16937, 104940, 125741, 105271, 47095, 106583, 101778, 61786, 0]})], [GenerationChunk(text=&amp;#39;有一個年輕女孩，她與自己的父親非常相愛。可是因為工作太忙，爸爸長期外出，並且忽略了女兒。直到一天，一場重大事故讓爸爸去世。在悲痛中，女孩發現了之前父親給她的信，裡面有對她的溫暖告白和深情懷念。這個消息使她心痛欲裂，從此女孩再也沒有恢復過。&amp;#39;, generation_info={&amp;#39;model&amp;#39;: &amp;#39;llama3.1:8b&amp;#39;, &amp;#39;created_at&amp;#39;: &amp;#39;2025-07-13T14:22:16.1064263Z&amp;#39;, &amp;#39;done&amp;#39;: True, &amp;#39;done_reason&amp;#39;: &amp;#39;stop&amp;#39;, &amp;#39;total_duration&amp;#39;: 14556868200, &amp;#39;load_duration&amp;#39;: 39856500, &amp;#39;prompt_eval_count&amp;#39;: 25, &amp;#39;prompt_eval_duration&amp;#39;: 516644200, &amp;#39;eval_count&amp;#39;: 104, &amp;#39;eval_duration&amp;#39;: 13999594200, &amp;#39;response&amp;#39;: &amp;#39;&amp;#39;, &amp;#39;thinking&amp;#39;: None, &amp;#39;context&amp;#39;: [128006, 882, 128007, 271, 104142, 37046, 106336, 114634, 116292, 114218, 9554, 117625, 3922, 16555, 94, 33857, 112825, 106649, 1811, 128009, 128006, 78191, 128007, 271, 108830, 102159, 8107, 125063, 58850, 105989, 105902, 102789, 107924, 104503, 106759, 108008, 50021, 103926, 1811, 113426, 63212, 101399, 102301, 101402, 112008, 3922, 117283, 117283, 101544, 23538, 48915, 20834, 113415, 103786, 120994, 105838, 35287, 58850, 114763, 1811, 74245, 28037, 15120, 36827, 104295, 75267, 125478, 123429, 114816, 117283, 117283, 86436, 101083, 107644, 116292, 108631, 16325, 3922, 58850, 105989, 103106, 102321, 35287, 112065, 104503, 106759, 110698, 109506, 22023, 3922, 115556, 28190, 19361, 104314, 109506, 117986, 118937, 58655, 101828, 34208, 102987, 40474, 103435, 115, 104611, 1811, 103864, 102159, 65305, 33655, 100911, 64209, 108631, 111654, 117068, 3922, 110039, 33091, 58850, 105989, 88356, 75863, 116721, 123843, 109095, 103188, 1811]})]] llm_output=None run=[RunInfo(run_id=UUID(&amp;#39;bc24e5b6-0c3f-4d2c-afb4-95f477e81adf&amp;#39;)), RunInfo(run_id=UUID(&amp;#39;f8f5fe28-4c1d-4b6f-8a74-fdcc6f397f7a&amp;#39;))] type=&amp;#39;LLMResult&amp;#39;
&lt;/code>&lt;/pre>&lt;p>可用陣列獲取特定輸出。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>print(generate_res&lt;span style="color:#f92672">.&lt;/span>generations[&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(generate_res&lt;span style="color:#f92672">.&lt;/span>generations[&lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>為什麼人類會走路?
因為鳥不喜歡吃路上的東西!
有一個年輕女孩，她與自己的父親非常相愛。可是因為工作太忙，爸爸長期外出，並且忽略了女兒。直到一天，一場重大事故讓爸爸去世。在悲痛中，女孩發現了之前父親給她的信，裡面有對她的溫暖告白和深情懷念。這個消息使她心痛欲裂，從此女孩再也沒有恢復過。
&lt;/code>&lt;/pre>&lt;h3 id="自定義-llm-模組">自定義 LLM 模組
&lt;/h3>&lt;ul>
&lt;li>用於封裝 Langchain 尚未支持的大型語言模型&lt;/li>
&lt;li>可以用來模擬測試&lt;/li>
&lt;li>自行定義當 LLM 被調用時，如何根據輸入的文本內容來輸出&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_code.ipynb" target="_blank" rel="noopener"
>詳細程式請參閱&lt;/a>&lt;/p>
&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>使用 Docker 快速建立 Jupyter Notebook 環境教學</title><link>https://Dandelionlibra.github.io/post/virtual-environment/setup-jupyter-notebook-with-docker/</link><pubDate>Thu, 10 Jul 2025 16:56:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/virtual-environment/setup-jupyter-notebook-with-docker/</guid><description>&lt;h2 id="內容大綱">內容大綱
&lt;/h2>&lt;ol>
&lt;li>為什麼用 Docker 建立 Jupyter Notebook？&lt;/li>
&lt;li>安裝 Docker
&lt;ul>
&lt;li>Linux&lt;/li>
&lt;li>Mac&lt;/li>
&lt;li>Windows&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>下載與執行 Jupyter Notebook Docker 映像檔&lt;/li>
&lt;li>設定 Notebook 存取與資料掛載&lt;/li>
&lt;li>使用 GPU&lt;/li>
&lt;li>參考資料&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="1-為什麼用-docker-建立-jupyter-notebook">1. 為什麼用 Docker 建立 Jupyter Notebook？
&lt;/h2>&lt;p>Docker 可讓你快速建立隔離的開發環境，避免本機安裝衝突。Jupyter Notebook 是資料科學常用的互動式開發工具，透過 Docker 可輕鬆部署、移植與分享。&lt;/p>
&lt;hr>
&lt;h2 id="2-安裝-docker">2. 安裝 Docker
&lt;/h2>&lt;h3 id="linux">Linux
&lt;/h3>&lt;p>大多數 Linux 發行版可透過套件管理器安裝 Docker：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 更新套件清單&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt update
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 安裝 Docker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install docker.io
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 啟動 Docker 服務&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo systemctl start docker
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 設定開機自動啟動&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo systemctl enable docker
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="mac">Mac
&lt;/h3>&lt;p>前往 &lt;a class="link" href="https://www.docker.com/products/docker-desktop/" target="_blank" rel="noopener"
>Docker Desktop for Mac&lt;/a> 下載並安裝。&lt;/p>
&lt;h3 id="windows">Windows
&lt;/h3>&lt;p>前往 &lt;a class="link" href="https://www.docker.com/products/docker-desktop/" target="_blank" rel="noopener"
>Docker Desktop for Windows&lt;/a> 下載並安裝。&lt;/p>
&lt;hr>
&lt;h2 id="3-下載與執行-jupyter-notebook-docker-映像檔">3. 下載與執行 Jupyter Notebook Docker 映像檔
&lt;/h2>&lt;p>官方映像檔推薦使用 &lt;a class="link" href="https://hub.docker.com/r/jupyter/base-notebook" target="_blank" rel="noopener"
>&lt;code>jupyter/base-notebook&lt;/code>&lt;/a> 或 &lt;a class="link" href="https://hub.docker.com/r/jupyter/scipy-notebook" target="_blank" rel="noopener"
>&lt;code>jupyter/scipy-notebook&lt;/code>&lt;/a>：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>拉取映像檔&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker pull jupyter/base-notebook
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>建立容器&lt;br>
&lt;code>docker run [OPTIONS] IMAGE [COMMAND] [ARG...]&lt;/code>&lt;/p>
&lt;p>啟動容器並開啟本機 8888 端口：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -p 8888:8888 jupyter/base-notebook
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>啟動後，終端機會顯示一組 token，複製網址（如 &lt;code>http://127.0.0.1:8888/?token=...&lt;/code>）在瀏覽器開啟即可進入 Jupyter Notebook。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>※ &lt;a class="link" href="https://hub.docker.com" target="_blank" rel="noopener"
>&lt;code>DockerHub&lt;/code>&lt;/a>: DockerHub 是官方的 Docker 映像檔集中平台，提供各種應用程式的映像檔下載與分享，可以在這裡搜尋、取得映像檔，快速部署環境。&lt;/p>
&lt;hr>
&lt;h2 id="4-設定-notebook-存取與資料掛載">4. 設定 Notebook 存取與資料掛載
&lt;/h2>&lt;p>若要將本機資料夾掛載到容器，方便存取與保存 notebook 檔案：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -p 8888:8888 -v /your/local/path:/home/jovyan/work --name my-jupyter jupyter/base-notebook
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>-p&lt;/code>: Assigns the internal port to the external port&lt;/li>
&lt;li>&lt;code>-v&lt;/code>: Assigns a local directory to a container directory (mounts a volume)&lt;/li>
&lt;li>&lt;code>/your/local/path&lt;/code>：本機資料夾路徑&lt;/li>
&lt;li>&lt;code>/home/jovyan/work&lt;/code>：容器內預設工作目錄&lt;/li>
&lt;li>&lt;code>--name&lt;/code>: Sets the container name; otherwise, a random name will be assigned&lt;/li>
&lt;/ul>
&lt;p>可自訂密碼或 token，詳見 &lt;a class="link" href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#docker-options" target="_blank" rel="noopener"
>官方文件&lt;/a>。&lt;/p>
&lt;h2 id="5-使用-gpu">5. 使用 GPU
&lt;/h2>&lt;p>若你的主機支援 NVIDIA GPU，可利用 &lt;a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html" target="_blank" rel="noopener"
>NVIDIA Container Toolkit&lt;/a> 讓 Docker 容器存取 GPU 資源。&lt;/p>
&lt;h3 id="步驟">步驟
&lt;/h3>&lt;ol>
&lt;li>
&lt;p>&lt;strong>安裝 NVIDIA 驅動程式&lt;/strong>&lt;br>
請先安裝對應作業系統的 NVIDIA 顯示卡驅動。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>安裝 NVIDIA Container Toolkit&lt;/strong>&lt;br>
依照官方文件安裝 &lt;code>nvidia-docker&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt-get install -y nvidia-docker2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo systemctl restart docker
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>&lt;strong>啟動支援 GPU 的 Jupyter Notebook 容器&lt;/strong>&lt;br>
使用 &lt;code>--gpus all&lt;/code> 參數啟動容器：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run --gpus all -p 8888:8888 --name gpu_note -v ~/name:/tf/name tensorflow/tensorflow:latest-gpu-jupyter
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>&lt;strong>驗證 GPU 是否可用&lt;/strong>&lt;br>
在 Notebook 中執行下列程式碼，確認 GPU 是否被偵測到：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> tensorflow &lt;span style="color:#66d9ef">as&lt;/span> tf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(tf&lt;span style="color:#f92672">.&lt;/span>config&lt;span style="color:#f92672">.&lt;/span>list_physical_devices(&lt;span style="color:#e6db74">&amp;#39;GPU&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>注意：部分映像檔可能需額外安裝 CUDA、cuDNN 或深度學習框架，請參考 &lt;a class="link" href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/recipes.html#using-gpus" target="_blank" rel="noopener"
>Jupyter Docker Stacks 官方說明&lt;/a>。&lt;/p>&lt;/blockquote>
&lt;hr>
&lt;h2 id="6-參考資料">6. 參考資料
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://jupyter-docker-stacks.readthedocs.io/" target="_blank" rel="noopener"
>Jupyter Docker Stacks 官方文件&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.docker.com/" target="_blank" rel="noopener"
>Docker 官方網站&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://jupyter.org/" target="_blank" rel="noopener"
>Jupyter Notebook 官方網站&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>如何使用 SSH 進行遠端連線教學</title><link>https://Dandelionlibra.github.io/post/ssh/how-to-use-ssh/</link><pubDate>Thu, 10 Jul 2025 16:03:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/ssh/how-to-use-ssh/</guid><description>&lt;h2 id="內容大綱">內容大綱
&lt;/h2>&lt;ol>
&lt;li>SSH 基本介紹&lt;/li>
&lt;li>安裝 SSH 客戶端
&lt;ul>
&lt;li>Linux&lt;/li>
&lt;li>Mac&lt;/li>
&lt;li>Windows&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>產生 SSH 金鑰&lt;/li>
&lt;li>設定 SSH 連線
&lt;ul>
&lt;li>將公鑰加入遠端主機&lt;/li>
&lt;li>測試連線&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>常見應用情境
&lt;ul>
&lt;li>使用 VSCode 透過 SSH 遠端開發&lt;/li>
&lt;li>使用 Git 透過 SSH 進行版本控制&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>參考資料&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="1-ssh-基本介紹">1. SSH 基本介紹
&lt;/h2>&lt;p>SSH（Secure Shell）是一種加密的網路協定，用於在不安全的網路上安全地進行遠端登入與其他網路服務。常見用途包括遠端伺服器管理、檔案傳輸等。&lt;/p>
&lt;hr>
&lt;h2 id="2-安裝-ssh-客戶端">2. 安裝 SSH 客戶端
&lt;/h2>&lt;h3 id="linux">Linux
&lt;/h3>&lt;p>大多數 Linux 發行版預設已安裝 OpenSSH。若未安裝，可使用以下指令：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt update
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install openssh-client
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="mac">Mac
&lt;/h3>&lt;p>macOS 預設已安裝 SSH 客戶端，可直接在終端機使用 &lt;code>ssh&lt;/code> 指令。&lt;/p>
&lt;h3 id="windows">Windows
&lt;/h3>&lt;p>建議安裝 &lt;a class="link" href="https://gitforwindows.org/" target="_blank" rel="noopener"
>Git for Windows&lt;/a> 或 &lt;a class="link" href="https://aka.ms/terminal" target="_blank" rel="noopener"
>Windows Terminal&lt;/a>。Windows 10 以上可啟用內建 OpenSSH：&lt;/p>
&lt;ol>
&lt;li>開啟「設定」&amp;gt;「應用程式」&amp;gt;「選擇性功能」。&lt;/li>
&lt;li>找到並安裝「OpenSSH Client」。&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="3-產生-ssh-金鑰">3. 產生 SSH 金鑰
&lt;/h2>&lt;p>在本地端產生 SSH 金鑰：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ssh-keygen -t rsa -b &lt;span style="color:#ae81ff">4096&lt;/span> -C &lt;span style="color:#e6db74">&amp;#34;your_email@example.com&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>依照提示設定檔案名稱與密碼。預設會產生於 &lt;code>~/.ssh/id_rsa&lt;/code>（私鑰）與 &lt;code>~/.ssh/id_rsa.pub&lt;/code>（公鑰）。&lt;/p>
&lt;ul>
&lt;li>&lt;code>ssh-keygen&lt;/code>:
&lt;ul>
&lt;li>Private key: Stored locally, default path is &lt;code>~/.ssh/id_rsa&lt;/code>&lt;/li>
&lt;li>Public key: Placed on the server to enable passwordless login, default path is &lt;code>~/.ssh/id_rsa.pub&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>-t&lt;/code>: Assign the key type&lt;/li>
&lt;li>&lt;code>-b&lt;/code>: Assign the key length&lt;/li>
&lt;li>&lt;code>-C&lt;/code>: Adds a comment to the key for identifying the user and purpose&lt;/li>
&lt;/ul>
&lt;p>Press Enter save as default, if exist same name key, will prompt if you want to cover it or not, if not, need to use other key name.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>C:&lt;span style="color:#ae81ff">\W&lt;/span>INDOWS&lt;span style="color:#ae81ff">\s&lt;/span>ystem32&amp;gt;ssh-keygen -t rsa -b &lt;span style="color:#ae81ff">4096&lt;/span> -C &lt;span style="color:#e6db74">&amp;#34;test@gmail.com&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Generating public/private rsa key pair.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Enter file in which to save the key &lt;span style="color:#f92672">(&lt;/span>C:&lt;span style="color:#ae81ff">\U&lt;/span>sers&lt;span style="color:#ae81ff">\u&lt;/span>sername/.ssh/id_rsa&lt;span style="color:#f92672">)&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># press enter login without password（安全性較低）&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 設定密碼的話，即使 private key 被盜，仍須密碼&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Enter passphrase &lt;span style="color:#f92672">(&lt;/span>empty &lt;span style="color:#66d9ef">for&lt;/span> no passphrase&lt;span style="color:#f92672">)&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Enter same passphrase again:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Your identification has been saved in C:&lt;span style="color:#ae81ff">\U&lt;/span>sers&lt;span style="color:#ae81ff">\u&lt;/span>sername/.ssh/id_rsa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Your public key has been saved in C:&lt;span style="color:#ae81ff">\U&lt;/span>sers&lt;span style="color:#ae81ff">\u&lt;/span>sername/.ssh/id_rsa.pub
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>The key fingerprint is:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SHA256:...省略... test@gmail.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>The key&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>s randomart image is:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>+---&lt;span style="color:#f92672">[&lt;/span>RSA 4096&lt;span style="color:#f92672">]&lt;/span>----+
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...省略...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="4-設定-ssh-連線">4. 設定 SSH 連線
&lt;/h2>&lt;h3 id="將公鑰加入遠端主機">將公鑰加入遠端主機
&lt;/h3>&lt;p>將本地的公鑰內容 (&lt;code>~/.ssh/id_rsa.pub&lt;/code>) 複製到遠端主機的 &lt;code>~/.ssh/authorized_keys&lt;/code> 檔案中，可使用指令：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ssh-copy-id user@remote_host
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>或手動複製本地內容到 server 中。&lt;/p>
&lt;p>On Linux or Mac, you can use the following command in the terminal to display your public key:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat ~/.ssh/id_rsa.pub
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="測試連線">測試連線
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ssh user@remote_host
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>若成功登入並且不需輸入密碼即設定完成。&lt;/p>
&lt;hr>
&lt;h2 id="5-常見應用情境">5. 常見應用情境
&lt;/h2>&lt;h3 id="使用-vscode-透過-ssh-遠端開發">使用 VSCode 透過 SSH 遠端開發
&lt;/h3>&lt;ol>
&lt;li>
&lt;p>安裝 &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh" target="_blank" rel="noopener"
>Remote - SSH 擴充套件&lt;/a>。&lt;br>
在 VSCode 中可看到 Remote-SSH 圖示，點擊後可進行連線設定：
&lt;img src="https://Dandelionlibra.github.io/image/Remote-SSH.png"
loading="lazy"
alt="Remote-SSH"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>點擊 VScode 左下角的雙箭頭圖標，或者按下 &lt;code>F1&lt;/code>，輸入 &lt;code>Remote-SSH: Connect to Host...&lt;/code>，選擇或新增主機。&lt;/p>
&lt;pre tabindex="0">&lt;code># remote_host 輸入伺服器 ip 位址
user@remote_host [-p port_number]
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>連線後輸入用戶在 server 上的密碼即可在遠端主機上開發，或者已經設定過金鑰可不用再輸密碼。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="使用-git-透過-ssh-進行版本控制">使用 Git 透過 SSH 進行版本控制
&lt;/h3>&lt;ol>
&lt;li>將公鑰加入 Git 服務（如 GitHub、GitLab）。&lt;/li>
&lt;li>使用 SSH 方式 clone 或 push：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>git clone git@github.com:username/repo.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="6-參考資料">6. 參考資料
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.openssh.com/manual.html" target="_blank" rel="noopener"
>OpenSSH 官方文件&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh" target="_blank" rel="noopener"
>GitHub SSH 教學&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://code.visualstudio.com/docs/remote/ssh" target="_blank" rel="noopener"
>VSCode Remote SSH 官方說明&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>LangChain 安裝與基本使用-1</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-1/</link><pubDate>Sun, 06 Jul 2025 15:33:11 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-1/</guid><description>&lt;h1 id="安裝-langchain">安裝 LangChain
&lt;/h1>&lt;p>使用 pip 指令安裝 LangChain 核心套件，其中提供各組件與基本框架。&lt;br>
LangChain 相關套件的詳細資訊可以參考&lt;a class="link" href="https://python.langchain.com/api_reference/" target="_blank" rel="noopener"
>langchain 官方文件&lt;/a>。&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install langchain
&lt;/code>&lt;/pre>&lt;p>安裝 LangChain 社群套件，其中包含由社群維護的第三方整合模組。&lt;br>
隨著 LangChain 的模組化，許多原本內建於核心套件的整合功能被轉移到此套件中，以保持核心套件的輕量化。&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install langchain_community
&lt;/code>&lt;/pre>&lt;p>安裝 LangChain 與本地 Ollama 模型整合專用驅動，
可以在 LangChain 中使用本地 Ollama 模型作為 LLM。
LangChain 官方維護的專門用於整合本地 Ollama LLM 的插件套件。&lt;/p>
&lt;p>因為 LangChain 在 0.3.1 後將原本內建於 &lt;code>langchain_community.llms.Ollama&lt;/code> 的 Ollama 整合模組 拆分為獨立的 &lt;code>langchain-ollama&lt;/code> 套件。&lt;br>
詳細資訊可以參考&lt;a class="link" href="https://python.langchain.com/api_reference/ollama/index.html" target="_blank" rel="noopener"
>langchain 官方文件&lt;/a>。&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install langchain-ollama
&lt;/code>&lt;/pre>&lt;h1 id="簡單應用">簡單應用
&lt;/h1>&lt;p>本文所有範例程式碼都可以在 &lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_code.ipynb" target="_blank" rel="noopener"
>Jupyter Notebook&lt;/a> 中找到。&lt;/p>
&lt;h2 id="文本生成">文本生成
&lt;/h2>&lt;p>LangChain 中 LLM 的最基本功能是根據輸入的文本生成新的文本。&lt;/p>
&lt;p>註:不清楚 Ollama 如何使用的可以去看我關於 Ollama 的基礎使用文章。&lt;/p>
&lt;pre tabindex="0">&lt;code>from langchain_ollama import OllamaLLM
llm = OllamaLLM(model=&amp;#34;llama3.1:8b&amp;#34;)
response = llm.invoke(&amp;#34;幫我取一個文雅的中國男孩名&amp;#34;)
print(response)
&lt;/code>&lt;/pre>&lt;p>temperature 用於控制 LLM 生成回答的隨機性與創造性。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;code>temperature&lt;/code> 值&lt;/th>
&lt;th>行為特性&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>0&lt;/code>&lt;/td>
&lt;td>完全可重現，幾乎總是給出相同回答，適合需要準確且穩定輸出時使用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>0.3 ~ 0.7&lt;/code>&lt;/td>
&lt;td>中度創造性，適合一般應用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>1.0&lt;/code>&lt;/td>
&lt;td>高度創造性，回答可能更多樣化與隨機&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>&amp;gt;1&lt;/code>&lt;/td>
&lt;td>非常隨機，回答可能跳脫常規&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>例如可以在剛剛的 response 中使用 options 將 temperature 設為 0，使輸出每次都會得到一樣的答案。&lt;/p>
&lt;pre tabindex="0">&lt;code>response = llm.invoke(&amp;#34;幫我取一個文雅的中國男孩名&amp;#34;, options={&amp;#34;temperature&amp;#34;: 0})
&lt;/code>&lt;/pre>&lt;h2 id="聊天模組">聊天模組
&lt;/h2>&lt;pre tabindex="0">&lt;code>from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage
Chatllm = ChatOllama(model=&amp;#34;llama3.1:8b&amp;#34;)
test = &amp;#34;幫我取一個文雅的中國男孩名&amp;#34;
messages = [HumanMessage(content=test)]
response = Chatllm.invoke(messages)
print(response)
&lt;/code>&lt;/pre>&lt;h3 id="ollamallm-vschatollama">OllamaLLM vs.ChatOllama
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>項目&lt;/th>
&lt;th>&lt;strong>OllamaLLM&lt;/strong>&lt;/th>
&lt;th>&lt;strong>ChatOllama&lt;/strong>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>來源&lt;/strong>&lt;/td>
&lt;td>&lt;code>from langchain_ollama import OllamaLLM&lt;/code>&lt;/td>
&lt;td>&lt;code>from langchain_ollama import ChatOllama&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>用途&lt;/strong>&lt;/td>
&lt;td>單輪文字生成（Single-turn LLM）&lt;/td>
&lt;td>多輪對話（Chat-based LLM）&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>典型應用場景&lt;/strong>&lt;/td>
&lt;td>單次回答、批次生成資料、文字生成工具&lt;/td>
&lt;td>聊天機器人、多輪上下文對話、Memory 結合&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>輸入型態&lt;/strong>&lt;/td>
&lt;td>&lt;code>str&lt;/code>（純文字 prompt）&lt;/td>
&lt;td>&lt;code>List[BaseMessage]&lt;/code>（包含 &lt;code>SystemMessage&lt;/code>, &lt;code>HumanMessage&lt;/code>, &lt;code>AIMessage&lt;/code>）&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>回傳型態&lt;/strong>&lt;/td>
&lt;td>&lt;code>str&lt;/code>（文字回應）&lt;/td>
&lt;td>&lt;code>AIMessage(content='...')&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>回傳內容存取&lt;/strong>&lt;/td>
&lt;td>直接使用 &lt;code>print(response)&lt;/code>&lt;/td>
&lt;td>使用 &lt;code>print(response.content)&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>是否支援多輪上下文&lt;/strong>&lt;/td>
&lt;td>X&lt;/td>
&lt;td>O&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>適合結合 Agent&lt;/strong>&lt;/td>
&lt;td>作為推論引擎&lt;/td>
&lt;td>作為 Chat Agent 對話引擎&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>可搭配 Memory&lt;/strong>&lt;/td>
&lt;td>X&lt;/td>
&lt;td>可搭配 Memory 實現上下文持續對話&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="鏈式結構">鏈式結構
&lt;/h2>&lt;p>連接多個 LLM 模組。
&lt;img src="https://Dandelionlibra.github.io/image/LLMChain.png"
loading="lazy"
alt="LLMChain"
>&lt;/p>
&lt;h3 id="如何避免重複定義相似的-llm-模組">如何避免重複定義相似的 LLM 模組?
&lt;/h3>&lt;p>使用提示模板(prompt template)去避免重複定義功能相似的組件。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.prompts &lt;span style="color:#f92672">import&lt;/span> PromptTemplate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm_model &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>user_prompt &lt;span style="color:#f92672">=&lt;/span> PromptTemplate&lt;span style="color:#f92672">.&lt;/span>from_template(&lt;span style="color:#e6db74">&amp;#34;幫我取一個&lt;/span>&lt;span style="color:#e6db74">{形容詞}{對象}&lt;/span>&lt;span style="color:#e6db74">名, 並對應一個小名。&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(user_prompt&lt;span style="color:#f92672">.&lt;/span>format(對象 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;寵物&amp;#39;&lt;/span>, 形容詞 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;可愛的&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(user_prompt&lt;span style="color:#f92672">.&lt;/span>format(對象 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;男孩&amp;#39;&lt;/span>, 形容詞 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;文雅的&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.chains &lt;span style="color:#f92672">import&lt;/span> LLMChain
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chain &lt;span style="color:#f92672">=&lt;/span> LLMChain(llm&lt;span style="color:#f92672">=&lt;/span>llm_model, prompt&lt;span style="color:#f92672">=&lt;/span>user_prompt)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(chain&lt;span style="color:#f92672">.&lt;/span>run(對象 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;小狗&amp;#39;&lt;/span>, 形容詞 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;有趣的&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="代理人">代理人
&lt;/h2>&lt;p>主要用於處理鏈式結構無法處理的問題，並可達成動態決策。
舉例而言，一般大型語言模型是無法聯網的，而為了讓 LangChain 去獲得最新的內容或者現有資料庫中不存在的資訊，就需要使用代理人 (Agents) 組件達成聯網。&lt;/p>
&lt;h3 id="行為方式">行為方式
&lt;/h3>&lt;p>代理人可以使用一系列預設的工具&lt;/p>
&lt;ul>
&lt;li>選擇工具&lt;/li>
&lt;li>使用工具&lt;/li>
&lt;li>觀測並處理工具使用結果&lt;/li>
&lt;li>重複以上步驟&lt;/li>
&lt;/ul>
&lt;h3 id="範例">範例
&lt;/h3>&lt;p>使代理人能完成數學運算任務。&lt;/p>
&lt;p>&lt;strong>step1: 定義底層 LLM 模組&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm_model &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>step2: 定義允許代理人使用的工具&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.agents &lt;span style="color:#f92672">import&lt;/span> initialize_agent, load_tools
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tools &lt;span style="color:#f92672">=&lt;/span> load_tools([&lt;span style="color:#e6db74">&amp;#34;llm-math&amp;#34;&lt;/span>], llm&lt;span style="color:#f92672">=&lt;/span>llm_model)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>step3: 初始化代理人&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>agent &lt;span style="color:#f92672">=&lt;/span> initialize_agent(tools, llm_model, agent&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;zero-shot-react-description&amp;#34;&lt;/span>, verbose&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>step4: 運行代理人&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>agent&lt;span style="color:#f92672">.&lt;/span>invoke(&lt;span style="color:#e6db74">&amp;#34;如果我有 100 元，買了 3 個蘋果，每個蘋果 10 元，剩下多少錢？&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="聊天紀錄">聊天紀錄
&lt;/h2>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain_ollama &lt;span style="color:#f92672">import&lt;/span> OllamaLLM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>llm_model &lt;span style="color:#f92672">=&lt;/span> OllamaLLM(model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> langchain.chains &lt;span style="color:#f92672">import&lt;/span> ConversationChain
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>conversation &lt;span style="color:#f92672">=&lt;/span> ConversationChain(llm&lt;span style="color:#f92672">=&lt;/span>llm_model, verbose&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>conversation&lt;span style="color:#f92672">.&lt;/span>run(&lt;span style="color:#e6db74">&amp;#34;我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: 我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?
AI:
&amp;gt; Finished chain.
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>&amp;#39;啊哈！你想要一個聰明又可愛的伴侶嗎？我有一些超好的建議！基於你的描述，我推測你可能是新手狗主人，所以我要首先介紹一下最適合初學者的犬種。有了這些犬種，你就能輕鬆地培養起一個聽話又善良的伴侶。\n\n其中，拉布拉多犬和金氏體型小獵犬（Cavalier King Charles Spaniel）都很受人喜愛，.......你對於犬種的偏好是什麼？你想要一隻大犬還是一隻小犬呢？&amp;#39;
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>conversation&lt;span style="color:#f92672">.&lt;/span>run(&lt;span style="color:#e6db74">&amp;#34;那貓呢?&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>輸出&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: 我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?
AI: 啊哈！你想要一個聰明又可愛的伴侶嗎？我有一些超好的建議！基於你的描述，我推測你可能是新手狗主人，所以我要首先介紹一下最適合初學者的犬種。有了這些犬種，你就能輕鬆地培養起一個聽話又善良的伴侶。
...省略...
最後，我想問一下，你對於犬種的偏好是什麼？你想要一隻大犬還是一隻小犬呢？
Human: 那貓呢?
AI:
&amp;gt; Finished chain.
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>&amp;#39;貓！我很樂意幫助你找一個適合你的貓伴侶！但是，值得注意的是，我之前主要是在說狗的話題，因為我的訓練資料集中在犬類上。\n\n但是在貓類方面，我可以提供一些基本信息。...省略...或者你對貓的需求和生活方式是否有所變化？&amp;#39;
&lt;/code>&lt;/pre>&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Introduction langchain</title><link>https://Dandelionlibra.github.io/post/langchain/introlangchain/</link><pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/introlangchain/</guid><description>&lt;h1 id="介紹-langchain">介紹 LangChain
&lt;/h1>&lt;p>LangChain 為 2022 年發布的開源框架，主要用於開發由語言模型驅動的應用程式，可連接多種語言模型與外部工具。&lt;br>
&lt;a class="link" href="https://www.langchain.com" target="_blank" rel="noopener"
>LangChain 官方網站&lt;/a>
&lt;img src="https://Dandelionlibra.github.io/image/ecosystem_packages-32943b32657e7a187770c9b585f22a64.png"
loading="lazy"
alt="LLMChain"
>&lt;/p>
&lt;h2 id="優點">優點
&lt;/h2>&lt;ul>
&lt;li>開源工具&lt;/li>
&lt;li>支持多種開源模型&lt;/li>
&lt;li>可整合多項外部服務&lt;/li>
&lt;/ul>
&lt;h2 id="主要組件">主要組件
&lt;/h2>&lt;ul>
&lt;li>模型 (Models)
&lt;ul>
&lt;li>語言模型、文本嵌入模型等等&amp;hellip;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>記憶體 (Memory)
&lt;ul>
&lt;li>短期與長期記憶，用於儲存與檢索聊天歷史&lt;/li>
&lt;li>包含對話緩衝記憶體、實體記憶體、向量儲存記憶體&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>代理 (Agents)
&lt;ul>
&lt;li>推理引擎&lt;/li>
&lt;li>可以根據給定的情境與數據做出合理的決策與推理&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>LangChain 藉由這些組件連結各種模型與工具，以達成檢索與分析數據，並可進行個性化的訂製。&lt;/p>
&lt;h2 id="主要解決問題">主要解決問題
&lt;/h2>&lt;ul>
&lt;li>如何格式化輸出?&lt;/li>
&lt;li>如何輸出很長的文本?&lt;/li>
&lt;li>如何呼叫多次 api?&lt;/li>
&lt;li>如何使 api 能呼叫外部的服務、工具?&lt;/li>
&lt;li>如何進行標準化的開發?&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h1 id="reference">Reference
&lt;/h1>&lt;ul>
&lt;li>&lt;a class="link" href="https://python.langchain.com/docs/introduction/" target="_blank" rel="noopener"
>https://python.langchain.com/docs/introduction/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=feFp5TbrVMo" target="_blank" rel="noopener"
>https://www.youtube.com/watch?v=feFp5TbrVMo&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
>https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>How to install and use Ollama?</title><link>https://Dandelionlibra.github.io/post/ollama/ollama/</link><pubDate>Sat, 05 Jul 2025 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/ollama/ollama/</guid><description>&lt;h1 id="介紹-ollama">介紹 Ollama
&lt;/h1>&lt;p>Ollama 是一個能在 本地（Windows/Mac/Linux）執行大型語言模型（LLM）和 Vision Language Model（VLM） 的框架。&lt;/p>
&lt;ul>
&lt;li>開源工具&lt;/li>
&lt;li>在本地端運行大型語言模型&lt;/li>
&lt;li>離線特性以保護隱私&lt;/li>
&lt;/ul>
&lt;h1 id="安裝-ollama">安裝 Ollama
&lt;/h1>&lt;h2 id="windows">Windows
&lt;/h2>&lt;p>至 &lt;a class="link" href="https://ollama.com/" target="_blank" rel="noopener"
>Ollama 官方網站&lt;/a>
下載 windows 版本後，點擊執行檔安裝。&lt;br>
安裝後於終端機中測試是否安裝成功。&lt;/p>
&lt;pre tabindex="0">&lt;code>ollama --help
&lt;/code>&lt;/pre>&lt;h2 id="mac">Mac
&lt;/h2>&lt;p>參考官方文件的下載指令。&lt;/p>
&lt;pre tabindex="0">&lt;code>brew install ollama
&lt;/code>&lt;/pre>&lt;h2 id="linux">Linux
&lt;/h2>&lt;p>參考官方文件的下載指令。&lt;/p>
&lt;pre tabindex="0">&lt;code>curl -fsSL https://ollama.com/install.sh | sh
&lt;/code>&lt;/pre>&lt;h1 id="如何使用-ollama">如何使用 Ollama?
&lt;/h1>&lt;h3 id="在本地啟動服務">在本地啟動服務
&lt;/h3>&lt;pre tabindex="0">&lt;code>ollama serve
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama serve
&lt;/code>&lt;/pre>&lt;h3 id="執行語言模型">執行語言模型
&lt;/h3>&lt;p>可以參考官方文件中提供的模型 &lt;a class="link" href="https://ollama.com/search" target="_blank" rel="noopener"
>https://ollama.com/search&lt;/a>&lt;/p>
&lt;pre tabindex="0">&lt;code>ollama run [model name]
&lt;/code>&lt;/pre>&lt;p>若是第一次運行該模型則會執行下載。
minicpm-V 是可用於解說圖片的語言模型，使用 &lt;code>/bye&lt;/code> 離開。&lt;/p>
&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama run minicpm-v:latest
pulling manifest
pulling 262843d4806a: 100% ▕█████████████████▏ 4.4 GB
pulling f8a805e9e620: 100% ▕█████████████████▏ 1.0 GB
pulling 60ed67c565f8: 100% ▕█████████████████▏ 506 B
pulling 8603ca877636: 100% ▕█████████████████▏ 5.7 KB
pulling f02dd72bb242: 100% ▕█████████████████▏ 59 B
pulling 175e3bb367ab: 100% ▕█████████████████▏ 566 B
verifying sha256 digest
writing manifest
success
&amp;gt;&amp;gt;&amp;gt; Discribe this picture &amp;#34;C:\Users\user\Downloads\picture.png&amp;#34;
Added image &amp;#39;C:\Users\user\Downloads\picture.png&amp;#39;
This image depicts a small white rodent sitting on the ground in an
outdoor setting. The animal appears to have soft fur with light
brownish-grey patches around its eyes and ears. Its pink nose is
prominent, as are its large black eyes which stand out against its pale
face.
&amp;gt;&amp;gt;&amp;gt; /bye
&lt;/code>&lt;/pre>&lt;p>終端呼叫模型並輸入指令。&lt;/p>
&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama run llama3.1:8b &amp;#34;define what is atom&amp;#34;
An **atom** (from the Greek word &amp;#34;atomos,&amp;#34; meaning indivisible) is the smallest
unit of a chemical element that retains its chemical properties and is
considered the fundamental building block of matter.
In simpler terms, an atom is:
1. **Indivisible**: An atom cannot be broken down into smaller particles using
any known means.
2. **Stable**: Atoms are stable entities that do not change their structure or
composition over time.
3. **Unique**: Each element has a unique set of atoms with specific properties.
... 忽略 ...
Would you like me to explain any related concepts or clarify anything about
atoms?
&lt;/code>&lt;/pre>&lt;h3 id="查看目前已安裝的語言模型">查看目前已安裝的語言模型
&lt;/h3>&lt;pre tabindex="0">&lt;code>ollama list
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama list
NAME ID SIZE MODIFIED
minicpm-v:latest c92bfad01205 5.5 GB 2 hours ago
llama3.1:8b 46e0c10c039e 4.9 GB 2 hours ago
&lt;/code>&lt;/pre>&lt;h3 id="刪除已安裝的語言模型">刪除已安裝的語言模型
&lt;/h3>&lt;pre tabindex="0">&lt;code>ollama rm [model name]
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>C:\Users\user&amp;gt;ollama rm minicpm-v:latest
deleted &amp;#39;minicpm-v:latest&amp;#39;
C:\Users\user&amp;gt;ollama list
NAME ID SIZE MODIFIED
llama3.1:8b 46e0c10c039e 4.9 GB 8 hours ago
&lt;/code>&lt;/pre>&lt;h3 id="">
&lt;/h3>&lt;h3 id="role-的-3-個主要類型">&lt;code>role&lt;/code> 的 3 個主要類型
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>role&lt;/th>
&lt;th>說明&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>system&lt;/code>&lt;/td>
&lt;td>系統角色，設定「這個模型該如何表現自己」，定義整個對話的角色背景、口吻、限制。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>user&lt;/code>&lt;/td>
&lt;td>使用者角色，模擬真實使用者輸入的訊息。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>assistant&lt;/code>&lt;/td>
&lt;td>模型扮演的角色回覆。用來提供上下文（例如多輪對話）。&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="使用-python-與程式串接">使用 Python 與程式串接
&lt;/h2>&lt;h3 id="使用-requests-呼叫">使用 requests 呼叫
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> requests
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># API URL&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>url &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;http://127.0.0.1:11434/v1/chat/completions&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 請求資料&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>payload &lt;span style="color:#f92672">=&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;model&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 對應你本地拉取的模型名稱&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;messages&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;system&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;You are a helpful assistant.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What is the capital of France?&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;assistant&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;The capital of France is Paris.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What is the population of Paris?&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;assistant&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;As of 2023, the population of Paris is about 2.1 million.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What river flows through Paris?&amp;#34;&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Headers&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>headers &lt;span style="color:#f92672">=&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;Content-Type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;application/json&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># &amp;#34;Authorization&amp;#34;: &amp;#34;Bearer ollama&amp;#34; # 傳遞身份驗證資訊，本地伺服器預設不驗證金鑰可省略&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 發送 POST 請求&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> requests&lt;span style="color:#f92672">.&lt;/span>post(url, headers&lt;span style="color:#f92672">=&lt;/span>headers, data&lt;span style="color:#f92672">=&lt;/span>json&lt;span style="color:#f92672">.&lt;/span>dumps(payload))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 顯示結果&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> response&lt;span style="color:#f92672">.&lt;/span>status_code &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span>: &lt;span style="color:#75715e"># HTTP 狀態碼 200 代表請求成功。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> response&lt;span style="color:#f92672">.&lt;/span>json() &lt;span style="color:#75715e"># 解析 JSON 資料，此方法將回應內容（ex.字串）轉換成 Python 的資料結構（ex.dict）&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(data[&lt;span style="color:#e6db74">&amp;#34;choices&amp;#34;&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;message&amp;#34;&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;Error:&amp;#34;&lt;/span>, response&lt;span style="color:#f92672">.&lt;/span>status_code, response&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>response 返回結構類似：&lt;/p>
&lt;pre tabindex="0">&lt;code>{
&amp;#34;id&amp;#34;: &amp;#34;chatcmpl-1234567890abcdef&amp;#34;,
&amp;#34;object&amp;#34;: &amp;#34;chat.completion&amp;#34;,
&amp;#34;created&amp;#34;: 1700000000,
&amp;#34;model&amp;#34;: &amp;#34;llama3.1:8b&amp;#34;,
&amp;#34;choices&amp;#34;: [
{
&amp;#34;index&amp;#34;: 0,
&amp;#34;message&amp;#34;: {
&amp;#34;role&amp;#34;: &amp;#34;assistant&amp;#34;,
&amp;#34;content&amp;#34;: &amp;#34;The capital of France is Paris.&amp;#34;
},
&amp;#34;finish_reason&amp;#34;: &amp;#34;stop&amp;#34;
}
],
&amp;#34;usage&amp;#34;: {
&amp;#34;prompt_tokens&amp;#34;: 20,
&amp;#34;completion_tokens&amp;#34;: 10,
&amp;#34;total_tokens&amp;#34;: 30
}
}
&lt;/code>&lt;/pre>&lt;h3 id="使用-openai-sdk-呼叫">使用 openai SDK 呼叫
&lt;/h3>&lt;h4 id="安裝-openai">安裝 openai
&lt;/h4>&lt;p>使用 pip 指令進行安裝。&lt;br>
ps.若沒有 pip 我未來再寫一篇安裝與使用 pip 的文章 ;)&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install openai
&lt;/code>&lt;/pre>&lt;p>查看安裝版本 &amp;amp; 是否已安裝過&lt;/p>
&lt;pre tabindex="0">&lt;code>pip show openai
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>WARNING: Package(s) not found: openai
&lt;/code>&lt;/pre>&lt;p>若已安裝過且版本小於 1.0.0，更新 openai 套件&lt;/p>
&lt;pre tabindex="0">&lt;code>pip install --upgrade openai
&lt;/code>&lt;/pre>&lt;h3 id="使用語言模型">使用語言模型
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> openai &lt;span style="color:#f92672">import&lt;/span> OpenAI
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>client &lt;span style="color:#f92672">=&lt;/span> OpenAI(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># base_url = &amp;#34;http://localhost:11434/v1&amp;#34;,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> base_url &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;http://127.0.0.1:11434/v1&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 本地 Ollama 伺服器的 URL，預設端口為 11434&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> api_key &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;ollama&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 本地 Ollama 不驗證密鑰，只要隨意填入即可，習慣使用 ollama&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 呼叫本地 Ollama 伺服器進行 Chat Completion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> client&lt;span style="color:#f92672">.&lt;/span>chat&lt;span style="color:#f92672">.&lt;/span>completions&lt;span style="color:#f92672">.&lt;/span>create(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;llama3.1:8b&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> messages&lt;span style="color:#f92672">=&lt;/span>[ &lt;span style="color:#75715e"># 設定對話內容&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;system&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 設定模型行為&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;You are a helpful assistant.&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 使用者輸入的問題&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;What is the capital of France?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(response&lt;span style="color:#f92672">.&lt;/span>choices[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>message&lt;span style="color:#f92672">.&lt;/span>content)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="使用-vision-model">使用 Vision model
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> base64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> openai &lt;span style="color:#f92672">import&lt;/span> OpenAI
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_path &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">r&lt;/span>&lt;span style="color:#e6db74">&amp;#34;C:\圖片路徑.png&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> open(image_path, &lt;span style="color:#e6db74">&amp;#34;rb&amp;#34;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> img_file:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> b64_string &lt;span style="color:#f92672">=&lt;/span> base64&lt;span style="color:#f92672">.&lt;/span>b64encode(img_file&lt;span style="color:#f92672">.&lt;/span>read())&lt;span style="color:#f92672">.&lt;/span>decode(&lt;span style="color:#e6db74">&amp;#34;utf-8&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 建立可傳入 Ollama 的完整 URL 字串&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_b64_url &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;data:image/png;base64,&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>b64_string&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>client &lt;span style="color:#f92672">=&lt;/span> OpenAI(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> base_url&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;http://127.0.0.1:11434/v1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> api_key&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;ollama&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> client&lt;span style="color:#f92672">.&lt;/span>chat&lt;span style="color:#f92672">.&lt;/span>completions&lt;span style="color:#f92672">.&lt;/span>create(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;minicpm-v&amp;#34;&lt;/span>, &lt;span style="color:#75715e"># 支援圖片輸入的模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> messages&lt;span style="color:#f92672">=&lt;/span>[
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;role&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;content&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Please describe the image in detail.&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;image_url&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;image_url&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;url&amp;#34;&lt;/span>: image_b64_url
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(response&lt;span style="color:#f92672">.&lt;/span>choices[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>message&lt;span style="color:#f92672">.&lt;/span>content)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>
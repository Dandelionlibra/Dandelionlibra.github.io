<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Langchain on YuChen</title><link>https://Dandelionlibra.github.io/tags/langchain/</link><description>Recent content in Langchain on YuChen</description><generator>Hugo -- gohugo.io</generator><language>zh-Hant-TW</language><lastBuildDate>Fri, 18 Jul 2025 08:39:00 +0800</lastBuildDate><atom:link href="https://Dandelionlibra.github.io/tags/langchain/index.xml" rel="self" type="application/rss+xml"/><item><title>LangChain 記憶型檢索問答：《小王子》文本互動實踐</title><link>https://Dandelionlibra.github.io/post/langchain/retrieverqa-2/</link><pubDate>Fri, 18 Jul 2025 08:39:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/retrieverqa-2/</guid><description>&lt;h2 id="以-langchain-記憶型檢索問答實現小王子文本互動"&gt;以 LangChain 記憶型檢索問答實現《小王子》文本互動
&lt;/h2&gt;&lt;p&gt;本文介紹如何利用 LangChain 框架，結合 Ollama Embeddings、ChromaDB 與記憶型問答鏈（RunnableWithMessageHistory），實現能記住上下文的互動式檢索問答。以《小王子》文本為例，展示記憶型問答與一般檢索問答的差異。&lt;/p&gt;
&lt;h3 id="一記憶型問答鏈設計"&gt;一、記憶型問答鏈設計
&lt;/h3&gt;&lt;p&gt;LangChain 提供 &lt;code&gt;RunnableWithMessageHistory&lt;/code&gt;，可根據 session_id 保存對話歷程，讓模型具備「記憶」功能。核心流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;建立 InMemoryHistory 類&lt;/strong&gt;：用於儲存每個 session 的訊息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;載入 PDF 並分割文本&lt;/strong&gt;：使用 &lt;code&gt;PyPDFLoader&lt;/code&gt; 和 &lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;建立向量資料庫&lt;/strong&gt;：用 Ollama Embeddings 將文本轉向量，存入 ChromaDB。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;設計 Prompt 與 Chain&lt;/strong&gt;：結合歷史訊息與提問，串接 LLM。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;啟動記憶型問答鏈&lt;/strong&gt;：每次提問都能保留上下文，實現多輪互動。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="主要程式片段"&gt;主要程式片段
&lt;/h4&gt;&lt;p&gt;完整程式碼請參考：&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/example/LangChain_memory_ask_via_pdf.ipynb" target="_blank" rel="noopener"
&gt;GitHub 範例程式&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 建立記憶管理器&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#66d9ef"&gt;class&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;InMemoryHistory&lt;/span&gt;(BaseChatMessageHistory, BaseModel):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; messages: list[BaseMessage] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; Field(default_factory&lt;span style="color:#f92672"&gt;=&lt;/span&gt;list)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;add_messages&lt;/span&gt;(self, messages: list[BaseMessage]) &lt;span style="color:#f92672"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#66d9ef"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; self&lt;span style="color:#f92672"&gt;.&lt;/span&gt;messages&lt;span style="color:#f92672"&gt;.&lt;/span&gt;extend(messages)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;clear&lt;/span&gt;(self) &lt;span style="color:#f92672"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#66d9ef"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; self&lt;span style="color:#f92672"&gt;.&lt;/span&gt;messages &lt;span style="color:#f92672"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;store &lt;span style="color:#f92672"&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;get_by_session_id&lt;/span&gt;(session_id: str) &lt;span style="color:#f92672"&gt;-&amp;gt;&lt;/span&gt; BaseChatMessageHistory:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;if&lt;/span&gt; session_id &lt;span style="color:#f92672"&gt;not&lt;/span&gt; &lt;span style="color:#f92672"&gt;in&lt;/span&gt; store:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; store[session_id] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; InMemoryHistory()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;return&lt;/span&gt; store[session_id]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 啟動記憶型問答鏈&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;chain_with_history &lt;span style="color:#f92672"&gt;=&lt;/span&gt; RunnableWithMessageHistory(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chain,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; get_by_session_id,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; input_messages_key&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;question&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; history_messages_key&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;history&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="二互動範例"&gt;二、互動範例
&lt;/h3&gt;&lt;h4 id="問答一你看過經典故事小王子嗎"&gt;問答一：你看過經典故事小王子嗎？
&lt;/h4&gt;&lt;p&gt;模型回答：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我看過《小王子》！這是個非常著名的小說，作者是安托瓦內·德·聖-埃克絮佩里。故事充滿哲理與寓意，讓人思考生命、愛情和友誼。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="問答二啟蒙了你什麼"&gt;問答二：啟蒙了你什麼？
&lt;/h4&gt;&lt;p&gt;模型回答：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;小王子和這個故事都啟蒙了我對生命、愛情和友誼的看法。它教會我要珍惜生命、關心他人和追求夢想。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="問答三你覺得小王子是個怎樣的人"&gt;問答三：你覺得小王子是個怎樣的人？
&lt;/h4&gt;&lt;p&gt;模型回答：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;小王子是一個獨特、敏感和浪漫的年輕人。他能看到世界的美麗和價值，願意為之付出努力，但也有些缺乏勇氣承認自己的情感。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="問答四續寫第二部小王子"&gt;問答四：續寫第二部小王子
&lt;/h4&gt;&lt;p&gt;模型回答：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;根據小王子的故事，我們可以繼續他的冒險旅程。他想探索更大的世界，沿途遇到許多新奇的生物和景色，對每件事都充滿好奇和興趣。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="三記憶型問答-vs-一般檢索問答"&gt;三、記憶型問答 VS 一般檢索問答
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;記憶型問答&lt;/strong&gt;：能保留上下文，支持多輪互動，回答更貼合對話脈絡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一般檢索問答&lt;/strong&gt;：每次提問獨立，無法記住前文，回答較為片段。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="一般檢索問答範例"&gt;一般檢索問答範例
&lt;/h4&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;qa_chain &lt;span style="color:#f92672"&gt;=&lt;/span&gt; RetrievalQA&lt;span style="color:#f92672"&gt;.&lt;/span&gt;from_chain_type(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; llm&lt;span style="color:#f92672"&gt;=&lt;/span&gt;ollama_llm,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; retriever&lt;span style="color:#f92672"&gt;=&lt;/span&gt;vector_db&lt;span style="color:#f92672"&gt;.&lt;/span&gt;as_retriever(),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;qa_chain&lt;span style="color:#f92672"&gt;.&lt;/span&gt;invoke(&lt;span style="color:#e6db74"&gt;&amp;#39;你看過經典故事小王子嘛？&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 回答：是的，我看過《小王子》。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="四總結"&gt;四、總結
&lt;/h3&gt;&lt;p&gt;結合 LangChain 記憶型問答鏈，可針對文本進行多輪互動，模型能記住上下文，回答更自然且具延續性。適合用於深入文本探索、故事續寫等場景。&lt;/p&gt;
&lt;h2 id="參考資料"&gt;參考資料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html" target="_blank" rel="noopener"
&gt;LangChain RunnableWithMessageHistory 官方文件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://dandelionlibra.github.io/post/langchain/retrieverqa-1/" target="_blank" rel="noopener"
&gt;LangChain 檢索問答基礎篇&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>使用 Langchain 框架進行檢索提問</title><link>https://Dandelionlibra.github.io/post/langchain/retrieverqa-1/</link><pubDate>Fri, 18 Jul 2025 02:59:00 +0800</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/retrieverqa-1/</guid><description>&lt;h2 id="程式運行詳細步驟"&gt;程式運行詳細步驟
&lt;/h2&gt;&lt;p&gt;以下以 Jupyter Notebook 格式，記錄如何使用 LangChain 框架結合 Ollama Embeddings 與 ChromaDB，實現 PDF 文件的檢索式問答。&lt;br&gt;
詳細程式參考：&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/example/LangChain_ask_via_pdf.ipynb" target="_blank" rel="noopener"
&gt;GitHub 範例程式&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="1-載入必要套件與初始化-embedding-模型"&gt;1. 載入必要套件與初始化 Embedding 模型
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_community.document_loaders &lt;span style="color:#f92672"&gt;import&lt;/span&gt; PyPDFLoader
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_text_splitters &lt;span style="color:#f92672"&gt;import&lt;/span&gt; RecursiveCharacterTextSplitter
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_ollama &lt;span style="color:#f92672"&gt;import&lt;/span&gt; OllamaEmbeddings
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_chroma &lt;span style="color:#f92672"&gt;import&lt;/span&gt; Chroma
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 初始化 Ollama Embeddings&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;embeddings_model &lt;span style="color:#f92672"&gt;=&lt;/span&gt; OllamaEmbeddings(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_url&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#39;http://dandelion-ollama-1:11434&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;bge-m3:567m&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="2-載入-pdf-文件並分割文本"&gt;2. 載入 PDF 文件並分割文本
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 載入 PDF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;loader &lt;span style="color:#f92672"&gt;=&lt;/span&gt; PyPDFLoader(&lt;span style="color:#e6db74"&gt;&amp;#39;./data/PDF_file.pdf&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;docs &lt;span style="color:#f92672"&gt;=&lt;/span&gt; loader&lt;span style="color:#f92672"&gt;.&lt;/span&gt;load_and_split()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 設定分段參數&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;chunk_size &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#ae81ff"&gt;256&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;chunk_overlap &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#ae81ff"&gt;128&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;text_splitter &lt;span style="color:#f92672"&gt;=&lt;/span&gt; RecursiveCharacterTextSplitter(chunk_size&lt;span style="color:#f92672"&gt;=&lt;/span&gt;chunk_size, chunk_overlap&lt;span style="color:#f92672"&gt;=&lt;/span&gt;chunk_overlap)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;documents &lt;span style="color:#f92672"&gt;=&lt;/span&gt; text_splitter&lt;span style="color:#f92672"&gt;.&lt;/span&gt;split_documents(docs)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="3-建立-chroma-向量資料庫"&gt;3. 建立 Chroma 向量資料庫
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;db &lt;span style="color:#f92672"&gt;=&lt;/span&gt; Chroma&lt;span style="color:#f92672"&gt;.&lt;/span&gt;from_documents(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; documents,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embedding&lt;span style="color:#f92672"&gt;=&lt;/span&gt;embeddings_model,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; persist_directory&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;./story-db&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="4-啟動檢索式問答鏈-retrievalqa-chain"&gt;4. 啟動檢索式問答鏈 (RetrievalQA Chain)
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_ollama &lt;span style="color:#f92672"&gt;import&lt;/span&gt; OllamaLLM
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.chains &lt;span style="color:#f92672"&gt;import&lt;/span&gt; RetrievalQA
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;ollama_llm &lt;span style="color:#f92672"&gt;=&lt;/span&gt; OllamaLLM(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_url&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#39;http://dandelion-ollama-1:11434&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;llama3.1:8b&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; temperature&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#ae81ff"&gt;0.0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; num_predict&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#ae81ff"&gt;512&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;qa_chain &lt;span style="color:#f92672"&gt;=&lt;/span&gt; RetrievalQA&lt;span style="color:#f92672"&gt;.&lt;/span&gt;from_chain_type(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; llm&lt;span style="color:#f92672"&gt;=&lt;/span&gt;ollama_llm,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; retriever&lt;span style="color:#f92672"&gt;=&lt;/span&gt;db&lt;span style="color:#f92672"&gt;.&lt;/span&gt;as_retriever(),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="5-問答範例及模型回答"&gt;5. 問答範例及模型回答
&lt;/h3&gt;&lt;p&gt;以下僅列出部分問答範例，其餘可自行嘗試：&lt;/p&gt;
&lt;hr&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;query &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;玫瑰是誰？&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;result &lt;span style="color:#f92672"&gt;=&lt;/span&gt; qa_chain&lt;span style="color:#f92672"&gt;.&lt;/span&gt;invoke(query)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(result)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;模型回答：&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;{&amp;#39;query&amp;#39;: &amp;#39;玫瑰是誰？&amp;#39;, &amp;#39;result&amp;#39;: &amp;#39;玫瑰是小王子的玫瑰花，還有園中其他五千朵玫瑰花（但小王子的玫瑰花是獨一無二的）。&amp;#39;}
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;qa_chain&lt;span style="color:#f92672"&gt;.&lt;/span&gt;invoke(&lt;span style="color:#e6db74"&gt;&amp;#39;小王子的來歷是什？&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;模型回答：&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;{&amp;#39;query&amp;#39;: &amp;#39;小王子的來歷是什？&amp;#39;, &amp;#39;result&amp;#39;: &amp;#39;小王子所來自的那個星球是小行星B612。&amp;#39;}
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;qa_chain&lt;span style="color:#f92672"&gt;.&lt;/span&gt;invoke(&lt;span style="color:#e6db74"&gt;&amp;#39;你覺得小王子是個怎樣的人？&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;模型回答：&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;{&amp;#39;query&amp;#39;: &amp;#39;你覺得小王子是個怎樣的人？&amp;#39;, &amp;#39;result&amp;#39;: &amp;#39;根據文中描述，小王子的性格可以看出來。他似乎是一個敏感、浪漫、獨立的年輕人。他對他所遇到的陌生人的評價很細致，能夠看穿別人的真實面目。他也顯示出對自由和自主的渴望。&amp;#39;}
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;更多問題可依據文本內容自由發揮，探索不同答案。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="筆記重點"&gt;筆記重點
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;透過 &lt;code&gt;PyPDFLoader&lt;/code&gt; 讀取 PDF，並用 &lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt; 分割文本，利於後續檢索。&lt;/li&gt;
&lt;li&gt;使用 Ollama Embeddings 將文本轉為向量，存入 ChromaDB。&lt;/li&gt;
&lt;li&gt;結合 Ollama LLM 與 RetrievalQA Chain，實現自然語言問答。&lt;/li&gt;
&lt;li&gt;可針對文本內容進行多樣化提問，快速獲得答案。&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>LangChain 基本使用-4</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-4/</link><pubDate>Tue, 15 Jul 2025 21:12:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-4/</guid><description>&lt;h1 id="甚麼是-langchain-的鏈結構"&gt;甚麼是 Langchain 的鏈結構?
&lt;/h1&gt;&lt;h2 id="定義"&gt;定義
&lt;/h2&gt;&lt;p&gt;將小的模組串起來，而形成的串列結構。&lt;br&gt;
舉例: 定義提示詞 -&amp;gt; 選擇 LLM -&amp;gt; 運行 inferencing(呼叫 function) -&amp;gt; 得到結果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;優點:
&lt;ul&gt;
&lt;li&gt;模組化更容易修改個別功能，而不影響其他部分&lt;/li&gt;
&lt;li&gt;提高了模組的標準化、可再用性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="鏈結構分類"&gt;鏈結構分類
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;基礎鏈結構&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;LLM chain (單鏈)&lt;br&gt;
對應直接調用大型語言模型，最少 1 次 LLM call。&lt;br&gt;
ex. llm.invoke()&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定義 prompt&lt;/li&gt;
&lt;li&gt;定義 llm&lt;/li&gt;
&lt;li&gt;定義 chain&lt;/li&gt;
&lt;li&gt;運行 predict&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Router chain (多鏈)&lt;br&gt;
判斷要使用哪個鏈，最少 2 次 LLM call，第一次呼叫是為了決定使用哪條鏈，第二次是為了得到回答。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定義 prompt&lt;/li&gt;
&lt;li&gt;定義 llm/emdeddings&lt;/li&gt;
&lt;li&gt;定義 chain (多鏈併行，選一條鏈處理)&lt;/li&gt;
&lt;li&gt;運行 predict
&lt;img src="https://Dandelionlibra.github.io/image/Router_chain.JPG"
loading="lazy"
alt="Data_Connection"
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sequential chain (多鏈)&lt;br&gt;
上一個語言模型的調用結果是下一個語言模型調用的輸入。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定義 prompt&lt;/li&gt;
&lt;li&gt;定義 llm/emdeddings&lt;/li&gt;
&lt;li&gt;定義 chain (多鏈併行，依照順序執行)&lt;/li&gt;
&lt;li&gt;運行 predict&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transformation chain (文本處理鏈)&lt;br&gt;
將輸入文本處理後。
&lt;img src="https://Dandelionlibra.github.io/image/Transformation_chain.JPG"
loading="lazy"
alt="Data_Connection"
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;應用鏈結構&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Document chains type (長文本處理鏈): 總結、向量數據庫&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stuff:
當要詢問模型沒有訓練過的訊息時，要透過 prompt 將資訊傳入，但若輸入長度超過模型可接受的最大 token 會無法運行。
&lt;img src="https://Dandelionlibra.github.io/image/Stuff.JPG"
loading="lazy"
alt="Data_Connection"
&gt;&lt;/li&gt;
&lt;li&gt;Refine:
調用多次語言模型，將原本的長上下文分段落，避免輸入超過最大 token 的問題，將上一輪的輸出作為中間回答放到第三部分中
&lt;img src="https://Dandelionlibra.github.io/image/Refine.JPG"
loading="lazy"
alt="Data_Connection"
&gt;&lt;/li&gt;
&lt;li&gt;Map reduce&lt;/li&gt;
&lt;li&gt;Map rerank&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Retrieval QA&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="程式事例"&gt;程式事例
&lt;/h2&gt;&lt;p&gt;&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/example/LangChain_link.ipynb" target="_blank" rel="noopener"
&gt;詳細程式請參閱&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="reference"&gt;Reference
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
&gt;https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>LangChain 基本使用-3</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-3/</link><pubDate>Mon, 14 Jul 2025 10:56:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-3/</guid><description>&lt;h1 id="data-connection"&gt;Data Connection
&lt;/h1&gt;&lt;h2 id="定義"&gt;定義
&lt;/h2&gt;&lt;p&gt;許多基於大型語言模型而執行的應用常會用到模型數據集中沒有的數據。而針對這類需求，Langchain 提供了許多工具使用戶可以從各類數據源中加載新的數據、轉換數據、儲存數據、訪問數據。&lt;/p&gt;
&lt;p&gt;※大型語言模型不可能在訓練階段就涵蓋所有數據，且每時每刻都有新的數據產生。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文檔載入器(Document loaders): 從多種數據源加載文檔，ex.網頁、pdf。&lt;/li&gt;
&lt;li&gt;文檔轉換器: 拆分文檔、丟棄冗餘文檔，主要運行在文檔載入器之後，針對加載出來的文檔做處理。&lt;/li&gt;
&lt;li&gt;文本嵌入(embedding)模型: 將非結構化的文本轉為浮點數列表。&lt;/li&gt;
&lt;li&gt;向量數據庫: 儲存和搜尋 embedding 數據。&lt;/li&gt;
&lt;li&gt;檢索器: 查詢向量數據。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="data-connection-處理流程"&gt;Data Connection 處理流程
&lt;/h2&gt;&lt;p&gt;&lt;img src="https://Dandelionlibra.github.io/image/Data_Connection.JPG"
loading="lazy"
alt="Data_Connection"
&gt;&lt;/p&gt;
&lt;h3 id="1-文本載入器document-loaders"&gt;1. 文本載入器(Document loaders)
&lt;/h3&gt;&lt;p&gt;將文本數據從原始數據(Source)中提取出來，改成 langchain 認識的語言，總而言之就是將非結構化的文本數據加載到結構化的字符串中。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;輸入: 各種數據源，ex.PDF、URL、影片。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;輸出: 一系列的 Document 對象，例，有6頁pdf會產出6個 documents，以分別對應。
&lt;img src="https://Dandelionlibra.github.io/image/Document_loaders.JPG"
loading="lazy"
alt="Document_loaders.JPG"
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;舉例&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;結構化文件: 加載 CSV 文件&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.document_loaders.csv_loader &lt;span style="color:#f92672"&gt;import&lt;/span&gt; CSVLoader
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;loader &lt;span style="color:#f92672"&gt;=&lt;/span&gt; CSVLoader(file_path&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#39;./data/file.csv&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;data &lt;span style="color:#f92672"&gt;=&lt;/span&gt; loader&lt;span style="color:#f92672"&gt;.&lt;/span&gt;load()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;非結構化文件: 純文本、ppt、html、pdf、圖片。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="link" href="https://python.langchain.com/docs/integrations/document_loaders/" target="_blank" rel="noopener"
&gt;全部文件格式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-文本分割器document-transformers"&gt;2. 文本分割器(Document transformers)
&lt;/h3&gt;&lt;p&gt;將加載好的文檔進行轉換，從而更好的適應各種場景。舉例，將文檔拆分成較小的塊，以避免大型語言模型對於輸入長度的限制。&lt;br&gt;
Langchain 中提供的文檔轉換器可以提供拆分、合併、過濾等功能。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文本分割器-拆分: 分割長文本，根據語意相關性將所有有關聯的文本放在同一個分割段中。&lt;br&gt;
&lt;img src="https://Dandelionlibra.github.io/image/Document_transformers.JPG"
loading="lazy"
alt="Document_transformers.JPG.JPG"
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;將文本拆分為小、具語意意義的塊。&lt;/li&gt;
&lt;li&gt;將小塊組合成大塊，直到達到一定規模。&lt;/li&gt;
&lt;li&gt;將達到一定規模的塊作為獨立的文本片段，然後創建新的文本塊，此外，為了維持塊間的連貫性，兩個文本塊之間會有重疊的部分。&lt;br&gt;
以圖例而言，Document 由一塊變為三塊。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="3-文本詞嵌入word-embedding"&gt;3. 文本詞嵌入(Word Embedding)
&lt;/h3&gt;&lt;p&gt;詞嵌入是將詞語數值化表達的方式，通常會將詞映射到高維的向量中，使電腦藉由高維的數字化表達得以理解自然語言的語意，接近的語意=接近的向量距離。&lt;/p&gt;
&lt;h3 id="4-向量數據庫"&gt;4. 向量數據庫
&lt;/h3&gt;&lt;p&gt;用於儲存嵌入的數據向量。&lt;/p&gt;
&lt;h3 id="5-檢索器"&gt;5. 檢索器
&lt;/h3&gt;&lt;p&gt;根據輸入的非結構化查詢語句返回對應文檔的接口(一系列 Documents 對象)。&lt;br&gt;
不同於向量數據庫，向量數據庫可以視為一種具備儲存功能的檢索器，但檢索器不一定需要具備儲存的功能。&lt;/p&gt;
&lt;h2 id="程式事例"&gt;程式事例
&lt;/h2&gt;&lt;p&gt;&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_csv_loader.ipynb" target="_blank" rel="noopener"
&gt;詳細程式請參閱&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="reference"&gt;Reference
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
&gt;https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>LangChain 基本使用-2</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</link><pubDate>Sun, 13 Jul 2025 08:06:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-2/</guid><description>&lt;h1 id="提示模板"&gt;提示模板
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;對語言模型的指令&lt;/li&gt;
&lt;li&gt;提供簡單的事例給語言模型使模型接近理想結果&lt;/li&gt;
&lt;li&gt;提給語言模型的問題&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain &lt;span style="color:#f92672"&gt;import&lt;/span&gt; PromptTemplate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 使用 PromptTemplate 來定義對話的提示模板&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;no_input_prompt_template &lt;span style="color:#f92672"&gt;=&lt;/span&gt; PromptTemplate(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; input_variables&lt;span style="color:#f92672"&gt;=&lt;/span&gt;[],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; template&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;說個故事&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;multi_input_prompt_template &lt;span style="color:#f92672"&gt;=&lt;/span&gt; PromptTemplate(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; input_variables&lt;span style="color:#f92672"&gt;=&lt;/span&gt;[&lt;span style="color:#e6db74"&gt;&amp;#34;主題&amp;#34;&lt;/span&gt;, &lt;span style="color:#e6db74"&gt;&amp;#34;風格&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; template&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;請講一個關於&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{主題}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;的故事，風格是&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{風格}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;。&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;multi_input_prompt_template&lt;span style="color:#f92672"&gt;.&lt;/span&gt;format(主題&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;勇氣&amp;#34;&lt;/span&gt;, 風格&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;童話&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# other example，由 from_template 將 string 轉成 PromptTemplate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;template &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;請講一個關於&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{主題}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;的故事，風格是&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{風格}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;。&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;prompt_template &lt;span style="color:#f92672"&gt;=&lt;/span&gt; PromptTemplate&lt;span style="color:#f92672"&gt;.&lt;/span&gt;from_template(template)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 此時輸出 [&amp;#34;主題&amp;#34;, &amp;#34;風格&amp;#34;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;prompt_template&lt;span style="color:#f92672"&gt;.&lt;/span&gt;input_variables
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="接收部分參數"&gt;接收部分參數
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在所有參數無法同步獲取時，可以先用現有參數傳入第一個模板，以獲得新的參數，再將新參數傳入新的模板中，以得到最終想問的問題。&lt;br&gt;
&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_1.JPG"
loading="lazy"
alt="partial_prompt_template"
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有些參數要用特定方式獲取 (ex.函式呼叫)
&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_2.JPG"
loading="lazy"
alt="partial_prompt_template"
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain &lt;span style="color:#f92672"&gt;import&lt;/span&gt; PromptTemplate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; datetime &lt;span style="color:#f92672"&gt;import&lt;/span&gt; datetime
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;get_date&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; now &lt;span style="color:#f92672"&gt;=&lt;/span&gt; datetime&lt;span style="color:#f92672"&gt;.&lt;/span&gt;now()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;return&lt;/span&gt; now&lt;span style="color:#f92672"&gt;.&lt;/span&gt;strftime(&lt;span style="color:#e6db74"&gt;&amp;#34;%m月&lt;/span&gt;&lt;span style="color:#e6db74"&gt;%d&lt;/span&gt;&lt;span style="color:#e6db74"&gt;日&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;prompt &lt;span style="color:#f92672"&gt;=&lt;/span&gt; PromptTemplate(template&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;告訴我&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{城市}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;在&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{年份}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;年&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{日期}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;的平均氣溫是多少？&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; input_variables&lt;span style="color:#f92672"&gt;=&lt;/span&gt;[&lt;span style="color:#e6db74"&gt;&amp;#34;城市&amp;#34;&lt;/span&gt;, &lt;span style="color:#e6db74"&gt;&amp;#34;年份&amp;#34;&lt;/span&gt;, &lt;span style="color:#e6db74"&gt;&amp;#34;日期&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;PromptTemplate_2 &lt;span style="color:#f92672"&gt;=&lt;/span&gt; prompt&lt;span style="color:#f92672"&gt;.&lt;/span&gt;partial(城市&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;台北&amp;#34;&lt;/span&gt;, 日期&lt;span style="color:#f92672"&gt;=&lt;/span&gt;get_date())
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(PromptTemplate_2&lt;span style="color:#f92672"&gt;.&lt;/span&gt;format(年份&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;2023&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出:&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;告訴我台北在2023年07月13日的平均氣溫是多少？
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="少樣本學習-few-shot"&gt;少樣本學習 (few-shot)
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;藉由少量的樣本、範例，使語言模型能處理特定問題&lt;/li&gt;
&lt;li&gt;不同於微調 (fine-tuning)，微調會使用大量樣本，最終會改變模型本身&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;例子:&lt;br&gt;
&amp;ldquo;你好嗎?&amp;rdquo; - &amp;ldquo;主人，我很好。&amp;rdquo;&lt;br&gt;
&amp;ldquo;今天禮拜幾?&amp;rdquo; - &amp;ldquo;主人，今天禮拜日。&amp;rdquo;&lt;br&gt;
&amp;ldquo;天氣真好呀。&amp;rdquo; - &amp;ldquo;主人，是的，今天天氣非常好。&amp;rdquo;&lt;/p&gt;
&lt;p&gt;希望模型學會&amp;quot;主人&amp;quot;的前綴。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="fewshot-prompt-template"&gt;FewShot Prompt Template
&lt;/h3&gt;&lt;p&gt;利用提示模板，將樣本數據加載成完整的提示詞，接著將樣本連同提示詞一併送給樣本提示模板，最終得到完整的提示詞。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://Dandelionlibra.github.io/image/prompt_template_3.JPG"
loading="lazy"
alt="partial_prompt_template"
&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.prompts.few_shot &lt;span style="color:#f92672"&gt;import&lt;/span&gt; FewShotPromptTemplate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.prompts.prompt &lt;span style="color:#f92672"&gt;import&lt;/span&gt; PromptTemplate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# FewShot examples&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;examples &lt;span style="color:#f92672"&gt;=&lt;/span&gt; [
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;question&amp;#34;&lt;/span&gt;: &lt;span style="color:#e6db74"&gt;&amp;#34;你好嗎?&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;: &lt;span style="color:#e6db74"&gt;&amp;#34;主人，我很好。&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; },
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;question&amp;#34;&lt;/span&gt;: &lt;span style="color:#e6db74"&gt;&amp;#34;今天禮拜幾?&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;: &lt;span style="color:#e6db74"&gt;&amp;#34;主人，今天禮拜日。&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; },
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;question&amp;#34;&lt;/span&gt;: &lt;span style="color:#e6db74"&gt;&amp;#34;天氣真好呀。&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;: &lt;span style="color:#e6db74"&gt;&amp;#34;主人，是的，今天天氣非常好。&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# FewShotPromptTemplate-樣本提示模板&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 提示模板以 Question:開頭&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;example_prompt &lt;span style="color:#f92672"&gt;=&lt;/span&gt; PromptTemplate(input_variables&lt;span style="color:#f92672"&gt;=&lt;/span&gt;[&lt;span style="color:#e6db74"&gt;&amp;#34;question&amp;#34;&lt;/span&gt;, &lt;span style="color:#e6db74"&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;], template&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;Question: &lt;/span&gt;&lt;span style="color:#e6db74"&gt;{question}&lt;/span&gt;&lt;span style="color:#ae81ff"&gt;\n&lt;/span&gt;&lt;span style="color:#e6db74"&gt;Answer: &lt;/span&gt;&lt;span style="color:#e6db74"&gt;{answer}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;few_shot_prompt &lt;span style="color:#f92672"&gt;=&lt;/span&gt; FewShotPromptTemplate(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; examples&lt;span style="color:#f92672"&gt;=&lt;/span&gt;examples, &lt;span style="color:#75715e"&gt;# 傳入樣本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; example_prompt&lt;span style="color:#f92672"&gt;=&lt;/span&gt;example_prompt, &lt;span style="color:#75715e"&gt;# 傳入樣本模板&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; suffix&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;Question: &lt;/span&gt;&lt;span style="color:#e6db74"&gt;{input}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;&lt;/span&gt;, &lt;span style="color:#75715e"&gt;# 問題的提示詞&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; input_variables&lt;span style="color:#f92672"&gt;=&lt;/span&gt;[&lt;span style="color:#e6db74"&gt;&amp;#34;input&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(few_shot_prompt&lt;span style="color:#f92672"&gt;.&lt;/span&gt;format(input&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;你今天過得怎麼樣?&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出完整提示詞如下，但前面三組為提供的範例案例，最後一組是輸入的提問。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;Question: 你好嗎?
Answer: 主人，我很好。
Question: 今天禮拜幾?
Answer: 主人，今天禮拜日。
Question: 天氣真好呀。
Answer: 主人，是的，今天天氣非常好。
Question: 你今天過得怎麼樣?
&lt;/code&gt;&lt;/pre&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_ollama &lt;span style="color:#f92672"&gt;import&lt;/span&gt; OllamaLLM
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;llm &lt;span style="color:#f92672"&gt;=&lt;/span&gt; OllamaLLM(model&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;llama3.1:8b&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;response &lt;span style="color:#f92672"&gt;=&lt;/span&gt; llm&lt;span style="color:#f92672"&gt;.&lt;/span&gt;invoke(few_shot_prompt&lt;span style="color:#f92672"&gt;.&lt;/span&gt;format(input&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;你今天過得怎麼樣?&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(response)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出結果：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;你的問題是問你今天過得怎麼樣？我可以回答說：您也很好。或者，我可以詢問一下您今天過得怎麼樣？
如果你想知道我的答案，那就是：主人，今天我很好，謝謝您的關心！
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="樣本篩選器-exampleselector"&gt;樣本篩選器 (ExampleSelector)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;樣本數量太多時&lt;/li&gt;
&lt;li&gt;不是所有樣本都能幫助提升輸出質量
&lt;img src="https://Dandelionlibra.github.io/image/ExampleSelector.JPG"
loading="lazy"
alt="partial_prompt_template"
&gt;&lt;/li&gt;
&lt;li&gt;舉例: SemanticSimilarityExampleSelector (語意相似度篩選器)，依據最終提的問題，在所有樣本中尋找語意最為接近的樣本。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="大型語言模型的封裝"&gt;大型語言模型的封裝
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Langchain 不提供現成的大型語言模型&lt;/li&gt;
&lt;li&gt;Langchain 提供的是針對不同語言模型的標準化接口&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="大型語言模型llm模塊的基本用法"&gt;大型語言模型(LLM)模塊的基本用法
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;直接呼叫
&lt;ul&gt;
&lt;li&gt;類似直接呼叫.invoke()，讓語言模型根據輸入回答內容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_ollama &lt;span style="color:#f92672"&gt;import&lt;/span&gt; OllamaLLM
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;llm &lt;span style="color:#f92672"&gt;=&lt;/span&gt; OllamaLLM(model&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;llama3.1:8b&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(llm(&lt;span style="color:#e6db74"&gt;&amp;#34;跟我說一個笑話，盡量簡短。&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;為什麼電池走路去了? 因為它想充電
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;批量生成
&lt;ul&gt;
&lt;li&gt;generate()&lt;/li&gt;
&lt;li&gt;輸入：文本的列表&lt;/li&gt;
&lt;li&gt;輸出：文本的列表&lt;/li&gt;
&lt;li&gt;ex. 輸入問題的列表，輸出回答的列表。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;generate_res &lt;span style="color:#f92672"&gt;=&lt;/span&gt; llm&lt;span style="color:#f92672"&gt;.&lt;/span&gt;generate([&lt;span style="color:#e6db74"&gt;&amp;#34;跟我說一個笑話，盡量簡短。&amp;#34;&lt;/span&gt;, &lt;span style="color:#e6db74"&gt;&amp;#34;跟我說一個悲傷的故事，盡量簡短。&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(generate_res)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出：&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;generations=[[GenerationChunk(text=&amp;#39;為什麼人類會走路?\n\n因為鳥不喜歡吃路上的東西!&amp;#39;, generation_info={&amp;#39;model&amp;#39;: &amp;#39;llama3.1:8b&amp;#39;, &amp;#39;created_at&amp;#39;: &amp;#39;2025-07-13T14:22:01.5478452Z&amp;#39;, &amp;#39;done&amp;#39;: True, &amp;#39;done_reason&amp;#39;: &amp;#39;stop&amp;#39;, &amp;#39;total_duration&amp;#39;: 2588937700, &amp;#39;load_duration&amp;#39;: 39039000, &amp;#39;prompt_eval_count&amp;#39;: 23, &amp;#39;prompt_eval_duration&amp;#39;: 335147300, &amp;#39;eval_count&amp;#39;: 22, &amp;#39;eval_duration&amp;#39;: 2214149200, &amp;#39;response&amp;#39;: &amp;#39;&amp;#39;, &amp;#39;thinking&amp;#39;: None, &amp;#39;context&amp;#39;: [128006, 882, 128007, 271, 104142, 37046, 106336, 114634, 49838, 87177, 3922, 16555, 94, 33857, 112825, 106649, 1811, 128009, 128006, 78191, 128007, 271, 101399, 101567, 114064, 17792, 104770, 101835, 102149, 47095, 1980, 63212, 101399, 116750, 16937, 104940, 125741, 105271, 47095, 106583, 101778, 61786, 0]})], [GenerationChunk(text=&amp;#39;有一個年輕女孩，她與自己的父親非常相愛。可是因為工作太忙，爸爸長期外出，並且忽略了女兒。直到一天，一場重大事故讓爸爸去世。在悲痛中，女孩發現了之前父親給她的信，裡面有對她的溫暖告白和深情懷念。這個消息使她心痛欲裂，從此女孩再也沒有恢復過。&amp;#39;, generation_info={&amp;#39;model&amp;#39;: &amp;#39;llama3.1:8b&amp;#39;, &amp;#39;created_at&amp;#39;: &amp;#39;2025-07-13T14:22:16.1064263Z&amp;#39;, &amp;#39;done&amp;#39;: True, &amp;#39;done_reason&amp;#39;: &amp;#39;stop&amp;#39;, &amp;#39;total_duration&amp;#39;: 14556868200, &amp;#39;load_duration&amp;#39;: 39856500, &amp;#39;prompt_eval_count&amp;#39;: 25, &amp;#39;prompt_eval_duration&amp;#39;: 516644200, &amp;#39;eval_count&amp;#39;: 104, &amp;#39;eval_duration&amp;#39;: 13999594200, &amp;#39;response&amp;#39;: &amp;#39;&amp;#39;, &amp;#39;thinking&amp;#39;: None, &amp;#39;context&amp;#39;: [128006, 882, 128007, 271, 104142, 37046, 106336, 114634, 116292, 114218, 9554, 117625, 3922, 16555, 94, 33857, 112825, 106649, 1811, 128009, 128006, 78191, 128007, 271, 108830, 102159, 8107, 125063, 58850, 105989, 105902, 102789, 107924, 104503, 106759, 108008, 50021, 103926, 1811, 113426, 63212, 101399, 102301, 101402, 112008, 3922, 117283, 117283, 101544, 23538, 48915, 20834, 113415, 103786, 120994, 105838, 35287, 58850, 114763, 1811, 74245, 28037, 15120, 36827, 104295, 75267, 125478, 123429, 114816, 117283, 117283, 86436, 101083, 107644, 116292, 108631, 16325, 3922, 58850, 105989, 103106, 102321, 35287, 112065, 104503, 106759, 110698, 109506, 22023, 3922, 115556, 28190, 19361, 104314, 109506, 117986, 118937, 58655, 101828, 34208, 102987, 40474, 103435, 115, 104611, 1811, 103864, 102159, 65305, 33655, 100911, 64209, 108631, 111654, 117068, 3922, 110039, 33091, 58850, 105989, 88356, 75863, 116721, 123843, 109095, 103188, 1811]})]] llm_output=None run=[RunInfo(run_id=UUID(&amp;#39;bc24e5b6-0c3f-4d2c-afb4-95f477e81adf&amp;#39;)), RunInfo(run_id=UUID(&amp;#39;f8f5fe28-4c1d-4b6f-8a74-fdcc6f397f7a&amp;#39;))] type=&amp;#39;LLMResult&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可用陣列獲取特定輸出。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(generate_res&lt;span style="color:#f92672"&gt;.&lt;/span&gt;generations[&lt;span style="color:#ae81ff"&gt;0&lt;/span&gt;][&lt;span style="color:#ae81ff"&gt;0&lt;/span&gt;]&lt;span style="color:#f92672"&gt;.&lt;/span&gt;text)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(generate_res&lt;span style="color:#f92672"&gt;.&lt;/span&gt;generations[&lt;span style="color:#ae81ff"&gt;1&lt;/span&gt;][&lt;span style="color:#ae81ff"&gt;0&lt;/span&gt;]&lt;span style="color:#f92672"&gt;.&lt;/span&gt;text)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;為什麼人類會走路?
因為鳥不喜歡吃路上的東西!
有一個年輕女孩，她與自己的父親非常相愛。可是因為工作太忙，爸爸長期外出，並且忽略了女兒。直到一天，一場重大事故讓爸爸去世。在悲痛中，女孩發現了之前父親給她的信，裡面有對她的溫暖告白和深情懷念。這個消息使她心痛欲裂，從此女孩再也沒有恢復過。
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="自定義-llm-模組"&gt;自定義 LLM 模組
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;用於封裝 Langchain 尚未支持的大型語言模型&lt;/li&gt;
&lt;li&gt;可以用來模擬測試&lt;/li&gt;
&lt;li&gt;自行定義當 LLM 被調用時，如何根據輸入的文本內容來輸出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_code.ipynb" target="_blank" rel="noopener"
&gt;詳細程式請參閱&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="reference"&gt;Reference
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
&gt;https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>LangChain 安裝與基本使用-1</title><link>https://Dandelionlibra.github.io/post/langchain/uselangchain-1/</link><pubDate>Sun, 06 Jul 2025 15:33:11 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/uselangchain-1/</guid><description>&lt;h1 id="安裝-langchain"&gt;安裝 LangChain
&lt;/h1&gt;&lt;p&gt;使用 pip 指令安裝 LangChain 核心套件，其中提供各組件與基本框架。&lt;br&gt;
LangChain 相關套件的詳細資訊可以參考&lt;a class="link" href="https://python.langchain.com/api_reference/" target="_blank" rel="noopener"
&gt;langchain 官方文件&lt;/a&gt;。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;pip install langchain
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安裝 LangChain 社群套件，其中包含由社群維護的第三方整合模組。&lt;br&gt;
隨著 LangChain 的模組化，許多原本內建於核心套件的整合功能被轉移到此套件中，以保持核心套件的輕量化。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;pip install langchain_community
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安裝 LangChain 與本地 Ollama 模型整合專用驅動，
可以在 LangChain 中使用本地 Ollama 模型作為 LLM。
LangChain 官方維護的專門用於整合本地 Ollama LLM 的插件套件。&lt;/p&gt;
&lt;p&gt;因為 LangChain 在 0.3.1 後將原本內建於 &lt;code&gt;langchain_community.llms.Ollama&lt;/code&gt; 的 Ollama 整合模組 拆分為獨立的 &lt;code&gt;langchain-ollama&lt;/code&gt; 套件。&lt;br&gt;
詳細資訊可以參考&lt;a class="link" href="https://python.langchain.com/api_reference/ollama/index.html" target="_blank" rel="noopener"
&gt;langchain 官方文件&lt;/a&gt;。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;pip install langchain-ollama
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="簡單應用"&gt;簡單應用
&lt;/h1&gt;&lt;p&gt;本文所有範例程式碼都可以在 &lt;a class="link" href="https://github.com/Dandelionlibra/Dandelionlibra.github.io/blob/main/content/post/langchain/LangChain_code.ipynb" target="_blank" rel="noopener"
&gt;Jupyter Notebook&lt;/a&gt; 中找到。&lt;/p&gt;
&lt;h2 id="文本生成"&gt;文本生成
&lt;/h2&gt;&lt;p&gt;LangChain 中 LLM 的最基本功能是根據輸入的文本生成新的文本。&lt;/p&gt;
&lt;p&gt;註:不清楚 Ollama 如何使用的可以去看我關於 Ollama 的基礎使用文章。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;from langchain_ollama import OllamaLLM
llm = OllamaLLM(model=&amp;#34;llama3.1:8b&amp;#34;)
response = llm.invoke(&amp;#34;幫我取一個文雅的中國男孩名&amp;#34;)
print(response)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;temperature 用於控制 LLM 生成回答的隨機性與創造性。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;temperature&lt;/code&gt; 值&lt;/th&gt;
&lt;th&gt;行為特性&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;完全可重現，幾乎總是給出相同回答，適合需要準確且穩定輸出時使用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;0.3 ~ 0.7&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;中度創造性，適合一般應用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;高度創造性，回答可能更多樣化與隨機&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;&amp;gt;1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;非常隨機，回答可能跳脫常規&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;例如可以在剛剛的 response 中使用 options 將 temperature 設為 0，使輸出每次都會得到一樣的答案。&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;response = llm.invoke(&amp;#34;幫我取一個文雅的中國男孩名&amp;#34;, options={&amp;#34;temperature&amp;#34;: 0})
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="聊天模組"&gt;聊天模組
&lt;/h2&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage
Chatllm = ChatOllama(model=&amp;#34;llama3.1:8b&amp;#34;)
test = &amp;#34;幫我取一個文雅的中國男孩名&amp;#34;
messages = [HumanMessage(content=test)]
response = Chatllm.invoke(messages)
print(response)
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="ollamallm-vschatollama"&gt;OllamaLLM vs.ChatOllama
&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;項目&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;OllamaLLM&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;ChatOllama&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;來源&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;from langchain_ollama import OllamaLLM&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;from langchain_ollama import ChatOllama&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;用途&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;單輪文字生成（Single-turn LLM）&lt;/td&gt;
&lt;td&gt;多輪對話（Chat-based LLM）&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;典型應用場景&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;單次回答、批次生成資料、文字生成工具&lt;/td&gt;
&lt;td&gt;聊天機器人、多輪上下文對話、Memory 結合&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;輸入型態&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;str&lt;/code&gt;（純文字 prompt）&lt;/td&gt;
&lt;td&gt;&lt;code&gt;List[BaseMessage]&lt;/code&gt;（包含 &lt;code&gt;SystemMessage&lt;/code&gt;, &lt;code&gt;HumanMessage&lt;/code&gt;, &lt;code&gt;AIMessage&lt;/code&gt;）&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;回傳型態&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;str&lt;/code&gt;（文字回應）&lt;/td&gt;
&lt;td&gt;&lt;code&gt;AIMessage(content='...')&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;回傳內容存取&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;直接使用 &lt;code&gt;print(response)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;使用 &lt;code&gt;print(response.content)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;是否支援多輪上下文&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;td&gt;O&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;適合結合 Agent&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;作為推論引擎&lt;/td&gt;
&lt;td&gt;作為 Chat Agent 對話引擎&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;可搭配 Memory&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;td&gt;可搭配 Memory 實現上下文持續對話&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="鏈式結構"&gt;鏈式結構
&lt;/h2&gt;&lt;p&gt;連接多個 LLM 模組。
&lt;img src="https://Dandelionlibra.github.io/image/LLMChain.png"
loading="lazy"
alt="LLMChain"
&gt;&lt;/p&gt;
&lt;h3 id="如何避免重複定義相似的-llm-模組"&gt;如何避免重複定義相似的 LLM 模組?
&lt;/h3&gt;&lt;p&gt;使用提示模板(prompt template)去避免重複定義功能相似的組件。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_ollama &lt;span style="color:#f92672"&gt;import&lt;/span&gt; OllamaLLM
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.prompts &lt;span style="color:#f92672"&gt;import&lt;/span&gt; PromptTemplate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;llm_model &lt;span style="color:#f92672"&gt;=&lt;/span&gt; OllamaLLM(model&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;llama3.1:8b&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;user_prompt &lt;span style="color:#f92672"&gt;=&lt;/span&gt; PromptTemplate&lt;span style="color:#f92672"&gt;.&lt;/span&gt;from_template(&lt;span style="color:#e6db74"&gt;&amp;#34;幫我取一個&lt;/span&gt;&lt;span style="color:#e6db74"&gt;{形容詞}{對象}&lt;/span&gt;&lt;span style="color:#e6db74"&gt;名, 並對應一個小名。&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(user_prompt&lt;span style="color:#f92672"&gt;.&lt;/span&gt;format(對象 &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#39;寵物&amp;#39;&lt;/span&gt;, 形容詞 &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#39;可愛的&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(user_prompt&lt;span style="color:#f92672"&gt;.&lt;/span&gt;format(對象 &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#39;男孩&amp;#39;&lt;/span&gt;, 形容詞 &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#39;文雅的&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.chains &lt;span style="color:#f92672"&gt;import&lt;/span&gt; LLMChain
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;chain &lt;span style="color:#f92672"&gt;=&lt;/span&gt; LLMChain(llm&lt;span style="color:#f92672"&gt;=&lt;/span&gt;llm_model, prompt&lt;span style="color:#f92672"&gt;=&lt;/span&gt;user_prompt)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(chain&lt;span style="color:#f92672"&gt;.&lt;/span&gt;run(對象 &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#39;小狗&amp;#39;&lt;/span&gt;, 形容詞 &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#39;有趣的&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="代理人"&gt;代理人
&lt;/h2&gt;&lt;p&gt;主要用於處理鏈式結構無法處理的問題，並可達成動態決策。
舉例而言，一般大型語言模型是無法聯網的，而為了讓 LangChain 去獲得最新的內容或者現有資料庫中不存在的資訊，就需要使用代理人 (Agents) 組件達成聯網。&lt;/p&gt;
&lt;h3 id="行為方式"&gt;行為方式
&lt;/h3&gt;&lt;p&gt;代理人可以使用一系列預設的工具&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;選擇工具&lt;/li&gt;
&lt;li&gt;使用工具&lt;/li&gt;
&lt;li&gt;觀測並處理工具使用結果&lt;/li&gt;
&lt;li&gt;重複以上步驟&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="範例"&gt;範例
&lt;/h3&gt;&lt;p&gt;使代理人能完成數學運算任務。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;step1: 定義底層 LLM 模組&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_ollama &lt;span style="color:#f92672"&gt;import&lt;/span&gt; OllamaLLM
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;llm_model &lt;span style="color:#f92672"&gt;=&lt;/span&gt; OllamaLLM(model&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;llama3.1:8b&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;step2: 定義允許代理人使用的工具&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.agents &lt;span style="color:#f92672"&gt;import&lt;/span&gt; initialize_agent, load_tools
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;tools &lt;span style="color:#f92672"&gt;=&lt;/span&gt; load_tools([&lt;span style="color:#e6db74"&gt;&amp;#34;llm-math&amp;#34;&lt;/span&gt;], llm&lt;span style="color:#f92672"&gt;=&lt;/span&gt;llm_model)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;step3: 初始化代理人&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;agent &lt;span style="color:#f92672"&gt;=&lt;/span&gt; initialize_agent(tools, llm_model, agent&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;zero-shot-react-description&amp;#34;&lt;/span&gt;, verbose&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#66d9ef"&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;step4: 運行代理人&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;agent&lt;span style="color:#f92672"&gt;.&lt;/span&gt;invoke(&lt;span style="color:#e6db74"&gt;&amp;#34;如果我有 100 元，買了 3 個蘋果，每個蘋果 10 元，剩下多少錢？&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="聊天紀錄"&gt;聊天紀錄
&lt;/h2&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain_ollama &lt;span style="color:#f92672"&gt;import&lt;/span&gt; OllamaLLM
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;llm_model &lt;span style="color:#f92672"&gt;=&lt;/span&gt; OllamaLLM(model&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#e6db74"&gt;&amp;#34;llama3.1:8b&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; langchain.chains &lt;span style="color:#f92672"&gt;import&lt;/span&gt; ConversationChain
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;conversation &lt;span style="color:#f92672"&gt;=&lt;/span&gt; ConversationChain(llm&lt;span style="color:#f92672"&gt;=&lt;/span&gt;llm_model, verbose&lt;span style="color:#f92672"&gt;=&lt;/span&gt;&lt;span style="color:#66d9ef"&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;conversation&lt;span style="color:#f92672"&gt;.&lt;/span&gt;run(&lt;span style="color:#e6db74"&gt;&amp;#34;我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: 我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?
AI:
&amp;gt; Finished chain.
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;#39;啊哈！你想要一個聰明又可愛的伴侶嗎？我有一些超好的建議！基於你的描述，我推測你可能是新手狗主人，所以我要首先介紹一下最適合初學者的犬種。有了這些犬種，你就能輕鬆地培養起一個聽話又善良的伴侶。\n\n其中，拉布拉多犬和金氏體型小獵犬（Cavalier King Charles Spaniel）都很受人喜愛，.......你對於犬種的偏好是什麼？你想要一隻大犬還是一隻小犬呢？&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;conversation&lt;span style="color:#f92672"&gt;.&lt;/span&gt;run(&lt;span style="color:#e6db74"&gt;&amp;#34;那貓呢?&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: 我想養一隻聽話又好照顧的動物，你有甚麼推薦嗎?
AI: 啊哈！你想要一個聰明又可愛的伴侶嗎？我有一些超好的建議！基於你的描述，我推測你可能是新手狗主人，所以我要首先介紹一下最適合初學者的犬種。有了這些犬種，你就能輕鬆地培養起一個聽話又善良的伴侶。
...省略...
最後，我想問一下，你對於犬種的偏好是什麼？你想要一隻大犬還是一隻小犬呢？
Human: 那貓呢?
AI:
&amp;gt; Finished chain.
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;#39;貓！我很樂意幫助你找一個適合你的貓伴侶！但是，值得注意的是，我之前主要是在說狗的話題，因為我的訓練資料集中在犬類上。\n\n但是在貓類方面，我可以提供一些基本信息。...省略...或者你對貓的需求和生活方式是否有所變化？&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="reference"&gt;Reference
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
&gt;https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Introduction langchain</title><link>https://Dandelionlibra.github.io/post/langchain/introlangchain/</link><pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate><guid>https://Dandelionlibra.github.io/post/langchain/introlangchain/</guid><description>&lt;h1 id="介紹-langchain"&gt;介紹 LangChain
&lt;/h1&gt;&lt;p&gt;LangChain 為 2022 年發布的開源框架，主要用於開發由語言模型驅動的應用程式，可連接多種語言模型與外部工具。&lt;br&gt;
&lt;a class="link" href="https://www.langchain.com" target="_blank" rel="noopener"
&gt;LangChain 官方網站&lt;/a&gt;
&lt;img src="https://Dandelionlibra.github.io/image/ecosystem_packages-32943b32657e7a187770c9b585f22a64.png"
loading="lazy"
alt="LLMChain"
&gt;&lt;/p&gt;
&lt;h2 id="優點"&gt;優點
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;開源工具&lt;/li&gt;
&lt;li&gt;支持多種開源模型&lt;/li&gt;
&lt;li&gt;可整合多項外部服務&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="主要組件"&gt;主要組件
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;模型 (Models)
&lt;ul&gt;
&lt;li&gt;語言模型、文本嵌入模型等等&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;記憶體 (Memory)
&lt;ul&gt;
&lt;li&gt;短期與長期記憶，用於儲存與檢索聊天歷史&lt;/li&gt;
&lt;li&gt;包含對話緩衝記憶體、實體記憶體、向量儲存記憶體&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;代理 (Agents)
&lt;ul&gt;
&lt;li&gt;推理引擎&lt;/li&gt;
&lt;li&gt;可以根據給定的情境與數據做出合理的決策與推理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LangChain 藉由這些組件連結各種模型與工具，以達成檢索與分析數據，並可進行個性化的訂製。&lt;/p&gt;
&lt;h2 id="主要解決問題"&gt;主要解決問題
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;如何格式化輸出?&lt;/li&gt;
&lt;li&gt;如何輸出很長的文本?&lt;/li&gt;
&lt;li&gt;如何呼叫多次 api?&lt;/li&gt;
&lt;li&gt;如何使 api 能呼叫外部的服務、工具?&lt;/li&gt;
&lt;li&gt;如何進行標準化的開發?&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="reference"&gt;Reference
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://python.langchain.com/docs/introduction/" target="_blank" rel="noopener"
&gt;https://python.langchain.com/docs/introduction/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://www.youtube.com/watch?v=feFp5TbrVMo" target="_blank" rel="noopener"
&gt;https://www.youtube.com/watch?v=feFp5TbrVMo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI" target="_blank" rel="noopener"
&gt;https://www.youtube.com/playlist?list=PLAr9oL1AT4OElxInUijCzCgU3CpgHTjTI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item></channel></rss>